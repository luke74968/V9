# Copyright (c) 2025 Minuk Lee. All rights reserved.
# 
# This source code is proprietary and confidential.
# Unauthorized copying of this file, via any medium is strictly prohibited.
# 
# For licensing terms, see the LICENSE file.
# Contact: minuklee@snu.ac.kr
# 
import torch
from tensordict import TensorDict
from torchrl.envs import EnvBase
from torchrl.data import Unbounded, UnboundedDiscrete, Composite
from typing import Optional, Dict, Union, Tuple, List

# --- í˜„ì¬ íŒ¨í‚¤ì§€(transformer_solver) ëª¨ë“ˆ ì„í¬íŠ¸ ---
from .definitions import (
    FEATURE_DIM, FEATURE_INDEX, SCALAR_PROMPT_FEATURE_DIM,
    NODE_TYPE_PADDING, NODE_TYPE_BATTERY, NODE_TYPE_LOAD, 
    NODE_TYPE_IC, NODE_TYPE_EMPTY
)
from .env_generator import PocatGenerator

# --- í™˜ê²½ ìƒìˆ˜ ---
BATTERY_NODE_IDX = 0 # ë°°í„°ë¦¬ ë…¸ë“œëŠ” í•­ìƒ 0ë²ˆ ì¸ë±ìŠ¤
REWARD_WEIGHT_ACTION = 0.0  # (A2C) ì•¡ì…˜(IC ìŠ¤í°) ì¦‰ì‹œ ë¹„ìš©ì— ëŒ€í•œ ê°€ì¤‘ì¹˜
REWARD_WEIGHT_PATH = 1.0    # (A2C) ê²½ë¡œ(Load->BATT) ì™„ì„± ì‹œ ëˆ„ì  ë¹„ìš© ê°€ì¤‘ì¹˜
STEP_PENALTY = 0.0          # (A2C) ìŠ¤í…ë‹¹ í˜ë„í‹°
FAILURE_PENALTY = -20000.0    # (A2C) ì‹¤íŒ¨(ë§‰ë‹¤ë¥¸ ê¸¸) í˜ë„í‹°

# 1. ê°€ê²©(BOM) ë¯¼ê°ë„ ê°€ì¤‘ì¹˜ (Cost Sensitivity)
#    ê¸°ë³¸ê°’ 1.0 -> 100.0ìœ¼ë¡œ ìƒí–¥ (0.01ë‹¬ëŸ¬ ì ˆì•½ = +1.0ì  ë³´ìƒ)
#    ì´ì œ ëª¨ë¸ì€ 1ì„¼íŠ¸(0.01) ì°¨ì´ë„ 1ì  ì°¨ì´ë¡œ í¬ê²Œ ëŠë‚ë‹ˆë‹¤.
WEIGHT_BOM = 100.0

# 2. ìœ„ë°˜ í˜ë„í‹° ê°€ì¤‘ì¹˜ (Violation Weight)
#    ì˜ˆì‚° ì´ˆê³¼ëŸ‰(A)ì— ê³±í•´ì§ˆ ê³„ìˆ˜ì…ë‹ˆë‹¤.
#    (ì˜ˆ: 1mA(=0.001) ì´ˆê³¼ ì‹œ -> 0.001 * 50000 = 50ì  ê°ì )
PENALTY_SLEEP_WEIGHT = 50000.0 

# 3. ì˜ˆì‚° ì´ˆê³¼ ì‹œ ê³ ì • í˜ë„í‹° (Step Penalty)
#    ê°€ê²© ê°€ì¤‘ì¹˜ê°€ ì»¤ì¡Œìœ¼ë¯€ë¡œ, ë²Œê¸ˆë„ ê°™ì´ ì˜¬ë ¤ì•¼ ê·œì œë¥¼ ë¬´ì‹œí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
#    (ì˜ˆ: 5ë‹¬ëŸ¬ë¥¼ ì•„ê»´ì„œ +500ì ì„ ë°›ì•„ë„, ë²Œê¸ˆì´ -2000ì ì´ë©´ ì ˆëŒ€ ìœ„ë°˜ ì•ˆ í•¨)
PENALTY_SLEEP_STEP = 2000.0



class PocatEnv(EnvBase):
    """
    Pocat ë¬¸ì œë¥¼ í’€ê¸° ìœ„í•œ ê°•í™”í•™ìŠµ í™˜ê²½(Environment)ì…ë‹ˆë‹¤.
    
    TensorDictë¥¼ ìƒíƒœ(State)ë¡œ ì‚¬ìš©í•˜ë©°, Parameterized Action(Connect/Spawn)ì„
    ì²˜ë¦¬í•˜ì—¬ ìƒíƒœë¥¼ ì „ì´ì‹œí‚¤ê³  ë³´ìƒ(Reward)ì„ ê³„ì‚°í•©ë‹ˆë‹¤.
    """
    
    name = "pocat_env"

    def __init__(self, generator_params: dict, device: str = "cpu", N_max: int = 500, **kwargs):
        """
        PocatEnvë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
        
        Args:
            generator_params (dict): PocatGeneratorì— ì „ë‹¬ë  íŒŒë¼ë¯¸í„°
            device (str): í…ì„œ ì—°ì‚°ì„ ìˆ˜í–‰í•  ë””ë°”ì´ìŠ¤
            N_max (int): ëª¨ë¸ì´ ì²˜ë¦¬í•  ê³ ì •ëœ ìµœëŒ€ ë…¸ë“œ í¬ê¸°
        """
        super().__init__(device=device)
        
        # 1. N_max ê°’ì„ ì €ì¥í•©ë‹ˆë‹¤.
        self.N_max = N_max
        
        # 2. ì œë„ˆë ˆì´í„° ì´ˆê¸°í™” (N_max ì „ë‹¬)
        self.generator = PocatGenerator(**generator_params, N_max=N_max)
        
        # 3. ë§ˆìŠ¤í‚¹ ë° ê³„ì‚°ì— ì‚¬ìš©í•  ë²„í¼ ë“±ë¡
        self.register_buffer("arange_nodes", None, persistent=False)
        self.register_buffer("node_type_tensor", None, persistent=False)
        self.register_buffer("load_idx_tensor", None, persistent=False)
        self.register_buffer("rail_types", None, persistent=False)

        # 4. Observation, Action ìŠ¤í™ ì •ì˜
        self._make_spec()
        
        # 5. ì œì•½ì¡°ê±´(ì‹œí€€ì‹±, ë…ë¦½) ì •ë³´ ë¡œë“œ
        self._load_constraint_info()

    def _make_spec(self):
        """í™˜ê²½ì˜ Observation, Action, Reward ìŠ¤í™ì„ ì •ì˜í•©ë‹ˆë‹¤."""
        
        num_nodes = self.N_max
        
        # 1. Observation ìŠ¤í™ ì •ì˜
        self.observation_spec = Composite({
            # --- ì •ì  í…ì„œ (Generator ì œê³µ) ---
            "nodes": Unbounded(shape=(num_nodes, FEATURE_DIM)),
            "scalar_prompt_features": Unbounded(shape=(SCALAR_PROMPT_FEATURE_DIM,)),
            "matrix_prompt_features": Unbounded(shape=(num_nodes, num_nodes)),
            "connectivity_matrix": Unbounded(shape=(num_nodes, num_nodes), dtype=torch.bool),
            "attention_mask": Unbounded(shape=(num_nodes, num_nodes), dtype=torch.bool),
            
            # --- ë™ì  í…ì„œ (Env ê´€ë¦¬) ---
            "adj_matrix": Unbounded(shape=(num_nodes, num_nodes), dtype=torch.bool),
            "adj_matrix_T": Unbounded(shape=(num_nodes, num_nodes), dtype=torch.bool),
            "unconnected_loads_mask": Unbounded(shape=(num_nodes,), dtype=torch.bool),
            "trajectory_head": UnboundedDiscrete(shape=(1,)),
            "step_count": UnboundedDiscrete(shape=(1,)),
            "current_cost": Unbounded(shape=(1,)),
            "staging_cost": Unbounded(shape=(1,)), # í˜„ì¬ ê²½ë¡œì˜ ëˆ„ì  ë¹„ìš©
            "sleep_cost": Unbounded(shape=(1,)), # [ì¶”ê°€] ì•”ì „ë¥˜ í˜ë„í‹° ë¹„ìš©
    
            "log_reward_bom": Unbounded(shape=(1,)),
            "log_reward_sleep": Unbounded(shape=(1,)),
            "log_reward_fail": Unbounded(shape=(1,)),   
            
            "is_used_ic_mask": Unbounded(shape=(num_nodes,), dtype=torch.bool),
            "current_target_load": UnboundedDiscrete(shape=(1,)),
            "is_exclusive_mask": Unbounded(shape=(num_nodes,), dtype=torch.long),
            "next_empty_slot_idx": UnboundedDiscrete(shape=(1,)), # ë‹¤ìŒ ìŠ¤í° ìœ„ì¹˜
        })
        
        # 2. Action ìŠ¤í™ ì •ì˜ (Parameterized Action)
        self.action_spec = Composite({
            # (0: Connect, 1: Spawn)
            "action_type": UnboundedDiscrete(shape=(1,)),
            # (0 ~ N_max-1): Connect ëŒ€ìƒ
            "connect_target": UnboundedDiscrete(shape=(1,)),
            # (0 ~ N_max-1): Spawní•  í…œí”Œë¦¿
            "spawn_template": UnboundedDiscrete(shape=(1,)),
        })
        
        # 3. Reward ìŠ¤í™ ì •ì˜
        self.reward_spec = Unbounded(shape=(1,))

    def _load_constraint_info(self):
        """
        config íŒŒì¼ì—ì„œ ì œì•½ì¡°ê±´ ì •ë³´ë¥¼ ë¡œë“œí•˜ê³ 
        ë§ˆìŠ¤í‚¹ì— ì‚¬ìš©í•˜ê¸° ì‰½ë„ë¡ í…ì„œë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥í•©ë‹ˆë‹¤.
        """
        # (B,L,IC) ìˆœì„œê°€ í…ì„œ ìˆœì„œì™€ ì¼ì¹˜
        self.node_name_to_idx = {name: i for i, name in enumerate(self.generator.config.node_names)}
        
        # 1. Independent Rail (ë…ë¦½ ë ˆì¼) ì •ë³´
        rail_type_map = {"exclusive_supplier": 1, "exclusive_path": 2}
        rail_types_list = []
        
        # (Load ë…¸ë“œëŠ” 1ë²ˆ ì¸ë±ìŠ¤ë¶€í„° ì‹œì‘)
        load_start_idx = self.generator.num_battery
        for i, load_cfg in enumerate(self.generator.config.loads):
            load_idx = load_start_idx + i
            rail_type = rail_type_map.get(load_cfg.get("independent_rail_type"), 0)
            rail_types_list.append((load_idx, rail_type))
        
        # (N_max,) í¬ê¸°ì˜ í…ì„œë¡œ ë³€í™˜
        self.rail_types_tensor = torch.zeros(self.N_max, dtype=torch.long, device=self.device)
        if rail_types_list:
            indices = torch.tensor([idx for idx, _ in rail_types_list], dtype=torch.long, device=self.device)
            values = torch.tensor([val for _, val in rail_types_list], dtype=torch.long, device=self.device)
            self.rail_types_tensor.scatter_(0, indices, values)

        # 2. Power Sequence (ì „ì› ì‹œí€€ì‹±) ì •ë³´
        self.power_sequences = []
        for seq in self.generator.config.constraints.get("power_sequences", []):
            f_flag = seq.get("f", 1) # (1: ë™ì¼ ë¶€ëª¨ ê¸ˆì§€)
            j_idx = self.node_name_to_idx.get(seq['j'])
            k_idx = self.node_name_to_idx.get(seq['k'])
            if j_idx is not None and k_idx is not None:
                self.power_sequences.append((j_idx, k_idx, f_flag))

    def _ensure_buffers(self, td: TensorDict):
        """
        Observation í…ì„œê°€ ë³€ê²½ë  ë•Œë§ˆë‹¤(ì£¼ë¡œ _reset ì‹œ)
        ë§ˆìŠ¤í‚¹ ê³„ì‚°ì— í•„ìš”í•œ í—¬í¼ í…ì„œë“¤ì„ ë¯¸ë¦¬ ê³„ì‚°í•©ë‹ˆë‹¤.
        """
        num_nodes = td["nodes"].shape[1] # (N_max)

        if self.arange_nodes is None or self.arange_nodes.numel() != num_nodes:
            self.arange_nodes = torch.arange(num_nodes, device=self.device)
        
        if self.node_type_tensor is None:
            # (N_max,)
            node_types = td["nodes"][0, :, FEATURE_INDEX["node_type"][0]:FEATURE_INDEX["node_type"][1]].argmax(-1)
            self.node_type_tensor = node_types
            
            # (N_loads,)
            self.load_idx_tensor = torch.where(node_types == NODE_TYPE_LOAD)[0]

    def select_start_nodes(self, td: TensorDict) -> Tuple[int, torch.Tensor]:
        """ POMO (Multi-Start)ë¥¼ ìœ„í•´ ì‹œì‘ ê°€ëŠ¥í•œ ëª¨ë“  Load ë…¸ë“œì˜ ì¸ë±ìŠ¤ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤. """
        self._ensure_buffers(td) # load_idx_tensor ìµœì‹ í™”
        return len(self.load_idx_tensor), self.load_idx_tensor

    def _set_seed(self, seed: Optional[int] = None):
        if seed is not None:
            torch.manual_seed(seed)

    def _reset(self, td: Optional[TensorDict] = None, **kwargs) -> TensorDict:
        """ í™˜ê²½ì„ ì´ˆê¸° ìƒíƒœ(State)ë¡œ ë¦¬ì…‹í•©ë‹ˆë‹¤. """

        # [ì¶”ê°€] 'init_td' í‚¤ì›Œë“œ ì¸ìê°€ ìˆìœ¼ë©´ ê·¸ê²ƒì„ ì…ë ¥ ë°ì´í„°ë¡œ ì‚¬ìš©
        # (EnvBase.resetì˜ ì—„ê²©í•œ shape checkë¥¼ ìš°íšŒí•˜ê¸° ìœ„í•¨)
        if td is None and "init_td" in kwargs:
            td = kwargs["init_td"]

        batch_size = kwargs.get("batch_size", self.batch_size)
        current_epoch = kwargs.get("current_epoch", None) # [ì¶”ê°€] Trainerì—ì„œ ì „ë‹¬ë°›ìŒ

        if td is None:
            if isinstance(batch_size, tuple): batch_size = batch_size[0]
            # batch_sizeê°€ torch.Size ê°ì²´ì¼ ê²½ìš° intë¡œ ë³€í™˜
            if isinstance(batch_size, torch.Size):
                 batch_size = batch_size[0] if len(batch_size) > 0 else 1

            td_initial = self.generator(batch_size=batch_size).to(self.device)
        else:
            td_initial = td
            batch_size = td_initial.batch_size[0]

        num_nodes = self.N_max

        # --- 1. ë™ì  ìƒíƒœ í…ì„œ ì´ˆê¸°í™” ---
        
        # adj_matrix: (B, N_max, N_max) - ì‹¤ì œ ì—°ê²°ëœ ì—£ì§€ (ëª¨ë‘ 0)
        adj_matrix = torch.zeros(batch_size, num_nodes, num_nodes, dtype=torch.bool, device=self.device)
        adj_matrix_T = torch.zeros(batch_size, num_nodes, num_nodes, dtype=torch.bool, device=self.device)

        # is_active_mask: (B, N_max) - í˜„ì¬ í™œì„±í™”ëœ ë…¸ë“œ (ì •ì  í”¼ì²˜ì—ì„œ ë³µì‚¬)
        is_active_mask = td_initial["nodes"][..., FEATURE_INDEX["is_active"]].bool()
        # (ì •ì  í”¼ì²˜ì—ì„œ ë™ì  ë§ˆìŠ¤í¬ë¡œ ë³µì‚¬)
        is_template_mask = td_initial["nodes"][..., FEATURE_INDEX["is_template"]].bool()
        can_spawn_into_mask = td_initial["nodes"][..., FEATURE_INDEX["can_spawn_into"]].bool()

        # unconnected_loads_mask: (B, N_max) - ì•„ì§ ì—°ê²° ì•ˆ ëœ ë¡œë“œ
        node_types = td_initial["nodes"][0, :, FEATURE_INDEX["node_type"][0]:FEATURE_INDEX["node_type"][1]].argmax(-1)
        unconnected_loads_mask = (node_types == NODE_TYPE_LOAD).unsqueeze(0).expand(batch_size, -1)
        
        # next_empty_slot_idx: (B, 1) - ë‹¤ìŒ ìŠ¤í° ìœ„ì¹˜ (BATT+LOADS+TEMPLATES ê°œìˆ˜)
        next_empty_slot_idx = torch.full((batch_size, 1), self.generator.num_components, dtype=torch.long, device=self.device)

        # 2. TensorDict ìƒì„±
        reset_td = TensorDict({
            # ì •ì  í…ì„œ (Generatorë¡œë¶€í„° ë³µì‚¬)
            "nodes": td_initial["nodes"].clone(),
            "scalar_prompt_features": td_initial["scalar_prompt_features"],
            "matrix_prompt_features": td_initial["matrix_prompt_features"],
            "connectivity_matrix": td_initial["connectivity_matrix"],
            "attention_mask": td_initial["attention_mask"],
            
            # ë™ì  í…ì„œ (ì´ˆê¸°í™”)
            "adj_matrix": adj_matrix,
            "adj_matrix_T": adj_matrix_T,
            "unconnected_loads_mask": unconnected_loads_mask,
            "is_active_mask": is_active_mask,
            "is_template_mask": is_template_mask,
            "can_spawn_into_mask": can_spawn_into_mask,
            "next_empty_slot_idx": next_empty_slot_idx,
            "trajectory_head": torch.full((batch_size, 1), BATTERY_NODE_IDX, dtype=torch.long, device=self.device),
            "step_count": torch.zeros(batch_size, 1, dtype=torch.long, device=self.device),
            "current_cost": torch.zeros(batch_size, 1, dtype=torch.float32, device=self.device),
            "staging_cost": torch.zeros(batch_size, 1, dtype=torch.float32, device=self.device),
            "sleep_cost": torch.zeros(batch_size, 1, dtype=torch.float32, device=self.device),
            "is_used_ic_mask": torch.zeros(batch_size, num_nodes, dtype=torch.bool, device=self.device),
            "current_target_load": torch.full((batch_size, 1), -1, dtype=torch.long, device=self.device),
            "is_exclusive_mask": torch.zeros(batch_size, num_nodes, dtype=torch.long, device=self.device),
            "done": torch.zeros(batch_size, 1, dtype=torch.bool, device=self.device),
        }, batch_size=[batch_size], device=self.device)
       
        self._ensure_buffers(reset_td)
        return reset_td

    @torch.no_grad()
    def step(self, tensordict: TensorDict) -> TensorDict:
        """ _stepì„ í˜¸ì¶œ (torchrl EnvBase í˜¸í™˜ìš©) """
        return self._step(tensordict)

    def _step(self, td: TensorDict) -> TensorDict:
        """
        ëª¨ë¸ì´ ê²°ì •í•œ Parameterized Actionì„ ì‹¤í–‰í•˜ì—¬
        í™˜ê²½ì˜ ìƒíƒœ(State)ë¥¼ ë‹¤ìŒ ìŠ¤í…ìœ¼ë¡œ ì „ì´ì‹œí‚µë‹ˆë‹¤.
        
        - (ì•¡ì…˜ íƒ€ì… 0: Connect) -> ê¸°ì¡´ í™œì„± ë…¸ë“œì— ì—°ê²°
        - (ì•¡ì…˜ íƒ€ì… 1: Spawn)   -> í…œí”Œë¦¿ì„ Empty ìŠ¬ë¡¯ì— ë³µì‚¬(Spawn) í›„ ì—°ê²°
        """
        batch_size, num_nodes = td["nodes"].shape[0], self.N_max
        action_dict = td["action"]
        
        # (B,)
        action_type = action_dict["action_type"].squeeze(-1)
        connect_target = action_dict["connect_target"].squeeze(-1)
        spawn_template = action_dict["spawn_template"].squeeze(-1)
        
        current_head = td["trajectory_head"].squeeze(-1)  # (B,)


        # --- 0. ì´ë¯¸ 'done'ì¸ ë°°ì¹˜ëŠ” ë¬´ì‹œ ---
        is_already_done = td["done"].squeeze(-1)
        if is_already_done.all():
            return TensorDict({
                "next": td, 
                "reward": torch.zeros(batch_size, 1, device=self.device), 
                "done": td["done"]}, batch_size=td.batch_size)

        # --- 1. ìƒíƒœ í…ì„œ ì¤€ë¹„ (í•„ìš”í•œ ê²ƒë§Œ ì„ íƒ ë³µì‚¬) ---
        # ì „ì²´ td.clone() ì œê±° â†’ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì ˆê°
        next_obs = TensorDict({}, batch_size=td.batch_size, device=self.device)

        # 1-1. ì—í”¼ì†Œë“œ ë™ì•ˆ ë³€í•˜ì§€ ì•ŠëŠ” ì •ì  í…ì„œë“¤ì€ ì°¸ì¡°ë§Œ ê³µìœ 
        #      (clone ë¶ˆí•„ìš”, í° í–‰ë ¬ ì¬í• ë‹¹ ë°©ì§€)
        if "scalar_prompt_features" in td.keys():
            next_obs["scalar_prompt_features"] = td["scalar_prompt_features"]
        if "matrix_prompt_features" in td.keys():
            next_obs["matrix_prompt_features"] = td["matrix_prompt_features"]
        if "attention_mask" in td.keys():
            next_obs["attention_mask"] = td["attention_mask"]

        # âš  connectivity_matrixëŠ” Spawn ì‹œ in-placeë¡œ ê°±ì‹ ë˜ë¯€ë¡œ í˜„ì¬ êµ¬ì¡°ì—ì„œëŠ”
        #   ë™ì  í…ì„œ ì·¨ê¸‰ì´ í•„ìš”í•˜ë‹¤. (ì •ì ìœ¼ë¡œ ë§Œë“¤ë ¤ë©´ ì¶”ê°€ ë¦¬íŒ©í„°ë§ í•„ìš”)

        # 1-2. ì‹¤ì œë¡œ ìŠ¤í…ë§ˆë‹¤ ë³€í•˜ëŠ” ë™ì  í…ì„œë“¤ë§Œ clone()
        next_obs["nodes"] = td["nodes"].clone()  # (ê°€ì¥ ì¤‘ìš”)
        next_obs["adj_matrix"] = td["adj_matrix"].clone()
        next_obs["adj_matrix_T"] = td["adj_matrix_T"].clone()
        if "connectivity_matrix" in td.keys():
            next_obs["connectivity_matrix"] = td["connectivity_matrix"].clone()

        next_obs["unconnected_loads_mask"] = td["unconnected_loads_mask"].clone()
        next_obs["is_active_mask"] = td["is_active_mask"].clone()
        next_obs["is_template_mask"] = td["is_template_mask"].clone()
        next_obs["can_spawn_into_mask"] = td["can_spawn_into_mask"].clone()
        next_obs["next_empty_slot_idx"] = td["next_empty_slot_idx"].clone()

        next_obs["trajectory_head"] = td["trajectory_head"].clone()

        next_obs["step_count"] = td["step_count"].clone()
        next_obs["current_cost"] = td["current_cost"].clone()
        next_obs["staging_cost"] = td["staging_cost"].clone()
        next_obs["sleep_cost"] = td.get("sleep_cost", torch.zeros_like(td["current_cost"])).clone()
        next_obs["is_used_ic_mask"] = td["is_used_ic_mask"].clone()
        next_obs["current_target_load"] = td["current_target_load"].clone()
        if "is_exclusive_mask" in td.keys():
            next_obs["is_exclusive_mask"] = td["is_exclusive_mask"].clone()

        # doneì€ ì•„ë˜ì—ì„œ ìƒˆë¡œ ê³„ì‚°í•˜ì§€ë§Œ, 'ì´ë¯¸ doneì¸ ë°°ì¹˜ ë¡¤ë°±'ì—ì„œ ì‚¬ìš©ë˜ë¯€ë¡œ ë¨¼ì € ë³µì‚¬
        if "done" in td.keys():
            next_obs["done"] = td["done"].clone()
        else:
            next_obs["done"] = torch.zeros_like(td["step_count"], dtype=torch.bool)

        step_reward = torch.full((batch_size,), STEP_PENALTY, dtype=torch.float32, device=self.device)
        batch_indices = torch.arange(batch_size, device=self.device)
        bom_reward_batch = torch.zeros(batch_size, 1, dtype=torch.float32, device=self.device)

        # --- 2. ì•¡ì…˜ íƒ€ì… ë¶„ê¸° ---
        
        # --- 2a. [Select New Load] ---
        # (í˜„ì¬ í—¤ë“œê°€ ë°°í„°ë¦¬ì¼ ë•Œ)
        head_is_battery = (current_head == BATTERY_NODE_IDX)
        if head_is_battery.any():
            # 'Select New Load' ì•¡ì…˜ì€ 'Connect' ì•¡ì…˜ìœ¼ë¡œ ì „ë‹¬ë¨
            b_idx_batt = batch_indices[head_is_battery]
            selected_load = connect_target[head_is_battery]

            is_load_selection = (selected_load != BATTERY_NODE_IDX)
            if is_load_selection.any():
                load_rows = b_idx_batt[is_load_selection]
                load_node_idx = selected_load[is_load_selection]
                
                # Headë¥¼ ì„ íƒëœ Loadë¡œ ì´ë™
                next_obs["trajectory_head"][load_rows, 0] = load_node_idx
                # 'ì—°ê²° ì•ˆ ë¨' ë§ˆìŠ¤í¬ì—ì„œ ì œê±°
                next_obs["unconnected_loads_mask"][load_rows, load_node_idx] = False
                # í˜„ì¬ ê²½ë¡œì˜ ìµœì¢… íƒ€ê²Ÿìœ¼ë¡œ ì„¤ì •
                next_obs["current_target_load"][load_rows, 0] = load_node_idx
                # ê²½ë¡œ ë¹„ìš© ì´ˆê¸°í™”
                next_obs["staging_cost"][load_rows] = 0.0
                
                # 'ë…ë¦½ ë ˆì¼' ìƒíƒœ ì „íŒŒ ì‹œì‘
                # (B_load,)
                rail_status = self.rail_types_tensor[load_node_idx]
                next_obs["is_exclusive_mask"][load_rows, load_node_idx] = rail_status

        # --- 2b. [Find Parent / Spawn] ---
        # (í˜„ì¬ í—¤ë“œê°€ Load ë˜ëŠ” ICì¼ ë•Œ)
        head_is_node = ~head_is_battery
        if head_is_node.any():
            b_idx_node = batch_indices[head_is_node]
            child_node = current_head[head_is_node] # (B_node,)
            
            # (B_node,)
            is_connect = (action_type[head_is_node] == 0)
            is_spawn = ~is_connect
            
            # (B_node,) - ìµœì¢… ë¶€ëª¨ê°€ ë  ë…¸ë“œì˜ ì¸ë±ìŠ¤
            parent_node = torch.zeros_like(child_node)
            
            # --- Connect ì•¡ì…˜ ì²˜ë¦¬ ---
            if is_connect.any():
                b_idx_connect = b_idx_node[is_connect]
                # 'Connect' í—¤ë“œì—ì„œ ë¶€ëª¨ ì¸ë±ìŠ¤ ê°€ì ¸ì˜¤ê¸°
                parent_connect = connect_target[b_idx_connect]
                parent_node[is_connect] = parent_connect
            
            # --- Spawn ì•¡ì…˜ ì²˜ë¦¬ ---
            if is_spawn.any():
                b_idx_spawn = b_idx_node[is_spawn]
                child_spawn = child_node[is_spawn]
                
                # 'Spawn' í—¤ë“œì—ì„œ í…œí”Œë¦¿ ì¸ë±ìŠ¤ ê°€ì ¸ì˜¤ê¸°
                template_idx = spawn_template[b_idx_spawn] # (B_spawn,)
                # ìŠ¤í°ë  ë¹ˆ ìŠ¬ë¡¯ ì¸ë±ìŠ¤ ê°€ì ¸ì˜¤ê¸°
                # NOTE:
                #   next_empty_slot_idx í…ì„œëŠ” ì´í›„ ìŠ¤í° ë¡œì§ì—ì„œ in-placeë¡œ +1 ê°±ì‹ ëœë‹¤.
                #   clone() ì—†ì´ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ë©´, ì•„ë˜ì—ì„œ next_empty_slot_idxë¥¼ ìˆ˜ì •í•  ë•Œ
                #   autogradê°€ ì €ì¥í•´ ë‘” slot_idx ì¸ë±ìŠ¤ê°€ ë³€ê²½ë˜ì–´ "modified by an inplace"
                #   ì˜¤ë¥˜ê°€ ë°œìƒí•œë‹¤. ì•ˆì „í•˜ê²Œ ë³„ë„ ë³µì‚¬ë³¸ì„ ì‚¬ìš©í•œë‹¤.
                slot_idx = next_obs["next_empty_slot_idx"][b_idx_spawn].clone().squeeze(-1) # (B_spawn,)

                # 1. Spawn: í…œí”Œë¦¿ í”¼ì²˜ -> ë¹ˆ ìŠ¬ë¡¯ìœ¼ë¡œ ë³µì‚¬
                template_features = next_obs["nodes"][b_idx_spawn, template_idx]
                next_obs["nodes"][b_idx_spawn, slot_idx] = template_features.detach()

                # Spawnëœ ìŠ¬ë¡¯ì€ í…œí”Œë¦¿ê³¼ ë™ì¼í•œ ì „ì•• í˜¸í™˜ì„±ì„ ê°€ì ¸ì•¼ í•˜ë¯€ë¡œ
                # connectivity_matrixì˜ í–‰/ì—´ì„ í…œí”Œë¦¿ì—ì„œ ë³µì‚¬í•œë‹¤.
                connectivity_matrix = next_obs["connectivity_matrix"]
                connectivity_matrix[b_idx_spawn, :, slot_idx] = connectivity_matrix[b_idx_spawn, :, template_idx]
                connectivity_matrix[b_idx_spawn, slot_idx, :] = connectivity_matrix[b_idx_spawn, template_idx, :]

                # 2. ìƒíƒœ ë³€ê²½: (Template -> Active)
                next_obs["nodes"][b_idx_spawn, slot_idx, FEATURE_INDEX["is_active"]] = 1.0
                next_obs["nodes"][b_idx_spawn, slot_idx, FEATURE_INDEX["is_template"]] = 0.0
                next_obs["nodes"][b_idx_spawn, slot_idx, FEATURE_INDEX["can_spawn_into"]] = 0.0

                # ğŸš¨ ìˆ˜ì • 2: ë…¸ë“œ íƒ€ì… One-Hot í•„ë“œë¥¼ IC íƒ€ì…ìœ¼ë¡œ í™•ì •í•©ë‹ˆë‹¤.
                node_type_idx_start = FEATURE_INDEX["node_type"][0]
                node_type_idx_end = FEATURE_INDEX["node_type"][1]

                # ê¸°ì¡´ ì›-í•« ì¸ì½”ë”© í•„ë“œë¥¼ 0ìœ¼ë¡œ ì´ˆê¸°í™”
                next_obs["nodes"][b_idx_spawn, slot_idx, node_type_idx_start:node_type_idx_end] = 0.0
                # IC íƒ€ì…(3)ì„ 1.0ìœ¼ë¡œ ì„¤ì •
                next_obs["nodes"][b_idx_spawn, slot_idx, node_type_idx_start + NODE_TYPE_IC] = 1.0

                # 3. í™˜ê²½ ë™ì  ë§ˆìŠ¤í¬ ì—…ë°ì´íŠ¸
                next_obs["is_active_mask"][b_idx_spawn, slot_idx] = True
                next_obs["is_template_mask"][b_idx_spawn, slot_idx] = False
                next_obs["can_spawn_into_mask"][b_idx_spawn, slot_idx] = False

                # 4. ë‹¤ìŒ ë¹ˆ ìŠ¬ë¡¯ ì¸ë±ìŠ¤ +1 (In-place ë°©ì§€: += ëŒ€ì‹  = ... + 1 ì‚¬ìš©)
                # (Autograd ì˜¤ë¥˜ ìˆ˜ì •: modified by an inplace operation)
                next_obs["next_empty_slot_idx"][b_idx_spawn] = \
                    next_obs["next_empty_slot_idx"][b_idx_spawn] + 1
                
                # 5. ìŠ¤í° ë¹„ìš©(cost) ì¦‰ì‹œ ë°˜ì˜
                template_cost = next_obs["nodes"][b_idx_spawn, template_idx, FEATURE_INDEX["cost"]]
                staging_cost_increase = template_cost.unsqueeze(-1) # (B_spawn, 1)
                
                # staging_cost ë° current_costì— ìŠ¤í° ë¹„ìš© ì¶”ê°€
                next_obs["staging_cost"][b_idx_spawn] += staging_cost_increase
                next_obs["current_cost"][b_idx_spawn] += staging_cost_increase
                
                # R_action ë³´ìƒ (ìŠ¤í° ì¦‰ì‹œ)
                step_reward[b_idx_spawn] += REWARD_WEIGHT_ACTION * (-staging_cost_increase.squeeze(-1))
                
                # 'is_used_ic_mask'ì— í…œí”Œë¦¿ ì¸ë±ìŠ¤ ëŒ€ì‹  *ìŠ¤í°ëœ ìŠ¬ë¡¯ ì¸ë±ìŠ¤*ë¥¼ ê¸°ë¡
                next_obs["is_used_ic_mask"][b_idx_spawn, slot_idx] = True
                
                # 6. ìµœì¢… ë¶€ëª¨ë¥¼ 'ìŠ¤í°ëœ ìŠ¬ë¡¯'ìœ¼ë¡œ ì„¤ì •
                parent_node[is_spawn] = slot_idx

            # --- 3. ê³µí†µ ì—°ê²° ë¡œì§ (Connect/Spawn ê³µí†µ) ---
            
            # 3a. ì—£ì§€ ì¶”ê°€: (parent_node) -> (child_node)
            next_obs["adj_matrix"][b_idx_node, parent_node, child_node] = True
            # (Tì—ë„ ì—£ì§€ ì¶”ê°€: (child_node) -> (parent_node))
            next_obs["adj_matrix_T"][b_idx_node, child_node, parent_node] = True

            # 3b. 'ë…ë¦½ ë ˆì¼' ìƒíƒœ ì „íŒŒ (ìì‹ -> ë¶€ëª¨)
            child_status = next_obs["is_exclusive_mask"][b_idx_node, child_node] # (B_node,)
            if (child_status > 0).any():
                parent_status = next_obs["is_exclusive_mask"][b_idx_node, parent_node]
                
                # 'Path'(2)ëŠ” ICë¥¼ íƒ€ê³  ê³„ì† ì „íŒŒë¨
                status_to_propagate = torch.where(
                    child_status == 2, 
                    child_status, 
                    torch.tensor(0, device=self.device, dtype=torch.long)
                )
                
                # 'Supplier'(1)ëŠ” Loadì—ì„œ ì‹œì‘í•  ë•Œë§Œ ì „íŒŒë¨
                is_child_load = (self.node_type_tensor[child_node] == NODE_TYPE_LOAD)
                status_from_supplier = torch.where(
                    (child_status == 1) & is_child_load,
                    child_status,
                    torch.tensor(0, device=self.device, dtype=torch.long)
                )
                
                status_from_child = torch.max(status_to_propagate, status_from_supplier)
                new_parent_status = torch.max(parent_status, status_from_child)
                next_obs["is_exclusive_mask"][b_idx_node, parent_node] = new_parent_status
                next_obs["nodes"][b_idx_node, parent_node, FEATURE_INDEX["independent_rail_type"]] = new_parent_status.float()

            # --- [ì¶”ê°€] 3c. 'Always-On' ìƒíƒœ ì „íŒŒ (ìì‹ -> ë¶€ëª¨) ---
            # ìì‹ì´ ì˜ ë•Œë„ ì¼œì ¸ì•¼ í•œë‹¤ë©´(AO), ë¶€ëª¨ë„ ë¬´ì¡°ê±´ ì¼œì ¸ ìˆì–´ì•¼ í•¨(AO).
            # ëª¨ë¸ì—ê²Œ "ì´ ë¶€ëª¨ëŠ” ì´ë¯¸ ê¹¨ì–´ìˆìŒ(Penalty Pre-paid)"ì„ ì•Œë ¤ì£¼ì–´ ê·¸ë£¹í™”ë¥¼ ìœ ë„í•¨.
            child_is_ao = next_obs["nodes"][b_idx_node, child_node, FEATURE_INDEX["always_on_in_sleep"]]
            
            # (ì´ë¯¸ 1.0ì´ë©´ ìœ ì§€, ì•„ë‹ˆë©´ ìì‹ ìƒíƒœì— ë”°ë¼ 1.0ìœ¼ë¡œ ë³€ê²½)
            current_parent_ao = next_obs["nodes"][b_idx_node, parent_node, FEATURE_INDEX["always_on_in_sleep"]]
            new_parent_ao = torch.max(current_parent_ao, child_is_ao)
            next_obs["nodes"][b_idx_node, parent_node, FEATURE_INDEX["always_on_in_sleep"]] = new_parent_ao


            # 3d. ë‹¤ìŒ Head ì„¤ì •
            parent_is_battery = (parent_node == BATTERY_NODE_IDX)
            
            # í—¤ë“œ(parent_node)ê°€ ì´ë¯¸ ë¶€ëª¨ë¥¼ ê°€ì¡ŒëŠ”ì§€ í™•ì¸
            # adj_matrix_T[b, node, :]ê°€ 1ì´ë¼ë„ ìˆìœ¼ë©´, nodeëŠ” ì´ë¯¸ ë¶€ëª¨ê°€ ìˆìŒ
            parent_already_has_parent = next_obs["adj_matrix_T"][b_idx_node, parent_node].any(dim=-1)
            
            # ë°°í„°ë¦¬ì— ë„ë‹¬í•˜ê±°ë‚˜, ì´ë¯¸ ì—°ê²°ëœ ë…¸ë“œì— ë„ë‹¬í•˜ë©´ ê²½ë¡œ ì™„ì„±
            path_is_finished = parent_is_battery | parent_already_has_parent

            next_obs["trajectory_head"][b_idx_node, 0] = torch.where(
                path_is_finished,  # ğŸ’¡ ì¡°ê±´ ë³€ê²½
                BATTERY_NODE_IDX,  # ê²½ë¡œê°€ ëë‚¬ìœ¼ë©´ ë°°í„°ë¦¬ë¡œ ë³µê·€
                parent_node        # ì•„ë‹ˆë©´ ê²½ë¡œ ì¶”ì  ê³„ì†
            )
            
            # 3e. ê²½ë¡œ ì™„ì„± (R_path ë³´ìƒ) [ìˆ˜ì •]
            # parent_is_battery ëŒ€ì‹  path_is_finished ì¡°ê±´ì„ ì‚¬ìš©í•˜ì—¬
            # ê¸°ì¡´ íŠ¸ë¦¬ì— ì—°ê²°ëœ ê²½ìš°(parent_already_has_parent)ì—ë„ ë¹„ìš©ì„ ì •ì‚°í•˜ë„ë¡ ë³€ê²½


            if path_is_finished.any():
                finished_rows = b_idx_node[path_is_finished]
                
                # ê²½ë¡œ ì™„ì„± ì‹œ, ëˆ„ì ëœ staging_cost(BOM)ë¥¼ R_path ë³´ìƒìœ¼ë¡œ ì¶”ê°€
                sub_trajectory_total_cost = next_obs["staging_cost"][finished_rows]
                
                # [ìˆ˜ì •] ê°€ê²©ì— ê°€ì¤‘ì¹˜(WEIGHT_BOM)ë¥¼ ê³±í•´ ë¯¼ê°ë„ ì¦ê°€
                # Costê°€ ë†’ì„ìˆ˜ë¡(-) RewardëŠ” ë‚®ì•„ì§
                weighted_cost = WEIGHT_BOM * sub_trajectory_total_cost.squeeze(-1)
                
                r_bom = - REWARD_WEIGHT_PATH * weighted_cost
                step_reward[finished_rows] += r_bom
                bom_reward_batch[finished_rows] = r_bom.unsqueeze(-1) # ê¸°ë¡     

                # staging_cost ë¦¬ì…‹
                next_obs["staging_cost"][finished_rows] = 0.0
                next_obs["current_target_load"][finished_rows, 0] = -1

        # --- 4. ì „ë ¥/ë°œì—´ ì¬ê³„ì‚° (ì—°ì‚° ë¹„ìš© ë†’ìŒ) ---
        # (ëª¨ë“  ë°°ì¹˜ê°€ ìµœì†Œ 1ìŠ¤í… ì´ìƒ ì§„í–‰í–ˆì„ ë•Œë§Œ ê³„ì‚°)
        if td["step_count"].min() > 0 or head_is_node.any():
            final_i_out, power_loss, new_temp = self._calculate_tree_loads(
                next_obs["nodes"], 
                next_obs["adj_matrix"],
                next_obs["adj_matrix_T"] # ğŸ’¡ adj_matrix_T ì „ë‹¬
            )
            next_obs["nodes"][..., FEATURE_INDEX["current_out"]] = final_i_out
            next_obs["nodes"][..., FEATURE_INDEX["junction_temp"]] = new_temp
        
        next_obs.set("step_count", td["step_count"] + 1)

        # --- 5. ì¢…ë£Œ ì¡°ê±´ í™•ì¸ ---
        # (get_action_maskê°€ 3ì¢… ë§ˆìŠ¤í¬ë¥¼ ëª¨ë‘ ë°˜í™˜í•œë‹¤ê³  ê°€ì •)
        next_masks = self.get_action_mask(next_obs)
        # Connect/Spawn ë‘˜ ë‹¤ ë¶ˆê°€ëŠ¥í•œ ê²½ìš°
        is_stuck = ~(next_masks["mask_type"].any(dim=-1))
        
        all_loads_connected = (next_obs["unconnected_loads_mask"].sum(dim=1) == 0)
        trajectory_finished = (next_obs["trajectory_head"].squeeze(-1) == BATTERY_NODE_IDX)
        
        done_successfully = all_loads_connected & trajectory_finished
        max_steps = 2 * self.N_max # ìµœëŒ€ ìŠ¤í… ì œí•œ
        timed_out = (next_obs["step_count"] > max_steps).squeeze(-1)
        
        is_done = done_successfully | timed_out | is_stuck
        next_obs["done"] = is_done.unsqueeze(-1)

        # --- 6. ìµœì¢… ë³´ìƒ ê³„ì‚° ---
        final_reward, sleep_penalty_val, fail_penalty_val = self.get_reward(
            next_obs, step_reward, done_successfully, timed_out, is_stuck
        )
        # [ì¶”ê°€] í˜ë„í‹° ê°’ì„ ìƒíƒœì— ì €ì¥
        next_obs["sleep_cost"] = sleep_penalty_val.unsqueeze(-1)
        next_obs["log_reward_bom"] = bom_reward_batch
        next_obs["log_reward_sleep"] = -sleep_penalty_val.unsqueeze(-1)
        next_obs["log_reward_fail"] = fail_penalty_val.unsqueeze(-1)

        # ì´ë¯¸ 'done'ì´ì—ˆë˜ ìƒ˜í”Œì€ ë³´ìƒ 0, ìƒíƒœ ë¡¤ë°±
        if is_already_done.any():
            final_reward[is_already_done] = 0.0
            next_obs[is_already_done] = td[is_already_done]

        return TensorDict({
            "next": next_obs,
            "reward": final_reward.unsqueeze(-1),
            "done": next_obs["done"],
        }, batch_size=batch_size)
        
    def get_reward(self,
                   td: TensorDict,
                   step_reward: torch.Tensor,
                   done_successfully: torch.Tensor,
                   timed_out: torch.Tensor,
                   is_stuck: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]: # [ìˆ˜ì •] ë¦¬í„´ íƒ€ì… ë³€ê²½

        """
        ìµœì¢… ìŠ¤í… ë³´ìƒì„ ê³„ì‚°í•©ë‹ˆë‹¤.
        (ê¸°ë³¸ ìŠ¤í… ë³´ìƒ + ì„±ê³µ ì‹œ ì•”ì „ë¥˜ í˜ë„í‹° or ì‹¤íŒ¨ ì‹œ í˜ë„í‹°)
        """
        reward = step_reward.clone()
        sleep_penalty_record = torch.zeros_like(reward) # [ì¶”ê°€] í˜ë„í‹° ê¸°ë¡ìš©
        fail_penalty_record = torch.zeros_like(reward) # [ğŸš¨ ì¶”ê°€]

        # 1. ì„±ê³µí•œ ê²½ìš°: ì•”ì „ë¥˜ ì œì•½ ì¡°ê±´ ì ìš© (Hinge Loss + Step Penalty)
        #    "ì˜ˆì‚° ì´ë‚´ë©´ 0, ì´ˆê³¼í•˜ë©´ (ì°¨ì´ * ê°€ì¤‘ì¹˜ + ê³ ì •ë²Œê¸ˆ)"
        if done_successfully.any():
            td_success = td[done_successfully]
            
            total_sleep_current = self._calculate_total_sleep_current(td_success)
            
            # (ìŠ¤ì¹¼ë¼ í”„ë¡¬í”„íŠ¸ 1ë²ˆ ì¸ë±ìŠ¤ = max_sleep_current)
            max_sleep_current = td_success["scalar_prompt_features"][:, 1]
            
            # 1. ìœ„ë°˜ëŸ‰ ê³„ì‚° (ReLU: ì´ë‚´ë©´ 0, ì´ˆê³¼ë©´ ì–‘ìˆ˜)
            violation_amount = torch.relu(total_sleep_current - max_sleep_current)
            is_violated = (violation_amount > 1e-9).float() # ì•„ì£¼ ì‘ì€ ì˜¤ì°¨ ë¬´ì‹œ
            
            # 2. í˜ë„í‹° ê³„ì‚°: (ìœ„ë°˜ëŸ‰ * ê°€ì¤‘ì¹˜) + ê³ ì • ë²Œê¸ˆ
            #    * íŒ: ìœ„ë°˜ëŸ‰ì´ í´ìˆ˜ë¡ ë” ì•„í”„ê²Œ í•˜ë ¤ë©´ ì œê³±ì„ í•´ë„ ë¨ (violation_amount ** 2)
            #    ì—¬ê¸°ì„œëŠ” 1ì°¨ ë¹„ë¡€(Linear) + ê³ ì •ë²Œê¸ˆ ë°©ì‹ì„ ì‚¬ìš© (ì¶©ë¶„íˆ ê°•ë ¥í•¨)
            proportional_penalty = PENALTY_SLEEP_WEIGHT * violation_amount
            step_penalty = PENALTY_SLEEP_STEP * is_violated
            
            total_sleep_penalty = proportional_penalty + step_penalty
            
            # rewardì— ë°˜ì˜ (ê°ì )
            reward[done_successfully] -= total_sleep_penalty

            # í˜ë„í‹° ê¸°ë¡ (ë¡œê¹…ìš©)
            sleep_penalty_record[done_successfully] = total_sleep_penalty

        # 2. ì‹¤íŒ¨í•œ ê²½ìš°: ê³ ì • í˜ë„í‹°
        failed = (timed_out | is_stuck) & ~done_successfully
        if failed.any():
            reward[failed] = FAILURE_PENALTY
            fail_penalty_record[failed] = FAILURE_PENALTY # [ğŸš¨ ì¶”ê°€]
            
        return reward, sleep_penalty_record, fail_penalty_record

    # ---
    # ì„¹ì…˜ 5: ì•¡ì…˜ ë§ˆìŠ¤í‚¹ (ì—°ì‚° ì§‘ì•½ì )
    # ---

    @torch.no_grad()
    def get_action_mask(self, td: TensorDict, debug: bool = False) -> Dict[str, torch.Tensor]:
        """
        í˜„ì¬ ìƒíƒœ(td)ì—ì„œ ê°€ëŠ¥í•œ ëª¨ë“  ì•¡ì…˜ì„ ê³„ì‚°í•˜ì—¬
        3ì¢…ë¥˜ì˜ ë§ˆìŠ¤í¬ ë”•ì…”ë„ˆë¦¬ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
        
        Returns:
            {
                "mask_type": (B, 2) - [Can_Connect, Can_Spawn]
                "mask_connect": (B, N_max) - ì—°ê²° ê°€ëŠ¥í•œ ë¶€ëª¨(Active)
                "mask_spawn": (B, N_max) - ìŠ¤í° ê°€ëŠ¥í•œ í…œí”Œë¦¿(Template)
            }
        """
        self._ensure_buffers(td) # ë²„í¼ ìµœì‹ í™”

        batch_size, num_nodes = td.batch_size[0], self.N_max
        current_head = td["trajectory_head"].squeeze(-1)  # (B,)

        # --- 1. ê¸°ë³¸ ìƒíƒœ ë§ˆìŠ¤í¬ (ì €ë¹„ìš©) ---
        is_active = td["is_active_mask"] # (B, N_max) - í˜„ì¬ í™œì„± ë…¸ë“œ
        is_template = td["is_template_mask"] # (B, N_max) - í…œí”Œë¦¿ ë…¸ë“œ
        
        # --- 2. [Select New Load] ëª¨ë“œ ë§ˆìŠ¤í‚¹ ---
        head_is_battery = (current_head == BATTERY_NODE_IDX)
        if debug:
            reasons = {}

        # (B, 2)
        mask_type = torch.zeros(batch_size, 2, dtype=torch.bool, device=self.device)
        # (B, N_max)
        mask_connect = torch.zeros(batch_size, num_nodes, dtype=torch.bool, device=self.device)
        # (B, N_max)
        mask_spawn = torch.zeros(batch_size, num_nodes, dtype=torch.bool, device=self.device)

        if head_is_battery.any():
            b_idx_batt = torch.where(head_is_battery)[0]
            
            # ë°°í„°ë¦¬ì—ì„œëŠ” 'Connect'ë§Œ ê°€ëŠ¥
            mask_type[b_idx_batt, 0] = True 
            
            # 'Connect' ëŒ€ìƒì€ 'unconnected_loads_mask'
            mask_connect[b_idx_batt] = td["unconnected_loads_mask"][b_idx_batt]
            
            # ë§Œì•½ ëª¨ë“  ë¡œë“œê°€ ì—°ê²°ë˜ì—ˆìœ¼ë©´ (unconnected.sum() == 0),
            # 'BATTERY_NODE_IDX' (0ë²ˆ)ì— ì—°ê²°í•˜ì—¬ ì¢…ë£Œ ì‹ í˜¸
            all_connected = (td["unconnected_loads_mask"][b_idx_batt].sum(dim=-1) == 0)
            if all_connected.any():
                b_idx_finish = b_idx_batt[all_connected]
                mask_connect[b_idx_finish, BATTERY_NODE_IDX] = True
        
            if debug:
                reasons["mask_type"] = mask_type[b_idx_batt]
                reasons["mask_connect"] = mask_connect[b_idx_batt]

        # --- 3. [Find Parent / Spawn] ëª¨ë“œ ë§ˆìŠ¤í‚¹ (ê³ ë¹„ìš©) ---
        head_is_node = ~head_is_battery
        if head_is_node.any():
            b_idx_node = torch.where(head_is_node)[0]
            child_nodes = current_head[b_idx_node] # (B_node,)
            B_act = len(b_idx_node) # ì‹¤ì œ ì—°ì‚°í•  ë°°ì¹˜ í¬ê¸°
            
            # --- 3a. ì €ë¹„ìš© ë§ˆìŠ¤í¬ (ì „ì••, ì‚¬ì´í´, ë…ë¦½, ì‹œí€€ì‹±) ---
            
            # (B_act, N_max)
            connectivity = td["connectivity_matrix"][b_idx_node]
            volt_ok = connectivity[torch.arange(B_act), :, child_nodes]
            
            # (B_act, N_max)
            path_mask = self._trace_path_batch(child_nodes, td["adj_matrix_T"][b_idx_node])
            cycle_ok = ~path_mask            


            # (B_act, N_max)
            exclusive_ok = self._get_exclusive_mask(
                td,           # ğŸ’¡ 'td' ì „ë‹¬
                b_idx_node,   # ğŸ’¡ 'b_idx_node' ì „ë‹¬
                child_nodes
            )
            
            # (B_act, N_max)
            power_seq_ok = self._get_power_sequence_mask(
                td["adj_matrix"][b_idx_node],
                child_nodes,
                td,           
                b_idx_node    
            )
            
            # (B_act, N_max) - ëª¨ë“  ì €ë¹„ìš© ì œì•½ì„ í†µê³¼í•œ í›„ë³´
            base_valid_parents = volt_ok & cycle_ok & exclusive_ok & power_seq_ok
            
            # --- 3b. ê³ ë¹„ìš© ë§ˆìŠ¤í¬ (ì „ë¥˜/ë°œì—´ ì‹œë®¬ë ˆì´ì…˜) ---
            
            # (B_act, N_max) - ì‹œë®¬ë ˆì´ì…˜ìœ¼ë¡œ ê²€ì¦ëœ ìµœì¢… ìœ íš¨ ë¶€ëª¨
            thermal_current_ok = self._get_thermal_current_mask(
                td,
                b_idx_node,
                child_nodes,
                base_valid_parents # ì‹œë®¬ë ˆì´ì…˜ ëŒ€ìƒì„ ì¤„ì´ê¸° ìœ„í•´ ì €ë¹„ìš© ë§ˆìŠ¤í¬ ì „ë‹¬
            )
            
            final_valid_parents = base_valid_parents & thermal_current_ok
            
            # --- 3c. ìµœì¢… 3ì¢… ë§ˆìŠ¤í¬ ìƒì„± ---
            
            # 'Connect' ëŒ€ìƒ: ìµœì¢… ìœ íš¨ ë¶€ëª¨ + 'Active' ìƒíƒœ
            mask_connect[b_idx_node] = final_valid_parents & is_active[b_idx_node]
            
            # 'Spawn' ëŒ€ìƒ: ìµœì¢… ìœ íš¨ ë¶€ëª¨ + 'Template' ìƒíƒœ
            mask_spawn[b_idx_node] = final_valid_parents & is_template[b_idx_node]
            
            # 'Type' ë§ˆìŠ¤í¬
            can_connect = mask_connect[b_idx_node].any(dim=-1) # (B_node,)
            
            # (ìŠ¤í°ì€ ë¹ˆ ìŠ¬ë¡¯ì´ ë‚¨ì•„ìˆì–´ì•¼ ê°€ëŠ¥)
            has_empty_slots = (td["next_empty_slot_idx"][b_idx_node] < self.N_max)
            can_spawn = mask_spawn[b_idx_node].any(dim=-1) & has_empty_slots.squeeze(-1)
            
            mask_type[b_idx_node, 0] = can_connect
            mask_type[b_idx_node, 1] = can_spawn
            
            if debug:
                # (ë””ë²„ê·¸ ì •ë³´ëŠ” b_idx_node[0] (0ë²ˆ ìƒ˜í”Œ) ê¸°ì¤€ìœ¼ë¡œë§Œ ìˆ˜ì§‘)
                if 0 in b_idx_node:
                    reasons["volt_ok"] = volt_ok[0]
                    reasons["cycle_ok"] = cycle_ok[0]
                    reasons["exclusive_ok"] = exclusive_ok[0]
                    reasons["power_seq_ok"] = power_seq_ok[0]
                    reasons["base_valid_parents"] = base_valid_parents[0]
                    reasons["thermal_current_ok"] = thermal_current_ok[0]
                    reasons["final_valid_parents"] = final_valid_parents[0]
        # âœ… [ìˆ˜ì •] debug í”Œë˜ê·¸ì— ë”°ë¼ ë°˜í™˜ê°’ ë¶„ê¸° (return ìœ„ì¹˜ ìˆ˜ì •)
        if debug:
            return {
                "mask_type": mask_type,
                "mask_connect": mask_connect,
                "mask_spawn": mask_spawn,
                "reasons": reasons # ë””ë²„ê·¸ ì •ë³´ ë°˜í™˜
            }
        else:
            return {
                "mask_type": mask_type,
                "mask_connect": mask_connect,
                "mask_spawn": mask_spawn,
            }

    # ---
    # ì„¹ì…˜ 6: ë§ˆìŠ¤í‚¹ í—¬í¼ í•¨ìˆ˜ 
    # ---

    def _trace_path_batch(self, start_nodes: torch.Tensor, adj_matrix_T: torch.Tensor) -> torch.Tensor:
        """ start_nodesì˜ ëª¨ë“  ì¡°ìƒ(ancestors)ì„ ì°¾ì•„ ë§ˆìŠ¤í¬ë¡œ ë°˜í™˜ (ì‚¬ì´í´ ë°©ì§€ìš©) """
        batch_size, num_nodes, _ = adj_matrix_T.shape
        path_mask = torch.zeros(batch_size, num_nodes, dtype=torch.bool, device=self.device)

        if start_nodes.numel() > 0:
            path_mask.scatter_(1, start_nodes.unsqueeze(-1), True)
        
        adj_matrix_T_float = adj_matrix_T.float()

        for _ in range(num_nodes):
            # (B,N,N) @ (B,N,1) -> (B,N)
            parents_mask = (adj_matrix_T_float @ path_mask.float().unsqueeze(-1)).squeeze(-1).bool()
            if (parents_mask & ~path_mask).sum() == 0: break
            path_mask |= parents_mask
            
        return path_mask

    def _get_exclusive_mask(self, 
                            td: TensorDict,           # ğŸ’¡ 'td' ì¸ì ì¶”ê°€
                            b_idx_node: torch.Tensor, # ğŸ’¡ 'b_idx_node' ì¸ì ì¶”ê°€
                            child_nodes: torch.Tensor
                            ) -> torch.Tensor:
        """ ë…ë¦½ ë ˆì¼(Exclusive Rail) ì œì•½ì¡°ê±´ ë§ˆìŠ¤í¬ ìƒì„± """
        # (tdì™€ b_idx_nodeì—ì„œ í•„ìš”í•œ í…ì„œë¥¼ ê°€ì ¸ì˜´)
        is_exclusive_mask_batch = td["is_exclusive_mask"][b_idx_node]
        adj_matrix_batch = td["adj_matrix"][b_idx_node]
        B_act, N_nodes = is_exclusive_mask_batch.shape
        
        # 1. Head(Child)ì˜ ìƒíƒœadj_matrix_T
        head_status = is_exclusive_mask_batch[torch.arange(B_act), child_nodes] # (B_act,)
        node_type_indices_full = td["nodes"][b_idx_node, child_nodes, FEATURE_INDEX["node_type"][0]:FEATURE_INDEX["node_type"][1]].argmax(-1)
        head_is_load = (node_type_indices_full == NODE_TYPE_LOAD) # (B_act,)

        # 2. Parent(í›„ë³´)ì˜ ìƒíƒœ
        parent_status = is_exclusive_mask_batch # (B_act, N_nodes)
        parent_is_exclusive = (parent_status > 0)
        
        # (B_act, N_nodes) - ë¶€ëª¨ê°€ ì´ë¯¸ ìì‹ì„ ê°€ì¡ŒëŠ”ì§€?
        parent_has_any_child = adj_matrix_batch.any(dim=-1)
        
        # 3. ìœ„ë°˜(Violation) ê·œì¹™ (True = ìœ„ë°˜ = ê¸ˆì§€)
        
        # ê·œì¹™ 1: Headê°€ 'Path'(2) -> ë¶€ëª¨ëŠ” ìì‹ì´ ì—†ì–´ì•¼ í•¨
        # (B_act, 1) & (B_act, N_nodes) -> (B_act, N_nodes)
        violation_Rule1 = (head_status.unsqueeze(-1) == 2) & parent_has_any_child
        
        # ê·œì¹™ 2: Headê°€ 'Supplier Load'(1) -> ë¶€ëª¨ëŠ” ìì‹ì´ ì—†ì–´ì•¼ í•¨
        violation_Rule2 = ((head_status == 1) & head_is_load).unsqueeze(-1) & parent_has_any_child
        
        # ê·œì¹™ 3: Headê°€ 'Normal'(0) ë˜ëŠ” 'Supplier IC'(1) -> ë¶€ëª¨ëŠ” Exclusiveì´ë©´ ì•ˆ ë¨
        violation_Rule3 = ((head_status == 0) | ((head_status == 1) & ~head_is_load)).unsqueeze(-1) & parent_is_exclusive
        
        violations = violation_Rule1 | violation_Rule2 | violation_Rule3
        
        # 4. ë°°í„°ë¦¬ëŠ” í•­ìƒ í—ˆìš©
        is_battery_mask = (self.arange_nodes.unsqueeze(0) == BATTERY_NODE_IDX)
        exclusive_ok = torch.logical_not(violations) | is_battery_mask
        
        return exclusive_ok

    def _get_power_sequence_mask(self,
                                 adj_matrix_batch: torch.Tensor,
                                 child_nodes: torch.Tensor,
                                 td: TensorDict,           
                                 b_idx_node: torch.Tensor  
                                 ) -> torch.Tensor:
        """ ì „ì› ì‹œí€€ì‹±(Power Sequence) ì œì•½ì¡°ê±´ ë§ˆìŠ¤í¬ ìƒì„± """
        B_act, N_nodes, _ = adj_matrix_batch.shape
        adj_matrix_T_batch = td["adj_matrix_T"][b_idx_node]
        candidate_mask = torch.ones(B_act, N_nodes, dtype=torch.bool, device=self.device)

        for j_idx, k_idx, f_flag in self.power_sequences:
            # Case 1: í˜„ì¬ childê°€ 'k' (jì˜ ë¶€ëª¨ë¥¼ ì°¾ëŠ” ì¤‘)
            is_k_mask = (child_nodes == k_idx)
            if is_k_mask.any():
                b_idx_check = torch.where(is_k_mask)[0] # (B_k,)
                
                # 'j'ì˜ ë¶€ëª¨ê°€ ì´ë¯¸ ì¡´ì¬í•˜ëŠ”ê°€?
                parent_of_j_exists = adj_matrix_batch[b_idx_check, :, j_idx].any(dim=-1) # (B_k,)
                
                if parent_of_j_exists.any():
                    b_constr = b_idx_check[parent_of_j_exists] # (B_constr,)
                    
                    # 'j'ì˜ ë¶€ëª¨ ì¸ë±ìŠ¤ 
                    parent_of_j_idx = adj_matrix_batch[b_constr, :, j_idx].long().argmax(-1) # (B_constr,)
                    
                    # 'j'ì˜ ë¶€ëª¨(parent_of_j)ì˜ ëª¨ë“  ì¡°ìƒ(ancestors)ì„ ì°¾ìŒ
                    anc_mask = self._trace_path_batch(parent_of_j_idx, adj_matrix_T_batch[b_constr])
                    anc_mask[:, BATTERY_NODE_IDX] = False # ë°°í„°ë¦¬ ì œì™¸
                    
                    # 'k'ì˜ ë¶€ëª¨ëŠ” 'j'ì˜ ì¡°ìƒì´ ë  ìˆ˜ ì—†ìŒ
                    candidate_mask[b_constr] &= ~anc_mask
                    
                    # (f=1) 'k'ì˜ ë¶€ëª¨ëŠ” 'j'ì˜ ë¶€ëª¨ì™€ ê°™ì„ ìˆ˜ ì—†ìŒ
                    if f_flag == 1:
                        same_parent_mask = (self.arange_nodes == parent_of_j_idx.unsqueeze(1))
                        candidate_mask[b_constr] &= ~same_parent_mask

            # Case 2: í˜„ì¬ childê°€ 'j' (kì˜ ë¶€ëª¨ë¥¼ ì°¾ëŠ” ì¤‘)
            is_j_mask = (child_nodes == j_idx)
            if is_j_mask.any():
                b_idx_check = torch.where(is_j_mask)[0]
                parent_of_k_exists = adj_matrix_batch[b_idx_check, :, k_idx].any(dim=-1)
                
                if parent_of_k_exists.any():
                    b_constr = b_idx_check[parent_of_k_exists]
                    parent_of_k_idx = adj_matrix_batch[b_constr, :, k_idx].long().argmax(-1)
                    
                    anc_mask = self._trace_path_batch(parent_of_k_idx, adj_matrix_T_batch[b_constr])
                    anc_mask[:, BATTERY_NODE_IDX] = False
                    
                    # 'j'ì˜ ë¶€ëª¨ëŠ” 'k'ì˜ ì¡°ìƒì´ ë  ìˆ˜ ì—†ìŒ
                    candidate_mask[b_constr] &= ~anc_mask
                    
                    if f_flag == 1:
                        same_parent_mask = (self.arange_nodes == parent_of_k_idx.unsqueeze(1))
                        candidate_mask[b_constr] &= ~same_parent_mask
                        
        return candidate_mask
    
    @torch.no_grad()
    def _get_thermal_current_mask(self,
                                  td: TensorDict,
                                  b_idx_node: torch.Tensor,
                                  child_nodes: torch.Tensor,
                                  base_valid_parents: torch.Tensor) -> torch.Tensor:
        """
        ì „ë¥˜/ë°œì—´ í•œê³„ë¥¼ ë§Œì¡±í•˜ëŠ”ì§€ ì‹œë®¬ë ˆì´ì…˜í•˜ì—¬ ë§ˆìŠ¤í¬ ìƒì„±.
        (ì—°ì‚° ë¹„ìš©ì´ ê°€ì¥ ë†’ì€ í•¨ìˆ˜)
        """
        
        # (B_act, N_max)
        thermal_current_ok = base_valid_parents.clone()
        
        # ì‹œë®¬ë ˆì´ì…˜ ì²­í¬ í¬ê¸° (ë©”ëª¨ë¦¬/ì†ë„ íŠ¸ë ˆì´ë“œì˜¤í”„)
        SIM_CHUNK_SIZE = 8
        
        B_act, N_nodes = base_valid_parents.shape
        
        base_nodes = td["nodes"][b_idx_node]
        base_adj_matrix = td["adj_matrix"][b_idx_node]
        base_adj_matrix_T = td["adj_matrix_T"][b_idx_node]
        
        # ë§ˆì§„(Margin) ê°’ ë¯¸ë¦¬ ë¡œë“œ
        margin_I = float(self.generator.config.constraints.get("current_margin", 0.0))
        THERMAL_MARGIN_DEG = float(self.generator.config.constraints.get("thermal_margin_deg", 5.0))        

        """ ì˜ë¯¸ì—†ëŠ” ë¶€ë¶„ì¸ë“¯ ì‚­ì œí•´ë„ ë ì§€ë„ 
        # (N_max,) - IC íƒ€ì… ë§ˆìŠ¤í¬
        ic_mask_1d = (self.node_type_tensor == NODE_TYPE_IC)
        """
        # (N_max) í¬ê¸°ì˜ ì²­í¬ë¡œ ë‚˜ëˆ„ì–´ ì‹œë®¬ë ˆì´ì…˜
        for chunk_start in range(0, N_nodes, SIM_CHUNK_SIZE):
            chunk_end = min(chunk_start + SIM_CHUNK_SIZE, N_nodes)
            parent_indices_in_chunk = torch.arange(chunk_start, chunk_end, device=self.device)
            
            # (B_act, N_chunk) - ì´ë²ˆ ì²­í¬ì—ì„œ ì‹œë®¬ë ˆì´ì…˜í•  (ë°°ì¹˜, ë¶€ëª¨) í›„ë³´
            candidates_in_chunk_mask = base_valid_parents[:, chunk_start:chunk_end]
            
            # (N_sim,) - (B_act ê¸°ì¤€ ì¸ë±ìŠ¤, ë¡œì»¬ ë¶€ëª¨ ì¸ë±ìŠ¤)
            b_idx_sim_chunk, p_idx_sim_chunk_local = candidates_in_chunk_mask.nonzero(as_tuple=True)
            
            if b_idx_sim_chunk.numel() == 0:
                continue # ì‹œë®¬ë ˆì´ì…˜í•  í›„ë³´ ì—†ìŒ
            
            N_sim = b_idx_sim_chunk.numel()
            
            # 1. ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° ì¤€ë¹„ (N_sim,)
            sim_nodes = base_nodes[b_idx_sim_chunk]
            sim_adj_matrix = base_adj_matrix[b_idx_sim_chunk].clone()
            sim_adj_matrix_T = base_adj_matrix_T[b_idx_sim_chunk].clone()
            sim_child_nodes = child_nodes[b_idx_sim_chunk]
            
            # (N_sim,) - ì‹¤ì œ ë¶€ëª¨ ë…¸ë“œ ì¸ë±ìŠ¤
            sim_parent_indices_global = parent_indices_in_chunk[p_idx_sim_chunk_local]
            
            # 2. (ê°€ìƒ) ì—£ì§€ ì¶”ê°€: (parent) -> (child)
            sim_rows = torch.arange(N_sim, device=self.device)
            sim_adj_matrix[sim_rows, sim_parent_indices_global, sim_child_nodes] = True
            sim_adj_matrix_T[sim_rows, sim_child_nodes, sim_parent_indices_global] = True

            # 3. ğŸš€ íŠ¸ë¦¬ ì „ì²´ ë¶€í•˜ ì‹œë®¬ë ˆì´ì…˜
            (final_i_out, power_loss, junction_temp) = self._calculate_tree_loads(
                sim_nodes, 
                sim_adj_matrix,
                sim_adj_matrix_T # ğŸ’¡ T ë§¤íŠ¸ë¦­ìŠ¤ ì „ë‹¬
            )

            # 4. ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ ê²€ì¦
            i_limit = sim_nodes[..., FEATURE_INDEX["i_limit"]] * (1.0 - margin_I)
            t_max_raw = sim_nodes[..., FEATURE_INDEX["t_junction_max"]]
            t_max = t_max_raw - THERMAL_MARGIN_DEG            
            
            # (N_sim, N_max)
            current_check_ok = (final_i_out <= i_limit + 1e-6)
            temp_check_ok = (junction_temp <= t_max + 1e-6)
            
            # (N_sim, N_max)
            all_checks_ok = current_check_ok & temp_check_ok
            
            # (N_sim, N_max) - ICê°€ ì•„ë‹Œ ë…¸ë“œëŠ” í•­ìƒ OK
            ic_type_indices = sim_nodes[..., FEATURE_INDEX["node_type"][0]:FEATURE_INDEX["node_type"][1]].argmax(-1)
            ic_mask_sim = (ic_type_indices == NODE_TYPE_IC)   

            # [ìˆ˜ì •] ê²€ì¦ ëŒ€ìƒ í•„í„°ë§: "í˜„ì¬ Active ë…¸ë“œ" + "ì´ë²ˆ ì‹œë®¬ë ˆì´ì…˜ì˜ í›„ë³´ ë¶€ëª¨"ë§Œ ê²€ì‚¬
            # (ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ë‹¤ë¥¸ í…œí”Œë¦¿ë“¤ì´ ê³ ì˜¨ì—ì„œ FAIL ëœ¨ëŠ” ê²ƒì„ ë¬´ì‹œí•˜ê¸° ìœ„í•¨)
            relevant_mask = td["is_active_mask"][b_idx_sim_chunk].clone()
            
            sim_rows = torch.arange(N_sim, device=self.device)
            relevant_mask[sim_rows, sim_parent_indices_global] = True
            
            # (N_sim,) - (ê´€ë ¨ëœ ëª¨ë“  ICê°€ OKì—¬ì•¼ í•¨. ê´€ë ¨ ì—†ìœ¼ë©´ ë¬´ì‹œ)
            is_valid_simulation = (all_checks_ok | ~ic_mask_sim | ~relevant_mask).all(dim=-1)

            # 5. ì‹¤íŒ¨í•œ ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ë¥¼ (B_act, N_max) ë§ˆìŠ¤í¬ì— ë°˜ì˜
            failed_sim_mask = ~is_valid_simulation
            if failed_sim_mask.any():
                b_idx_failed = b_idx_sim_chunk[failed_sim_mask]
                p_idx_failed_global = sim_parent_indices_global[failed_sim_mask]
                thermal_current_ok[b_idx_failed, p_idx_failed_global] = False
                
        return thermal_current_ok

    # ---
    # ì„¹ì…˜ 7: ê³„ì‚° í—¬í¼ í•¨ìˆ˜ 
    # ---

    @torch.no_grad()
    def _calculate_tree_loads(self, 
                              nodes_tensor: torch.Tensor, 
                              adj_matrix: torch.Tensor,
                              adj_matrix_T: torch.Tensor
                              ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:
        """ Adjacency Matrixë¥¼ ê¸°ë°˜ìœ¼ë¡œ íŠ¸ë¦¬ ì „ì²´ì˜ ì „ë¥˜/ì „ë ¥ì†ì‹¤/ì˜¨ë„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤. """
        
        batch_size, num_nodes, _ = nodes_tensor.shape
        
        # 1. ì´ˆê¸° ìˆ˜ìš” = Loadì˜ í™œì„± ì „ë¥˜
        current_demands = nodes_tensor[..., FEATURE_INDEX["current_active"]].clone()
        
        # Loadê°€ ì•„ë‹Œ ë…¸ë“œëŠ” ì´ˆê¸° ìˆ˜ìš”ê°€ 0
        load_mask_1d = (self.node_type_tensor == NODE_TYPE_LOAD) # (N_max,)
        current_demands[:, ~load_mask_1d] = 0.0
        
        adj_matrix_float = adj_matrix.float()
        adj_matrix_T_float = adj_matrix_T.float()

        # (IC íƒ€ì…, LDO/Buck)
        ic_type = nodes_tensor[..., FEATURE_INDEX["ic_type_idx"]]
        ldo_mask_b = torch.isclose(ic_type, torch.tensor(1.0, device=ic_type.device))
        buck_mask_b = torch.isclose(ic_type, torch.tensor(2.0, device=ic_type.device))
        
        op_current = nodes_tensor[..., FEATURE_INDEX["op_current"]]
        vout = nodes_tensor[..., FEATURE_INDEX["vout_min"]] # (ê³ ì • Vout)
        vin = nodes_tensor[..., FEATURE_INDEX["vin_min"]]  # (ê³ ì • Vin)
        safe_vin = torch.where(vin > 0, vin, 1e-6)

        # [ì¶”ê°€] í…ì„œì—ì„œ íš¨ìœ¨ ë° í”¼ë“œë°± ì €í•­ ë¡œë“œ
        eff_active = nodes_tensor[..., FEATURE_INDEX["efficiency_active"]]
        safe_eff_active = torch.where(eff_active > 0, eff_active, 0.9)

        min_fb_res = nodes_tensor[..., FEATURE_INDEX["min_fb_res"]]
        fb_current = torch.zeros_like(vout) # í”¼ë“œë°±ì „ë¥˜ 0 ìœ¼ë¡œ ì´ˆê¸°í™” 
        valid_res_mask = (min_fb_res > 1e-6) # í”¼ë“œë°± ì €í•­ì´ ìˆëŠ”ê²½ìš° í”¼ë“œë°± ì €í•­ìœ¼ë¡œ ì¸í•œ ì „ë¥˜ ê³„ì‚°. 
        fb_current[valid_res_mask] = vout[valid_res_mask] / min_fb_res[valid_res_mask] 

        # 2. ì „ë¥˜ ì „íŒŒ (Bottom-up)
        # (i_in_totalì€ (B, N_max)ë¡œ, ê° ë…¸ë“œê°€ *ì†Œë¹„*í•˜ëŠ” ì´ ì „ë¥˜)
        i_in_total = current_demands.clone() 

        for _ in range(num_nodes):
            # i_out (B, N_max) = ì´ ë…¸ë“œê°€ ìì‹ë“¤ì—ê²Œ *ê³µê¸‰*í•´ì•¼ í•˜ëŠ” ì´ ì „ë¥˜
            # i_out = (B,N,N) @ (B,N,1) -> (B,N)
            i_out = (adj_matrix_float @ i_in_total.unsqueeze(-1)).squeeze(-1)            

            # I_in_ldo/buck (B, N_max) = ì´ ë…¸ë“œê°€ *ê³µê¸‰*í•˜ê¸° ìœ„í•´ *ì†Œë¹„*í•´ì•¼ í•˜ëŠ” ì „ë¥˜
            # LDO Input Current: I_in = I_out + I_fb + I_op
            i_in_ldo = i_out + fb_current + op_current
            
            # Buck Input Current: I_in = (Vout * (I_out + I_fb) / Eff) / Vin + I_op
            p_out_buck = vout * (i_out + fb_current)
            i_in_buck = (p_out_buck / safe_eff_active) / safe_vin
            
            # (B, N_max) - IC ë…¸ë“œë“¤ì˜ ì´ ì…ë ¥ ìˆ˜ìš”
            new_ic_demands = torch.zeros_like(i_in_total)
            new_ic_demands[ldo_mask_b] = i_in_ldo[ldo_mask_b]
            new_ic_demands[buck_mask_b] = i_in_buck[buck_mask_b]

            new_i_in_total = current_demands + new_ic_demands
            if torch.allclose(i_in_total, new_i_in_total, atol=1e-8):
                break
            i_in_total = new_i_in_total

        i_out = (adj_matrix_float @ i_in_total.unsqueeze(-1)).squeeze(-1)
            
        # 3. ìµœì¢… ì†ì‹¤ ë° ì˜¨ë„ ê³„ì‚°
        power_loss = self._calculate_power_loss(
            nodes_tensor, i_out, ldo_mask_b, buck_mask_b
        )
        theta_ja = nodes_tensor[..., FEATURE_INDEX["theta_ja"]]
        ambient_temp = self.generator.config.constraints.get("ambient_temperature", 25.0)
        junction_temp = ambient_temp + power_loss * theta_ja
        
        return i_out, power_loss, junction_temp

    def _calculate_power_loss(self, 
                              ic_node_features: torch.Tensor, 
                              i_out: torch.Tensor,
                              ldo_mask: torch.Tensor,
                              buck_mask: torch.Tensor
                              ) -> torch.Tensor:
        """ I_outì„ ê¸°ë°˜ìœ¼ë¡œ ICì˜ ì „ë ¥ ì†ì‹¤(P_loss)ì„ ê³„ì‚°í•©ë‹ˆë‹¤. """
        
        vin = ic_node_features[..., FEATURE_INDEX["vin_min"]]
        vout = ic_node_features[..., FEATURE_INDEX["vout_min"]]
        op_current = ic_node_features[..., FEATURE_INDEX["op_current"]]

        # [ì¶”ê°€] í”¼ë“œë°± ì „ë¥˜ ê³„ì‚° (ì†ì‹¤ì— í¬í•¨)
        min_fb_res = ic_node_features[..., FEATURE_INDEX["min_fb_res"]]
        fb_current = torch.zeros_like(vout)
        valid_res_mask = (min_fb_res > 1e-6)
        fb_current[valid_res_mask] = vout[valid_res_mask] / min_fb_res[valid_res_mask]

        power_loss = torch.zeros_like(i_out, dtype=ic_node_features.dtype)
        
        # LDO: P_loss = (V_in - V_out) * (I_out + I_fb) + V_in * I_op
        if ldo_mask.any():
            power_loss[ldo_mask] = (vin[ldo_mask] - vout[ldo_mask]) * (i_out[ldo_mask] + fb_current[ldo_mask]) + \
                                   vin[ldo_mask] * op_current[ldo_mask]
        
        # Buck: P_loss = P_out * (1/Eff - 1)
        # (Active ìƒíƒœì—ì„œëŠ” íš¨ìœ¨ì— I_op ì†ì‹¤ì´ í¬í•¨ëœ ê²ƒìœ¼ë¡œ ê°€ì •í•˜ì—¬ ë³„ë„ í•©ì‚°í•˜ì§€ ì•ŠìŒ)
        if buck_mask.any():
            eff_active = ic_node_features[buck_mask, FEATURE_INDEX["efficiency_active"]]
            safe_eff = torch.where(eff_active > 0, eff_active, 0.9)
            p_out_buck = vout[buck_mask] * (i_out[buck_mask] + fb_current[buck_mask])
            conversion_loss = (p_out_buck / safe_eff) - p_out_buck
            power_loss[buck_mask] = conversion_loss 
            
        return power_loss
    
    @torch.no_grad()
    def _calculate_total_sleep_current(self, td: TensorDict) -> torch.Tensor:
        """ ì•”ì „ë¥˜(Sleep Current) ì œì•½ì¡°ê±´ì„ ê²€ì‚¬í•©ë‹ˆë‹¤. """
        
        batch_size, num_nodes, _ = td["nodes"].shape
        adj_matrix = td["adj_matrix"].float()
        adj_matrix_T = td["adj_matrix_T"].float() # ğŸ’¡ (c, p) -> (p, c)

        # 1. "Always-On" ìƒíƒœ ì „íŒŒ (Load -> Battery)
        always_on_loads = (td["nodes"][..., FEATURE_INDEX["always_on_in_sleep"]] == 1.0)
        always_on_nodes = always_on_loads.clone()
        always_on_nodes[:, BATTERY_NODE_IDX] = True
        
        for _ in range(num_nodes):
            parents_mask = (adj_matrix @ always_on_nodes.float().unsqueeze(-1)).squeeze(-1).bool()
            if (parents_mask & ~always_on_nodes).sum() == 0: break
            always_on_nodes |= parents_mask
        
        # 2. IC ìì²´ ì•”ì „ë¥˜ ì†Œëª¨ (3-State)
        is_ao = always_on_nodes
        is_used = td["is_used_ic_mask"]
        parent_is_ao = (adj_matrix_T @ is_ao.float().unsqueeze(-1)).squeeze(-1).bool()

        #op_current = td["nodes"][..., FEATURE_INDEX["op_current"]]
        quiescent_current = td["nodes"][..., FEATURE_INDEX["quiescent_current"]]
        shutdown_current = td["nodes"][..., FEATURE_INDEX["shutdown_current"]]
        
        use_ishut_current = torch.where(shutdown_current > 1e-9, shutdown_current, quiescent_current)
        ic_self_sleep = torch.zeros(batch_size, num_nodes, device=self.device)
        
        # [ìˆ˜ì •] AO ìƒíƒœ(Sleep Active)ì¼ ë•ŒëŠ” ëŒ€ê¸° ì „ë¥˜(Iq)ë§Œ ì†Œëª¨í•©ë‹ˆë‹¤.
        ic_self_sleep[is_ao & is_used] = quiescent_current[is_ao & is_used]
        # ë¹„-AOì§€ë§Œ ë¶€ëª¨ê°€ ì¼œì§„ ê²½ìš° (Shutdown/Standby)
        ic_self_sleep[~is_ao & is_used & parent_is_ao] = use_ishut_current[~is_ao & is_used & parent_is_ao]

        # [ì¶”ê°€] í”¼ë“œë°± ì „ë¥˜(Ifb) ê³„ì‚°
        vout = td["nodes"][..., FEATURE_INDEX["vout_min"]]
        min_fb_res = td["nodes"][..., FEATURE_INDEX["min_fb_res"]]
        fb_current_draw = torch.zeros_like(vout)
        valid_res_mask = (min_fb_res > 1e-6)
        fb_current_draw[valid_res_mask] = vout[valid_res_mask] / min_fb_res[valid_res_mask]
        fb_current_draw = fb_current_draw * always_on_nodes.float()
        
        shut_mask = ~is_ao & is_used & parent_is_ao
        ic_self_sleep[shut_mask] = shutdown_current[shut_mask]

        # 3. Load ì•”ì „ë¥˜ ì†Œëª¨
        load_sleep_draw_base = td["nodes"][..., FEATURE_INDEX["current_sleep"]].clone()
        load_sleep_draw = load_sleep_draw_base * always_on_nodes.float()
        load_sleep_draw[~always_on_nodes] = 0.0

        # 4. ì „ë¥˜ ìˆ˜ìš” ì „íŒŒ (LDO/Buck íš¨ìœ¨ ì ìš©)
        # current_demandsëŠ” "ìì²´ ì†Œëª¨(Iq/Load)" + "ìì‹ ë…¸ë“œ ê³µê¸‰ì„ ìœ„í•œ ì…ë ¥ ì „ë¥˜"
        current_demands_sleep = load_sleep_draw + ic_self_sleep
        
        # (B, N) ëª¨ì–‘ì˜ LDO/Buck ë§ˆìŠ¤í¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
        # (B, N)
        ic_type = td["nodes"][..., FEATURE_INDEX["ic_type_idx"]]
        
        # (B, N)
        ldo_mask_b = torch.isclose(ic_type, torch.tensor(1.0, device=ic_type.device))
        
        # (B, N)
        buck_mask_b = torch.isclose(ic_type, torch.tensor(2.0, device=ic_type.device))

        # (ì°¸ê³ : ic_mask_b_nì€ ì´ í•¨ìˆ˜ì—ì„œ ì‚¬ìš©ë˜ì§€ ì•Šìœ¼ë¯€ë¡œ ì‚­ì œí•˜ê±°ë‚˜ (B, N)ìœ¼ë¡œ ë§Œë“¤ì–´ì•¼ í•¨)
        # (B, N)
        # ic_mask_b_n = (self.node_type_tensor == NODE_TYPE_IC).expand(batch_size, -1)        
        
        vin = td["nodes"][..., FEATURE_INDEX["vin_min"]]
        #vout = td["nodes"][..., FEATURE_INDEX["vout_min"]]
        safe_vin = torch.where(vin > 0, vin, 1e-6)

        # [ì¶”ê°€] Sleep íš¨ìœ¨ í…ì„œ ë¡œë“œ
        eff_sleep_tensor = td["nodes"][..., FEATURE_INDEX["efficiency_sleep"]]
        safe_eff_sleep = torch.where(eff_sleep_tensor > 0, eff_sleep_tensor, 0.35)

        
        for _ in range(num_nodes):
            # i_out_sleep = ìì‹ë“¤ì˜ 'ì…ë ¥ ìˆ˜ìš”' ì´í•© (Child Demands -> Parent Load)
            # adj_matrix_T (C, P) -> Transpose (P, C) @ Demands (C) = Load (P)
            i_out_sleep = (adj_matrix_T.transpose(-1, -2) @ current_demands_sleep.unsqueeze(-1)).squeeze(-1)
            
            # ë‹¤ìŒ ì´í„°ë ˆì´ì…˜ì„ ìœ„í•œ ìˆ˜ìš” ì—…ë°ì´íŠ¸ (Base = Self Consumption)
            new_demands_sleep = load_sleep_draw + ic_self_sleep
            
            # LDO: I_in = I_out + I_fb
            # (í”¼ë“œë°± ì „ë¥˜ëŠ” ì…ë ¥ë‹¨ì—ì„œ ì§ì ‘ ì†Œëª¨)
            ldo_demand = i_out_sleep[ldo_mask_b] + fb_current_draw[ldo_mask_b]
            new_demands_sleep[ldo_mask_b] += ldo_demand            

            # âœ… [ìˆ˜ì •] Buck ì¶”ê°€ ìˆ˜ìš”: ë³€í™˜ëœ ì…ë ¥ ì „ë¥˜ (Switching Input)
            # I_in_switching = (P_out + P_fb) / (Eff * Vin)
            i_out_buck = i_out_sleep[buck_mask_b]
            if_fb_buck = fb_current_draw[buck_mask_b]
            
            p_out_total_buck = vout[buck_mask_b] * (i_out_buck + if_fb_buck)
            
            eff = safe_eff_sleep[buck_mask_b]

            # ë³€í™˜ëœ ì…ë ¥ ì „ë¥˜ ê³„ì‚°
            i_in_switching_buck = (p_out_total_buck / eff) / safe_vin[buck_mask_b]
            
            # Buckì˜ ì´ ìˆ˜ìš” = (Iq + Load) + Switching Input
            new_demands_sleep[buck_mask_b] += i_in_switching_buck
            
            if torch.allclose(current_demands_sleep, new_demands_sleep, atol=1e-8):
                break
            current_demands_sleep = new_demands_sleep

        # 5. ë°°í„°ë¦¬ ì´ ì•”ì „ë¥˜
        battery_children_mask = adj_matrix[:, BATTERY_NODE_IDX, :]
        total_sleep_current = (current_demands_sleep * battery_children_mask).sum(dim=1)
        
        return total_sleep_current # (B,)