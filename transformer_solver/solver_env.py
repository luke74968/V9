# Copyright (c) 2025 Minuk Lee. All rights reserved.
# 
# This source code is proprietary and confidential.
# Unauthorized copying of this file, via any medium is strictly prohibited.
# 
# For licensing terms, see the LICENSE file.
# Contact: minuklee@snu.ac.kr
# 
import torch
from tensordict import TensorDict
from torchrl.envs import EnvBase
from torchrl.data import Unbounded, UnboundedDiscrete, Composite
from typing import Optional, Dict, Union, Tuple, List

# --- í˜„ì¬ íŒ¨í‚¤ì§€(transformer_solver) ëª¨ë“ˆ ì„í¬íŠ¸ ---
from .definitions import (
    FEATURE_DIM, FEATURE_INDEX, SCALAR_PROMPT_FEATURE_DIM,
    NODE_TYPE_PADDING, NODE_TYPE_BATTERY, NODE_TYPE_LOAD, 
    NODE_TYPE_IC, NODE_TYPE_EMPTY
)
from .env_generator import PocatGenerator

# --- í™˜ê²½ ìƒìˆ˜ ---
BATTERY_NODE_IDX = 0 # ë°°í„°ë¦¬ ë…¸ë“œëŠ” í•­ìƒ 0ë²ˆ ì¸ë±ìŠ¤
REWARD_WEIGHT_ACTION = 0.0  # (A2C) ì•¡ì…˜(IC ìŠ¤í°) ì¦‰ì‹œ ë¹„ìš©ì— ëŒ€í•œ ê°€ì¤‘ì¹˜
REWARD_WEIGHT_PATH = 1.0    # (A2C) ê²½ë¡œ(Load->BATT) ì™„ì„± ì‹œ ëˆ„ì  ë¹„ìš© ê°€ì¤‘ì¹˜
STEP_PENALTY = 0.0          # (A2C) ìŠ¤í…ë‹¹ í˜ë„í‹°
FAILURE_PENALTY = -20000.0    # (A2C) ì‹¤íŒ¨(ë§‰ë‹¤ë¥¸ ê¸¸) í˜ë„í‹°

# 1. ê°€ê²©(BOM) ë¯¼ê°ë„ ê°€ì¤‘ì¹˜ (Cost Sensitivity)
#    ê¸°ë³¸ê°’ 1.0 -> 100.0ìœ¼ë¡œ ìƒí–¥ (0.01ë‹¬ëŸ¬ ì ˆì•½ = +1.0ì  ë³´ìƒ)
#    ì´ì œ ëª¨ë¸ì€ 1ì„¼íŠ¸(0.01) ì°¨ì´ë„ 1ì  ì°¨ì´ë¡œ í¬ê²Œ ëŠë‚ë‹ˆë‹¤.
WEIGHT_BOM = 100.0
# [ìˆ˜ì •] V9: ê°€ê²© ë¯¼ê°ë„ëŠ” ìœ ì§€í•˜ë˜, ì•”ì „ë¥˜ í˜ë„í‹° ê´€ë ¨ ìƒìˆ˜ ì œê±°

class PocatEnv(EnvBase):
    """
    Pocat ë¬¸ì œë¥¼ í’€ê¸° ìœ„í•œ ê°•í™”í•™ìŠµ í™˜ê²½(Environment)ì…ë‹ˆë‹¤.
    
    TensorDictë¥¼ ìƒíƒœ(State)ë¡œ ì‚¬ìš©í•˜ë©°, Parameterized Action(Connect/Spawn)ì„
    ì²˜ë¦¬í•˜ì—¬ ìƒíƒœë¥¼ ì „ì´ì‹œí‚¤ê³  ë³´ìƒ(Reward)ì„ ê³„ì‚°í•©ë‹ˆë‹¤.
    """
    """
    Pocat V9 í™˜ê²½ (Hard Constraint Version)
    
    íŠ¹ì§•:
    1. Phase 1 (Always-On Backbone): Always-On ë¶€í•˜ë“¤ì„ ìš°ì„ ì ìœ¼ë¡œ ì—°ê²°í•˜ì—¬ ì•”ì „ë¥˜ êµ¬ì¡°ë¥¼ ê²°ì •í•©ë‹ˆë‹¤.
    2. Hard Sleep Constraint: ë³´ìƒ í˜ë„í‹° ëŒ€ì‹ , Action Maskingì„ í†µí•´ ì˜ˆì‚°ì„ ì´ˆê³¼í•˜ëŠ” í–‰ë™ì„ ì›ì²œ ì°¨ë‹¨í•©ë‹ˆë‹¤.
    """
    
    name = "pocat_env"

    def __init__(self, generator_params: dict, device: str = "cpu", N_max: int = 500, **kwargs):
        """
        PocatEnvë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
        
        Args:
            generator_params (dict): PocatGeneratorì— ì „ë‹¬ë  íŒŒë¼ë¯¸í„°
            device (str): í…ì„œ ì—°ì‚°ì„ ìˆ˜í–‰í•  ë””ë°”ì´ìŠ¤
            N_max (int): ëª¨ë¸ì´ ì²˜ë¦¬í•  ê³ ì •ëœ ìµœëŒ€ ë…¸ë“œ í¬ê¸°
        """
        super().__init__(device=device)
        
        # 1. N_max ê°’ì„ ì €ì¥í•©ë‹ˆë‹¤.
        self.N_max = N_max
        
        # 2. ì œë„ˆë ˆì´í„° ì´ˆê¸°í™” (N_max ì „ë‹¬)
        self.generator = PocatGenerator(**generator_params, N_max=N_max)
        
        # 3. ë§ˆìŠ¤í‚¹ ë° ê³„ì‚°ì— ì‚¬ìš©í•  ë²„í¼ ë“±ë¡
        self.register_buffer("arange_nodes", None, persistent=False)
        self.register_buffer("node_type_tensor", None, persistent=False)
        self.register_buffer("load_idx_tensor", None, persistent=False)
        self.register_buffer("rail_types", None, persistent=False)

        # 4. Observation, Action ìŠ¤í™ ì •ì˜
        self._make_spec()

        # 5. ì œì•½ì¡°ê±´(ì‹œí€€ì‹±, ë…ë¦½) ì •ë³´ ë¡œë“œ
        self._load_constraint_info()

    def _make_spec(self):
        """í™˜ê²½ì˜ Observation, Action, Reward ìŠ¤í™ì„ ì •ì˜í•©ë‹ˆë‹¤."""

        num_nodes = self.N_max
        
        # 1. Observation ìŠ¤í™ ì •ì˜
        self.observation_spec = Composite({
            # --- ì •ì  í…ì„œ (Generator ì œê³µ) ---
            "nodes": Unbounded(shape=(num_nodes, FEATURE_DIM)),
            "scalar_prompt_features": Unbounded(shape=(SCALAR_PROMPT_FEATURE_DIM,)),
            "matrix_prompt_features": Unbounded(shape=(num_nodes, num_nodes)),
            "connectivity_matrix": Unbounded(shape=(num_nodes, num_nodes), dtype=torch.bool),
            "attention_mask": Unbounded(shape=(num_nodes, num_nodes), dtype=torch.bool),
            
            # --- ë™ì  í…ì„œ (Env ê´€ë¦¬) ---
            "adj_matrix": Unbounded(shape=(num_nodes, num_nodes), dtype=torch.bool),
            "adj_matrix_T": Unbounded(shape=(num_nodes, num_nodes), dtype=torch.bool),
            "unconnected_loads_mask": Unbounded(shape=(num_nodes,), dtype=torch.bool),
            "trajectory_head": UnboundedDiscrete(shape=(1,)),
            "step_count": UnboundedDiscrete(shape=(1,)),
            "current_cost": Unbounded(shape=(1,)),
            "staging_cost": Unbounded(shape=(1,)), # í˜„ì¬ ê²½ë¡œì˜ ëˆ„ì  ë¹„ìš©
            "sleep_cost": Unbounded(shape=(1,)), # (V9: ë¡œê¹…ìš©ìœ¼ë¡œ ìœ ì§€í•˜ê±°ë‚˜ 0 ì²˜ë¦¬)
    
            "log_reward_bom": Unbounded(shape=(1,)),
            # "log_reward_sleep": Unbounded(shape=(1,)), # ì œê±°
            "log_reward_fail": Unbounded(shape=(1,)),   
            
            "is_used_ic_mask": Unbounded(shape=(num_nodes,), dtype=torch.bool),
            "current_target_load": UnboundedDiscrete(shape=(1,)),
            "is_exclusive_mask": Unbounded(shape=(num_nodes,), dtype=torch.long),
            "next_empty_slot_idx": UnboundedDiscrete(shape=(1,)),
        })
        
        # 2. Action ìŠ¤í™ ì •ì˜ (Parameterized Action)
        self.action_spec = Composite({
            # (0: Connect, 1: Spawn)
            "action_type": UnboundedDiscrete(shape=(1,)),
            # (0 ~ N_max-1): Connect ëŒ€ìƒ
            "connect_target": UnboundedDiscrete(shape=(1,)),
            # (0 ~ N_max-1): Spawní•  í…œí”Œë¦¿
            "spawn_template": UnboundedDiscrete(shape=(1,)),
        })
        
        # 3. Reward ìŠ¤í™ ì •ì˜
        self.reward_spec = Unbounded(shape=(1,))

    def _load_constraint_info(self):
        """
        config íŒŒì¼ì—ì„œ ì œì•½ì¡°ê±´ ì •ë³´ë¥¼ ë¡œë“œí•˜ê³ 
        ë§ˆìŠ¤í‚¹ì— ì‚¬ìš©í•˜ê¸° ì‰½ë„ë¡ í…ì„œë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥í•©ë‹ˆë‹¤.
        """
        # (B,L,IC) ìˆœì„œê°€ í…ì„œ ìˆœì„œì™€ ì¼ì¹˜
        self.node_name_to_idx = {name: i for i, name in enumerate(self.generator.config.node_names)}
        
        # 1. Independent Rail (ë…ë¦½ ë ˆì¼) ì •ë³´
        rail_type_map = {"exclusive_supplier": 1, "exclusive_path": 2}
        rail_types_list = []

        # (Load ë…¸ë“œëŠ” 1ë²ˆ ì¸ë±ìŠ¤ë¶€í„° ì‹œì‘)
        load_start_idx = self.generator.num_battery
        for i, load_cfg in enumerate(self.generator.config.loads):
            load_idx = load_start_idx + i
            rail_type = rail_type_map.get(load_cfg.get("independent_rail_type"), 0)
            rail_types_list.append((load_idx, rail_type))
        
        # (N_max,) í¬ê¸°ì˜ í…ì„œë¡œ ë³€í™˜
        self.rail_types_tensor = torch.zeros(self.N_max, dtype=torch.long, device=self.device)
        if rail_types_list:
            indices = torch.tensor([idx for idx, _ in rail_types_list], dtype=torch.long, device=self.device)
            values = torch.tensor([val for _, val in rail_types_list], dtype=torch.long, device=self.device)
            self.rail_types_tensor.scatter_(0, indices, values)

        # 2. Power Sequence (ì „ì› ì‹œí€€ì‹±) ì •ë³´
        self.power_sequences = []
        for seq in self.generator.config.constraints.get("power_sequences", []):
            f_flag = seq.get("f", 1)
            j_idx = self.node_name_to_idx.get(seq['j'])
            k_idx = self.node_name_to_idx.get(seq['k'])
            if j_idx is not None and k_idx is not None:
                self.power_sequences.append((j_idx, k_idx, f_flag))

    def _ensure_buffers(self, td: TensorDict):
        """
        Observation í…ì„œê°€ ë³€ê²½ë  ë•Œë§ˆë‹¤(ì£¼ë¡œ _reset ì‹œ)
        ë§ˆìŠ¤í‚¹ ê³„ì‚°ì— í•„ìš”í•œ í—¬í¼ í…ì„œë“¤ì„ ë¯¸ë¦¬ ê³„ì‚°í•©ë‹ˆë‹¤.
        """
        num_nodes = td["nodes"].shape[1] # (N_max)

        if self.arange_nodes is None or self.arange_nodes.numel() != num_nodes:
            self.arange_nodes = torch.arange(num_nodes, device=self.device)
        
        if self.node_type_tensor is None:
            # (N_max,)
            node_types = td["nodes"][0, :, FEATURE_INDEX["node_type"][0]:FEATURE_INDEX["node_type"][1]].argmax(-1)
            self.node_type_tensor = node_types
            
            # (N_loads,)
            self.load_idx_tensor = torch.where(node_types == NODE_TYPE_LOAD)[0]

    def select_start_nodes(self, td: TensorDict) -> Tuple[int, torch.Tensor]:
        #[ìˆ˜ì •] POMO ì‹œì‘ ë…¸ë“œ ì„ íƒ ì‹œ, Phase 1 ì „ëµì— ë”°ë¼ Always-On Loadë¥¼ ìš°ì„  ë°˜í™˜í•©ë‹ˆë‹¤. 
        
        self._ensure_buffers(td) # load_idx_tensor ìµœì‹ í™”

        # Always-On ì†ì„± í™•ì¸ (B, N) -> (N,) ê°€ì • (ëª¨ë“  ìƒ˜í”Œì´ ë™ì¼ Configë¼ê³  ê°€ì •)
        # í•˜ì§€ë§Œ ë°°ì¹˜ë§ˆë‹¤ ë‹¤ë¥¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì²« ë²ˆì§¸ ìƒ˜í”Œ ê¸°ì¤€ìœ¼ë¡œ ì¶”ì¶œ
        ao_feature = td["nodes"][0, :, FEATURE_INDEX["always_on_in_sleep"]]
        is_ao_load = (ao_feature == 1.0) & (self.node_type_tensor == NODE_TYPE_LOAD)
        
        ao_load_indices = torch.where(is_ao_load)[0]
        
        if len(ao_load_indices) > 0:
            return len(ao_load_indices), ao_load_indices
        else:
            # AO ë¶€í•˜ê°€ ì—†ìœ¼ë©´ ëª¨ë“  ë¶€í•˜ ë°˜í™˜
            return len(self.load_idx_tensor), self.load_idx_tensor

    def _set_seed(self, seed: Optional[int] = None):
        if seed is not None:
            torch.manual_seed(seed)

    def _reset(self, td: Optional[TensorDict] = None, **kwargs) -> TensorDict:
        """ í™˜ê²½ì„ ì´ˆê¸° ìƒíƒœ(State)ë¡œ ë¦¬ì…‹í•©ë‹ˆë‹¤. """

        # [ì¶”ê°€] 'init_td' í‚¤ì›Œë“œ ì¸ìê°€ ìˆìœ¼ë©´ ê·¸ê²ƒì„ ì…ë ¥ ë°ì´í„°ë¡œ ì‚¬ìš©
        # (EnvBase.resetì˜ ì—„ê²©í•œ shape checkë¥¼ ìš°íšŒí•˜ê¸° ìœ„í•¨)
        if td is None and "init_td" in kwargs:
            td = kwargs["init_td"]

        batch_size = kwargs.get("batch_size", self.batch_size)
        if td is None:
            if isinstance(batch_size, tuple): batch_size = batch_size[0]
            # batch_sizeê°€ torch.Size ê°ì²´ì¼ ê²½ìš° intë¡œ ë³€í™˜
            if isinstance(batch_size, torch.Size):
                 batch_size = batch_size[0] if len(batch_size) > 0 else 1

            td_initial = self.generator(batch_size=batch_size).to(self.device)
        else:
            td_initial = td
            batch_size = td_initial.batch_size[0]

        num_nodes = self.N_max

        # --- 1. ë™ì  ìƒíƒœ í…ì„œ ì´ˆê¸°í™” ---
        
        # adj_matrix: (B, N_max, N_max) - ì‹¤ì œ ì—°ê²°ëœ ì—£ì§€ (ëª¨ë‘ 0)
        adj_matrix = torch.zeros(batch_size, num_nodes, num_nodes, dtype=torch.bool, device=self.device)
        adj_matrix_T = torch.zeros(batch_size, num_nodes, num_nodes, dtype=torch.bool, device=self.device)

        # is_active_mask: (B, N_max) - í˜„ì¬ í™œì„±í™”ëœ ë…¸ë“œ (ì •ì  í”¼ì²˜ì—ì„œ ë³µì‚¬)
        is_active_mask = td_initial["nodes"][..., FEATURE_INDEX["is_active"]].bool()
        # (ì •ì  í”¼ì²˜ì—ì„œ ë™ì  ë§ˆìŠ¤í¬ë¡œ ë³µì‚¬)
        is_template_mask = td_initial["nodes"][..., FEATURE_INDEX["is_template"]].bool()
        can_spawn_into_mask = td_initial["nodes"][..., FEATURE_INDEX["can_spawn_into"]].bool()

        # unconnected_loads_mask: (B, N_max) - ì•„ì§ ì—°ê²° ì•ˆ ëœ ë¡œë“œ
        node_types = td_initial["nodes"][0, :, FEATURE_INDEX["node_type"][0]:FEATURE_INDEX["node_type"][1]].argmax(-1)
        unconnected_loads_mask = (node_types == NODE_TYPE_LOAD).unsqueeze(0).expand(batch_size, -1)
        
        # next_empty_slot_idx: (B, 1) - ë‹¤ìŒ ìŠ¤í° ìœ„ì¹˜ (BATT+LOADS+TEMPLATES ê°œìˆ˜)
        next_empty_slot_idx = torch.full((batch_size, 1), self.generator.num_components, dtype=torch.long, device=self.device)

        # 2. TensorDict ìƒì„±
        reset_td = TensorDict({
            # ì •ì  í…ì„œ (Generatorë¡œë¶€í„° ë³µì‚¬)
            "nodes": td_initial["nodes"].clone(),
            "scalar_prompt_features": td_initial["scalar_prompt_features"],
            "matrix_prompt_features": td_initial["matrix_prompt_features"],
            "connectivity_matrix": td_initial["connectivity_matrix"],
            "attention_mask": td_initial["attention_mask"],
            
            # ë™ì  í…ì„œ (ì´ˆê¸°í™”)
            "adj_matrix": adj_matrix,
            "adj_matrix_T": adj_matrix_T,
            "unconnected_loads_mask": unconnected_loads_mask,
            "is_active_mask": is_active_mask,
            "is_template_mask": is_template_mask,
            "can_spawn_into_mask": can_spawn_into_mask,
            "next_empty_slot_idx": next_empty_slot_idx,
            "trajectory_head": torch.full((batch_size, 1), BATTERY_NODE_IDX, dtype=torch.long, device=self.device),
            "step_count": torch.zeros(batch_size, 1, dtype=torch.long, device=self.device),
            "current_cost": torch.zeros(batch_size, 1, dtype=torch.float32, device=self.device),
            "staging_cost": torch.zeros(batch_size, 1, dtype=torch.float32, device=self.device),
            "sleep_cost": torch.zeros(batch_size, 1, dtype=torch.float32, device=self.device),
            "is_used_ic_mask": torch.zeros(batch_size, num_nodes, dtype=torch.bool, device=self.device),
            "current_target_load": torch.full((batch_size, 1), -1, dtype=torch.long, device=self.device),
            "is_exclusive_mask": torch.zeros(batch_size, num_nodes, dtype=torch.long, device=self.device),
            "done": torch.zeros(batch_size, 1, dtype=torch.bool, device=self.device),
        }, batch_size=[batch_size], device=self.device)
       
        self._ensure_buffers(reset_td)
        return reset_td

    @torch.no_grad()
    def step(self, tensordict: TensorDict) -> TensorDict:
        """ _stepì„ í˜¸ì¶œ (torchrl EnvBase í˜¸í™˜ìš©) """
        return self._step(tensordict)

    def _step(self, td: TensorDict) -> TensorDict:
        """
        ëª¨ë¸ì´ ê²°ì •í•œ Parameterized Actionì„ ì‹¤í–‰í•˜ì—¬
        í™˜ê²½ì˜ ìƒíƒœ(State)ë¥¼ ë‹¤ìŒ ìŠ¤í…ìœ¼ë¡œ ì „ì´ì‹œí‚µë‹ˆë‹¤.
        
        - (ì•¡ì…˜ íƒ€ì… 0: Connect) -> ê¸°ì¡´ í™œì„± ë…¸ë“œì— ì—°ê²°
        - (ì•¡ì…˜ íƒ€ì… 1: Spawn)   -> í…œí”Œë¦¿ì„ Empty ìŠ¬ë¡¯ì— ë³µì‚¬(Spawn) í›„ ì—°ê²°
        """
        batch_size, num_nodes = td["nodes"].shape[0], self.N_max
        action_dict = td["action"]
        
        # (B,)
        action_type = action_dict["action_type"].squeeze(-1)
        connect_target = action_dict["connect_target"].squeeze(-1)
        spawn_template = action_dict["spawn_template"].squeeze(-1)

        current_head = td["trajectory_head"].squeeze(-1)  # (B,)


        # --- 0. ì´ë¯¸ 'done'ì¸ ë°°ì¹˜ëŠ” ë¬´ì‹œ ---
        is_already_done = td["done"].squeeze(-1)
        if is_already_done.all():
            return TensorDict({
                "next": td, 
                "reward": torch.zeros(batch_size, 1, device=self.device), 
                "done": td["done"]}, batch_size=td.batch_size)

        # --- 1. ìƒíƒœ í…ì„œ ì¤€ë¹„ (í•„ìš”í•œ ê²ƒë§Œ ì„ íƒ ë³µì‚¬) ---
        # ì „ì²´ td.clone() ì œê±° â†’ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì ˆê°
        next_obs = TensorDict({}, batch_size=td.batch_size, device=self.device)

        # 1-1. ì—í”¼ì†Œë“œ ë™ì•ˆ ë³€í•˜ì§€ ì•ŠëŠ” ì •ì  í…ì„œë“¤ì€ ì°¸ì¡°ë§Œ ê³µìœ 
        #      (clone ë¶ˆí•„ìš”, í° í–‰ë ¬ ì¬í• ë‹¹ ë°©ì§€)
        if "scalar_prompt_features" in td.keys():
            next_obs["scalar_prompt_features"] = td["scalar_prompt_features"]
        if "matrix_prompt_features" in td.keys():
            next_obs["matrix_prompt_features"] = td["matrix_prompt_features"]
        if "attention_mask" in td.keys():
            next_obs["attention_mask"] = td["attention_mask"]

        # âš  connectivity_matrixëŠ” Spawn ì‹œ in-placeë¡œ ê°±ì‹ ë˜ë¯€ë¡œ í˜„ì¬ êµ¬ì¡°ì—ì„œëŠ”
        #   ë™ì  í…ì„œ ì·¨ê¸‰ì´ í•„ìš”í•˜ë‹¤. (ì •ì ìœ¼ë¡œ ë§Œë“¤ë ¤ë©´ ì¶”ê°€ ë¦¬íŒ©í„°ë§ í•„ìš”)

        # 1-2. ì‹¤ì œë¡œ ìŠ¤í…ë§ˆë‹¤ ë³€í•˜ëŠ” ë™ì  í…ì„œë“¤ë§Œ clone()
        next_obs["nodes"] = td["nodes"].clone()  # (ê°€ì¥ ì¤‘ìš”)
        next_obs["adj_matrix"] = td["adj_matrix"].clone()
        next_obs["adj_matrix_T"] = td["adj_matrix_T"].clone()
        if "connectivity_matrix" in td.keys():
            next_obs["connectivity_matrix"] = td["connectivity_matrix"].clone()

        next_obs["unconnected_loads_mask"] = td["unconnected_loads_mask"].clone()
        next_obs["is_active_mask"] = td["is_active_mask"].clone()
        next_obs["is_template_mask"] = td["is_template_mask"].clone()
        next_obs["can_spawn_into_mask"] = td["can_spawn_into_mask"].clone()
        next_obs["next_empty_slot_idx"] = td["next_empty_slot_idx"].clone()

        next_obs["trajectory_head"] = td["trajectory_head"].clone()

        next_obs["step_count"] = td["step_count"].clone()
        next_obs["current_cost"] = td["current_cost"].clone()
        next_obs["staging_cost"] = td["staging_cost"].clone()
        next_obs["sleep_cost"] = td.get("sleep_cost", torch.zeros_like(td["current_cost"])).clone()
        next_obs["is_used_ic_mask"] = td["is_used_ic_mask"].clone()
        next_obs["current_target_load"] = td["current_target_load"].clone()
        if "is_exclusive_mask" in td.keys():
            next_obs["is_exclusive_mask"] = td["is_exclusive_mask"].clone()
        # doneì€ ì•„ë˜ì—ì„œ ìƒˆë¡œ ê³„ì‚°í•˜ì§€ë§Œ, 'ì´ë¯¸ doneì¸ ë°°ì¹˜ ë¡¤ë°±'ì—ì„œ ì‚¬ìš©ë˜ë¯€ë¡œ ë¨¼ì € ë³µì‚¬
        if "done" in td.keys():
            next_obs["done"] = td["done"].clone()
        else:
            next_obs["done"] = torch.zeros_like(td["step_count"], dtype=torch.bool)

        step_reward = torch.full((batch_size,), STEP_PENALTY, dtype=torch.float32, device=self.device)
        batch_indices = torch.arange(batch_size, device=self.device)
        bom_reward_batch = torch.zeros(batch_size, 1, dtype=torch.float32, device=self.device)

        # --- 2. ì•¡ì…˜ íƒ€ì… ë¶„ê¸° ---
        
        # --- 2a. [Select New Load] ---
        # (í˜„ì¬ í—¤ë“œê°€ ë°°í„°ë¦¬ì¼ ë•Œ)
        head_is_battery = (current_head == BATTERY_NODE_IDX)
        if head_is_battery.any():
            # 'Select New Load' ì•¡ì…˜ì€ 'Connect' ì•¡ì…˜ìœ¼ë¡œ ì „ë‹¬ë¨
            b_idx_batt = batch_indices[head_is_battery]
            selected_load = connect_target[head_is_battery]

            is_load_selection = (selected_load != BATTERY_NODE_IDX)
            if is_load_selection.any():
                load_rows = b_idx_batt[is_load_selection]
                load_node_idx = selected_load[is_load_selection]
                
                # Headë¥¼ ì„ íƒëœ Loadë¡œ ì´ë™
                next_obs["trajectory_head"][load_rows, 0] = load_node_idx
                # 'ì—°ê²° ì•ˆ ë¨' ë§ˆìŠ¤í¬ì—ì„œ ì œê±°
                next_obs["unconnected_loads_mask"][load_rows, load_node_idx] = False
                # í˜„ì¬ ê²½ë¡œì˜ ìµœì¢… íƒ€ê²Ÿìœ¼ë¡œ ì„¤ì •
                next_obs["current_target_load"][load_rows, 0] = load_node_idx
                # ê²½ë¡œ ë¹„ìš© ì´ˆê¸°í™”
                next_obs["staging_cost"][load_rows] = 0.0
                
                # 'ë…ë¦½ ë ˆì¼' ìƒíƒœ ì „íŒŒ ì‹œì‘
                # (B_load,)
                rail_status = self.rail_types_tensor[load_node_idx]
                next_obs["is_exclusive_mask"][load_rows, load_node_idx] = rail_status

        # --- 2b. [Find Parent / Spawn] ---
        # (í˜„ì¬ í—¤ë“œê°€ Load ë˜ëŠ” ICì¼ ë•Œ)
        head_is_node = ~head_is_battery
        if head_is_node.any():
            b_idx_node = batch_indices[head_is_node]
            child_node = current_head[head_is_node] # (B_node,)
            
            # (B_node,)
            is_connect = (action_type[head_is_node] == 0)
            is_spawn = ~is_connect
            
            # (B_node,) - ìµœì¢… ë¶€ëª¨ê°€ ë  ë…¸ë“œì˜ ì¸ë±ìŠ¤
            parent_node = torch.zeros_like(child_node)
            
            # --- Connect ì•¡ì…˜ ì²˜ë¦¬ ---
            if is_connect.any():
                b_idx_connect = b_idx_node[is_connect]
                # 'Connect' í—¤ë“œì—ì„œ ë¶€ëª¨ ì¸ë±ìŠ¤ ê°€ì ¸ì˜¤ê¸°
                parent_connect = connect_target[b_idx_connect]
                parent_node[is_connect] = parent_connect
            
            # --- Spawn ì•¡ì…˜ ì²˜ë¦¬ ---
            if is_spawn.any():
                b_idx_spawn = b_idx_node[is_spawn]
                child_spawn = child_node[is_spawn]

                # 'Spawn' í—¤ë“œì—ì„œ í…œí”Œë¦¿ ì¸ë±ìŠ¤ ê°€ì ¸ì˜¤ê¸°
                template_idx = spawn_template[b_idx_spawn] # (B_spawn,)
                # ìŠ¤í°ë  ë¹ˆ ìŠ¬ë¡¯ ì¸ë±ìŠ¤ ê°€ì ¸ì˜¤ê¸°
                # NOTE:
                #   next_empty_slot_idx í…ì„œëŠ” ì´í›„ ìŠ¤í° ë¡œì§ì—ì„œ in-placeë¡œ +1 ê°±ì‹ ëœë‹¤.
                #   clone() ì—†ì´ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ë©´, ì•„ë˜ì—ì„œ next_empty_slot_idxë¥¼ ìˆ˜ì •í•  ë•Œ
                #   autogradê°€ ì €ì¥í•´ ë‘” slot_idx ì¸ë±ìŠ¤ê°€ ë³€ê²½ë˜ì–´ "modified by an inplace"
                #   ì˜¤ë¥˜ê°€ ë°œìƒí•œë‹¤. ì•ˆì „í•˜ê²Œ ë³„ë„ ë³µì‚¬ë³¸ì„ ì‚¬ìš©í•œë‹¤.
                slot_idx = next_obs["next_empty_slot_idx"][b_idx_spawn].clone().squeeze(-1) # (B_spawn,)

                # 1. Spawn: í…œí”Œë¦¿ í”¼ì²˜ -> ë¹ˆ ìŠ¬ë¡¯ìœ¼ë¡œ ë³µì‚¬
                template_features = next_obs["nodes"][b_idx_spawn, template_idx]
                next_obs["nodes"][b_idx_spawn, slot_idx] = template_features.detach()

                # Spawnëœ ìŠ¬ë¡¯ì€ í…œí”Œë¦¿ê³¼ ë™ì¼í•œ ì „ì•• í˜¸í™˜ì„±ì„ ê°€ì ¸ì•¼ í•˜ë¯€ë¡œ
                # connectivity_matrixì˜ í–‰/ì—´ì„ í…œí”Œë¦¿ì—ì„œ ë³µì‚¬í•œë‹¤.
                connectivity_matrix = next_obs["connectivity_matrix"]
                connectivity_matrix[b_idx_spawn, :, slot_idx] = connectivity_matrix[b_idx_spawn, :, template_idx]
                connectivity_matrix[b_idx_spawn, slot_idx, :] = connectivity_matrix[b_idx_spawn, template_idx, :]

                # 2. ìƒíƒœ ë³€ê²½: (Template -> Active)
                next_obs["nodes"][b_idx_spawn, slot_idx, FEATURE_INDEX["is_active"]] = 1.0
                next_obs["nodes"][b_idx_spawn, slot_idx, FEATURE_INDEX["is_template"]] = 0.0
                next_obs["nodes"][b_idx_spawn, slot_idx, FEATURE_INDEX["can_spawn_into"]] = 0.0

                # ğŸš¨ ìˆ˜ì • 2: ë…¸ë“œ íƒ€ì… One-Hot í•„ë“œë¥¼ IC íƒ€ì…ìœ¼ë¡œ í™•ì •í•©ë‹ˆë‹¤.
                node_type_idx_start = FEATURE_INDEX["node_type"][0]
                node_type_idx_end = FEATURE_INDEX["node_type"][1]

                # ê¸°ì¡´ ì›-í•« ì¸ì½”ë”© í•„ë“œë¥¼ 0ìœ¼ë¡œ ì´ˆê¸°í™”
                next_obs["nodes"][b_idx_spawn, slot_idx, node_type_idx_start:node_type_idx_end] = 0.0
                # IC íƒ€ì…(3)ì„ 1.0ìœ¼ë¡œ ì„¤ì •
                next_obs["nodes"][b_idx_spawn, slot_idx, node_type_idx_start + NODE_TYPE_IC] = 1.0

                # 3. í™˜ê²½ ë™ì  ë§ˆìŠ¤í¬ ì—…ë°ì´íŠ¸
                next_obs["is_active_mask"][b_idx_spawn, slot_idx] = True
                next_obs["is_template_mask"][b_idx_spawn, slot_idx] = False
                next_obs["can_spawn_into_mask"][b_idx_spawn, slot_idx] = False

                # 4. ë‹¤ìŒ ë¹ˆ ìŠ¬ë¡¯ ì¸ë±ìŠ¤ +1 (In-place ë°©ì§€: += ëŒ€ì‹  = ... + 1 ì‚¬ìš©)
                # (Autograd ì˜¤ë¥˜ ìˆ˜ì •: modified by an inplace operation)
                next_obs["next_empty_slot_idx"][b_idx_spawn] = \
                    next_obs["next_empty_slot_idx"][b_idx_spawn] + 1
                
                # 5. ìŠ¤í° ë¹„ìš©(cost) ì¦‰ì‹œ ë°˜ì˜
                template_cost = next_obs["nodes"][b_idx_spawn, template_idx, FEATURE_INDEX["cost"]]
                staging_cost_increase = template_cost.unsqueeze(-1) # (B_spawn, 1)
                
                # staging_cost ë° current_costì— ìŠ¤í° ë¹„ìš© ì¶”ê°€
                next_obs["staging_cost"][b_idx_spawn] += staging_cost_increase
                next_obs["current_cost"][b_idx_spawn] += staging_cost_increase
                
                # R_action ë³´ìƒ (ìŠ¤í° ì¦‰ì‹œ)
                step_reward[b_idx_spawn] += REWARD_WEIGHT_ACTION * (-staging_cost_increase.squeeze(-1))
                
                # 'is_used_ic_mask'ì— í…œí”Œë¦¿ ì¸ë±ìŠ¤ ëŒ€ì‹  *ìŠ¤í°ëœ ìŠ¬ë¡¯ ì¸ë±ìŠ¤*ë¥¼ ê¸°ë¡
                next_obs["is_used_ic_mask"][b_idx_spawn, slot_idx] = True
                
                # 6. ìµœì¢… ë¶€ëª¨ë¥¼ 'ìŠ¤í°ëœ ìŠ¬ë¡¯'ìœ¼ë¡œ ì„¤ì •
                parent_node[is_spawn] = slot_idx

            # --- 3. ê³µí†µ ì—°ê²° ë¡œì§ (Connect/Spawn ê³µí†µ) ---
            
            # 3a. ì—£ì§€ ì¶”ê°€: (parent_node) -> (child_node)
            next_obs["adj_matrix"][b_idx_node, parent_node, child_node] = True
            # (Tì—ë„ ì—£ì§€ ì¶”ê°€: (child_node) -> (parent_node))
            next_obs["adj_matrix_T"][b_idx_node, child_node, parent_node] = True

            # 3b. 'ë…ë¦½ ë ˆì¼' ìƒíƒœ ì „íŒŒ (ìì‹ -> ë¶€ëª¨)
            child_status = next_obs["is_exclusive_mask"][b_idx_node, child_node] # (B_node,)
            if (child_status > 0).any():
                parent_status = next_obs["is_exclusive_mask"][b_idx_node, parent_node]

                # 'Path'(2)ëŠ” ICë¥¼ íƒ€ê³  ê³„ì† ì „íŒŒë¨
                status_to_propagate = torch.where(
                    child_status == 2, 
                    child_status, 
                    torch.tensor(0, device=self.device, dtype=torch.long)
                )
                
                # 'Supplier'(1)ëŠ” Loadì—ì„œ ì‹œì‘í•  ë•Œë§Œ ì „íŒŒë¨
                is_child_load = (self.node_type_tensor[child_node] == NODE_TYPE_LOAD)
                status_from_supplier = torch.where(
                    (child_status == 1) & is_child_load,
                    child_status,
                    torch.tensor(0, device=self.device, dtype=torch.long)
                )

                status_from_child = torch.max(status_to_propagate, status_from_supplier)
                new_parent_status = torch.max(parent_status, status_from_child)
                next_obs["is_exclusive_mask"][b_idx_node, parent_node] = new_parent_status
                next_obs["nodes"][b_idx_node, parent_node, FEATURE_INDEX["independent_rail_type"]] = new_parent_status.float()

            # --- [ì¶”ê°€] 3c. 'Always-On' ìƒíƒœ ì „íŒŒ (ìì‹ -> ë¶€ëª¨) ---
            # ìì‹ì´ ì˜ ë•Œë„ ì¼œì ¸ì•¼ í•œë‹¤ë©´(AO), ë¶€ëª¨ë„ ë¬´ì¡°ê±´ ì¼œì ¸ ìˆì–´ì•¼ í•¨(AO).
            # ëª¨ë¸ì—ê²Œ "ì´ ë¶€ëª¨ëŠ” ì´ë¯¸ ê¹¨ì–´ìˆìŒ(Penalty Pre-paid)"ì„ ì•Œë ¤ì£¼ì–´ ê·¸ë£¹í™”ë¥¼ ìœ ë„í•¨.
            child_is_ao = next_obs["nodes"][b_idx_node, child_node, FEATURE_INDEX["always_on_in_sleep"]]

            # (ì´ë¯¸ 1.0ì´ë©´ ìœ ì§€, ì•„ë‹ˆë©´ ìì‹ ìƒíƒœì— ë”°ë¼ 1.0ìœ¼ë¡œ ë³€ê²½)
            current_parent_ao = next_obs["nodes"][b_idx_node, parent_node, FEATURE_INDEX["always_on_in_sleep"]]
            new_parent_ao = torch.max(current_parent_ao, child_is_ao)
            next_obs["nodes"][b_idx_node, parent_node, FEATURE_INDEX["always_on_in_sleep"]] = new_parent_ao

            # 3d. ë‹¤ìŒ Head ì„¤ì •
            parent_is_battery = (parent_node == BATTERY_NODE_IDX)

            # í—¤ë“œ(parent_node)ê°€ ì´ë¯¸ ë¶€ëª¨ë¥¼ ê°€ì¡ŒëŠ”ì§€ í™•ì¸
            # adj_matrix_T[b, node, :]ê°€ 1ì´ë¼ë„ ìˆìœ¼ë©´, nodeëŠ” ì´ë¯¸ ë¶€ëª¨ê°€ ìˆìŒ
            parent_already_has_parent = next_obs["adj_matrix_T"][b_idx_node, parent_node].any(dim=-1)

            # ë°°í„°ë¦¬ì— ë„ë‹¬í•˜ê±°ë‚˜, ì´ë¯¸ ì—°ê²°ëœ ë…¸ë“œì— ë„ë‹¬í•˜ë©´ ê²½ë¡œ ì™„ì„±
            path_is_finished = parent_is_battery | parent_already_has_parent

            next_obs["trajectory_head"][b_idx_node, 0] = torch.where(
                path_is_finished,  # ğŸ’¡ ì¡°ê±´ ë³€ê²½
                BATTERY_NODE_IDX,  # ê²½ë¡œê°€ ëë‚¬ìœ¼ë©´ ë°°í„°ë¦¬ë¡œ ë³µê·€
                parent_node        # ì•„ë‹ˆë©´ ê²½ë¡œ ì¶”ì  ê³„ì†
            )
              
            # 3e. ê²½ë¡œ ì™„ì„± (R_path ë³´ìƒ) [ìˆ˜ì •]
            # parent_is_battery ëŒ€ì‹  path_is_finished ì¡°ê±´ì„ ì‚¬ìš©í•˜ì—¬
            # ê¸°ì¡´ íŠ¸ë¦¬ì— ì—°ê²°ëœ ê²½ìš°(parent_already_has_parent)ì—ë„ ë¹„ìš©ì„ ì •ì‚°í•˜ë„ë¡ ë³€ê²½


            if path_is_finished.any():
                finished_rows = b_idx_node[path_is_finished]
                
                # ê²½ë¡œ ì™„ì„± ì‹œ, ëˆ„ì ëœ staging_cost(BOM)ë¥¼ R_path ë³´ìƒìœ¼ë¡œ ì¶”ê°€
                sub_trajectory_total_cost = next_obs["staging_cost"][finished_rows]
                
                # [ìˆ˜ì •] ê°€ê²©ì— ê°€ì¤‘ì¹˜(WEIGHT_BOM)ë¥¼ ê³±í•´ ë¯¼ê°ë„ ì¦ê°€
                # Costê°€ ë†’ì„ìˆ˜ë¡(-) RewardëŠ” ë‚®ì•„ì§
                weighted_cost = WEIGHT_BOM * sub_trajectory_total_cost.squeeze(-1)
                
                r_bom = - REWARD_WEIGHT_PATH * weighted_cost
                step_reward[finished_rows] += r_bom
                bom_reward_batch[finished_rows] = r_bom.unsqueeze(-1) # ê¸°ë¡     

                # staging_cost ë¦¬ì…‹
                next_obs["staging_cost"][finished_rows] = 0.0
                next_obs["current_target_load"][finished_rows, 0] = -1

        # --- 4. ì „ë ¥/ë°œì—´ ì¬ê³„ì‚° (ì—°ì‚° ë¹„ìš© ë†’ìŒ) ---
        # (ëª¨ë“  ë°°ì¹˜ê°€ ìµœì†Œ 1ìŠ¤í… ì´ìƒ ì§„í–‰í–ˆì„ ë•Œë§Œ ê³„ì‚°)
        if td["step_count"].min() > 0 or head_is_node.any():
            final_i_out, power_loss, new_temp = self._calculate_tree_loads(
                next_obs["nodes"], 
                next_obs["adj_matrix"],
                next_obs["adj_matrix_T"] # ğŸ’¡ adj_matrix_T ì „ë‹¬
            )
            next_obs["nodes"][..., FEATURE_INDEX["current_out"]] = final_i_out
            next_obs["nodes"][..., FEATURE_INDEX["junction_temp"]] = new_temp
        
        next_obs.set("step_count", td["step_count"] + 1)

        # --- 5. ì¢…ë£Œ ì¡°ê±´ í™•ì¸ ---
        # (get_action_maskê°€ 3ì¢… ë§ˆìŠ¤í¬ë¥¼ ëª¨ë‘ ë°˜í™˜í•œë‹¤ê³  ê°€ì •)
        next_masks = self.get_action_mask(next_obs)
        # Connect/Spawn ë‘˜ ë‹¤ ë¶ˆê°€ëŠ¥í•œ ê²½ìš°
        is_stuck = ~(next_masks["mask_type"].any(dim=-1))
        
        all_loads_connected = (next_obs["unconnected_loads_mask"].sum(dim=1) == 0)
        trajectory_finished = (next_obs["trajectory_head"].squeeze(-1) == BATTERY_NODE_IDX)
        
        done_successfully = all_loads_connected & trajectory_finished
        max_steps = 2 * self.N_max # ìµœëŒ€ ìŠ¤í… ì œí•œ
        timed_out = (next_obs["step_count"] > max_steps).squeeze(-1)
        
        is_done = done_successfully | timed_out | is_stuck
        next_obs["done"] = is_done.unsqueeze(-1)

        # --- 6. ìµœì¢… ë³´ìƒ ê³„ì‚°---
        final_reward, fail_penalty_val = self.get_reward(
            next_obs, step_reward, done_successfully, timed_out, is_stuck
        )
        next_obs["log_reward_bom"] = bom_reward_batch
        next_obs["log_reward_fail"] = fail_penalty_val.unsqueeze(-1)

        # ì´ë¯¸ 'done'ì´ì—ˆë˜ ìƒ˜í”Œì€ ë³´ìƒ 0, ìƒíƒœ ë¡¤ë°±
        if is_already_done.any():
            final_reward[is_already_done] = 0.0
            next_obs[is_already_done] = td[is_already_done]

        return TensorDict({
            "next": next_obs,
            "reward": final_reward.unsqueeze(-1),
            "done": next_obs["done"],
        }, batch_size=batch_size)
        
    def get_reward(self,
                   td: TensorDict,
                   step_reward: torch.Tensor,
                   done_successfully: torch.Tensor,
                   timed_out: torch.Tensor,
                   is_stuck: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]: # [ìˆ˜ì •] ë¦¬í„´ íƒ€ì… ë³€ê²½

        """
        [ìˆ˜ì •] ì•”ì „ë¥˜ ì œì•½ ìœ„ë°˜ í˜ë„í‹° ì œê±° (í•˜ë“œ ì œì•½ìœ¼ë¡œ ë³€ê²½ë¨)
        """
        reward = step_reward.clone()
        fail_penalty_record = torch.zeros_like(reward)

        # ì‹¤íŒ¨í•œ ê²½ìš°ë§Œ ê³ ì • í˜ë„í‹° (ì„±ê³µ ì‹œ ì•”ì „ë¥˜ ìœ„ë°˜ì€ ë§ˆìŠ¤í‚¹ìœ¼ë¡œ ë°©ì§€ë¨)
        failed = (timed_out | is_stuck) & ~done_successfully
        if failed.any():
            reward[failed] = FAILURE_PENALTY
            fail_penalty_record[failed] = FAILURE_PENALTY
            
        return reward, fail_penalty_record

    # ---
    # ì„¹ì…˜ 5: ì•¡ì…˜ ë§ˆìŠ¤í‚¹ (ì—°ì‚° ì§‘ì•½ì )
    # ---
    @torch.no_grad()
    def get_action_mask(self, td: TensorDict, debug: bool = False) -> Dict[str, torch.Tensor]:
        self._ensure_buffers(td)

        batch_size = td.batch_size[0]
        num_nodes = self.N_max
        current_head = td["trajectory_head"].squeeze(-1) 

        is_active = td["is_active_mask"]
        is_template = td["is_template_mask"]
        
        mask_type = torch.zeros(batch_size, 2, dtype=torch.bool, device=self.device)
        mask_connect = torch.zeros(batch_size, num_nodes, dtype=torch.bool, device=self.device)
        mask_spawn = torch.zeros(batch_size, num_nodes, dtype=torch.bool, device=self.device)
        
        reasons = {} # [Debug] ë””ë²„ê·¸ ì •ë³´ ì €ì¥ìš© ë”•ì…”ë„ˆë¦¬

        # --- 2. [Select New Load] (Phase Logic) ---
        head_is_battery = (current_head == BATTERY_NODE_IDX)

        if head_is_battery.any():
            b_idx_batt = torch.where(head_is_battery)[0]
            
            mask_type[b_idx_batt, 0] = True 
            
            # 1. ì¼ë‹¨ ì—°ê²° ì•ˆ ëœ ëª¨ë“  ë¶€í•˜ í›„ë³´
            candidate_loads = td["unconnected_loads_mask"][b_idx_batt] # (B, N)
            
            # 2. [Phase 1 ê°•ì œ] Always-On ë¶€í•˜ ìš°ì„  ì •ì±…
            ao_feature = td["nodes"][b_idx_batt, :, FEATURE_INDEX["always_on_in_sleep"]]
            ao_unconnected = candidate_loads & (ao_feature == 1.0)
            has_ao_remaining = ao_unconnected.any(dim=-1) # (B,)
            
            # 3. AO ë¶€í•˜ê°€ ë‚¨ì•„ìˆëŠ” ë°°ì¹˜ëŠ” AO ë¶€í•˜ë§Œ ì„ íƒ ê°€ëŠ¥í•˜ë„ë¡ í•„í„°ë§
            final_candidates = candidate_loads.clone()
            
            if has_ao_remaining.any():
                idx_with_ao = torch.where(has_ao_remaining)[0] 
                not_ao_mask = (ao_feature[idx_with_ao] != 1.0)
                final_candidates[idx_with_ao] &= ~not_ao_mask

            mask_connect[b_idx_batt] = final_candidates
            
            # ì¢…ë£Œ ì¡°ê±´ (ëª¨ë“  ë¡œë“œ ì—°ê²° ì™„ë£Œ ì‹œ ë°°í„°ë¦¬ ì„ íƒ)
            all_connected = (candidate_loads.sum(dim=-1) == 0)
            if all_connected.any():
                b_idx_finish = b_idx_batt[all_connected]
                mask_connect[b_idx_finish, BATTERY_NODE_IDX] = True
        

        # --- 3. [Find Parent / Spawn] (Hard Constraints) ---
        head_is_node = ~head_is_battery
        if head_is_node.any():
            b_idx_node = torch.where(head_is_node)[0]
            child_nodes = current_head[b_idx_node]
            B_act = len(b_idx_node)
            
            # 3a. ê¸°ë³¸ ì œì•½ (ì „ì••, ì‚¬ì´í´, ë…ì , ì‹œí€€ìŠ¤)
            connectivity = td["connectivity_matrix"][b_idx_node]
            volt_ok = connectivity[torch.arange(B_act), :, child_nodes]
            path_mask = self._trace_path_batch(child_nodes, td["adj_matrix_T"][b_idx_node])
            cycle_ok = ~path_mask            
            exclusive_ok = self._get_exclusive_mask(td, b_idx_node, child_nodes)
            power_seq_ok = self._get_power_sequence_mask(td["adj_matrix"][b_idx_node], child_nodes, td, b_idx_node)
            
            base_valid_parents = volt_ok & cycle_ok & exclusive_ok & power_seq_ok
            
            # 3b. Thermal Simulation Mask
            thermal_current_ok = self._get_thermal_current_mask(
                td, b_idx_node, child_nodes, base_valid_parents
            )

            # 3c. [Sleep Logic] Sleep Current Simulation Mask (Hard Constraint)
            # Thermalê¹Œì§€ í†µê³¼í•œ í›„ë³´ë“¤ì— ëŒ€í•´ ì•”ì „ë¥˜ ì˜ˆì‚° ê²€ì‚¬
            # (debugë¥¼ ìœ„í•´ ë³€ìˆ˜ë¥¼ ë¶„ë¦¬í–ˆìŠµë‹ˆë‹¤)
            sleep_current_ok = self._get_sleep_current_mask(
                td, b_idx_node, child_nodes, base_valid_parents & thermal_current_ok
            )
            
            # ìµœì¢… ìœ íš¨ ë¶€ëª¨ (ëª¨ë“  í•˜ë“œ ì œì•½ í†µê³¼)
            # (sleep_current_ok í•¨ìˆ˜ê°€ ì´ë¯¸ base & thermal ì¡°ê±´ì„ í¬í•¨í•˜ì—¬ ê³„ì‚°í•˜ì§€ë§Œ ëª…ì‹œì ìœ¼ë¡œ AND ì—°ì‚°)
            final_valid_parents = sleep_current_ok 
            
            # 3d. ë§ˆìŠ¤í¬ ì ìš©
            mask_connect[b_idx_node] = final_valid_parents & is_active[b_idx_node]
            mask_spawn[b_idx_node] = final_valid_parents & is_template[b_idx_node]
            
            can_connect = mask_connect[b_idx_node].any(dim=-1)
            has_empty_slots = (td["next_empty_slot_idx"][b_idx_node] < self.N_max)
            can_spawn = mask_spawn[b_idx_node].any(dim=-1) & has_empty_slots.squeeze(-1)
            
            mask_type[b_idx_node, 0] = can_connect
            mask_type[b_idx_node, 1] = can_spawn

            # --- [Debug Info Collection] ---
            if debug:
                # 0ë²ˆ ë°°ì¹˜ ìƒ˜í”Œì´ í˜„ì¬ ë…¸ë“œ ì„ íƒ ë‹¨ê³„ì— ìˆë‹¤ë©´ ì •ë³´ë¥¼ ìˆ˜ì§‘
                if 0 in b_idx_node:
                    # b_idx_node ë‚´ì—ì„œ 0ë²ˆ ë°°ì¹˜ì˜ ë¡œì»¬ ì¸ë±ìŠ¤ ì°¾ê¸°
                    local_idx = (b_idx_node == 0).nonzero(as_tuple=True)[0].item()
                    
                    reasons["volt_ok"] = volt_ok[local_idx]
                    reasons["cycle_ok"] = cycle_ok[local_idx]
                    reasons["exclusive_ok"] = exclusive_ok[local_idx]
                    reasons["power_seq_ok"] = power_seq_ok[local_idx]
                    reasons["base_valid_parents"] = base_valid_parents[local_idx]
                    reasons["thermal_current_ok"] = thermal_current_ok[local_idx]
                    # [New] ì•”ì „ë¥˜ ë§ˆìŠ¤í¬ ì •ë³´ ì¶”ê°€
                    reasons["sleep_current_ok"] = sleep_current_ok[local_idx]
                    reasons["final_valid_parents"] = final_valid_parents[local_idx]

        # âœ… [Return] debug ì—¬ë¶€ì— ë”°ë¼ ë¶„ê¸°
        if debug:
            return {
                "mask_type": mask_type,
                "mask_connect": mask_connect,
                "mask_spawn": mask_spawn,
                "reasons": reasons # ë””ë²„ê·¸ ì •ë³´ í¬í•¨
            }
        else:
            return {
                "mask_type": mask_type,
                "mask_connect": mask_connect,
                "mask_spawn": mask_spawn,
            }
    # ---
    # ì„¹ì…˜ 6: ë§ˆìŠ¤í‚¹ í—¬í¼ í•¨ìˆ˜ 
    # ---

    def _trace_path_batch(self, start_nodes: torch.Tensor, adj_matrix_T: torch.Tensor) -> torch.Tensor:
        """ start_nodesì˜ ëª¨ë“  ì¡°ìƒ(ancestors)ì„ ì°¾ì•„ ë§ˆìŠ¤í¬ë¡œ ë°˜í™˜ (ì‚¬ì´í´ ë°©ì§€ìš©) """
        batch_size, num_nodes, _ = adj_matrix_T.shape
        path_mask = torch.zeros(batch_size, num_nodes, dtype=torch.bool, device=self.device)

        if start_nodes.numel() > 0:
            path_mask.scatter_(1, start_nodes.unsqueeze(-1), True)

        adj_matrix_T_float = adj_matrix_T.float()

        for _ in range(num_nodes):
            # (B,N,N) @ (B,N,1) -> (B,N)
            parents_mask = (adj_matrix_T_float @ path_mask.float().unsqueeze(-1)).squeeze(-1).bool()
            if (parents_mask & ~path_mask).sum() == 0: break
            path_mask |= parents_mask
            
        return path_mask

    def _get_exclusive_mask(self, 
                            td: TensorDict,
                            b_idx_node: torch.Tensor, 
                            child_nodes: torch.Tensor
                            ) -> torch.Tensor:
        """ ë…ë¦½ ë ˆì¼(Exclusive Rail) ì œì•½ì¡°ê±´ ë§ˆìŠ¤í¬ ìƒì„± """
        # (tdì™€ b_idx_nodeì—ì„œ í•„ìš”í•œ í…ì„œë¥¼ ê°€ì ¸ì˜´)
        is_exclusive_mask_batch = td["is_exclusive_mask"][b_idx_node]
        adj_matrix_batch = td["adj_matrix"][b_idx_node]
        B_act, N_nodes = is_exclusive_mask_batch.shape
        
        # 1. Head(Child)ì˜ ìƒíƒœadj_matrix_T
        head_status = is_exclusive_mask_batch[torch.arange(B_act), child_nodes] # (B_act,)
        node_type_indices_full = td["nodes"][b_idx_node, child_nodes, FEATURE_INDEX["node_type"][0]:FEATURE_INDEX["node_type"][1]].argmax(-1)
        head_is_load = (node_type_indices_full == NODE_TYPE_LOAD) # (B_act,)

        # 2. Parent(í›„ë³´)ì˜ ìƒíƒœ
        parent_status = is_exclusive_mask_batch # (B_act, N_nodes)
        parent_is_exclusive = (parent_status > 0)

        # (B_act, N_nodes) - ë¶€ëª¨ê°€ ì´ë¯¸ ìì‹ì„ ê°€ì¡ŒëŠ”ì§€?
        parent_has_any_child = adj_matrix_batch.any(dim=-1)

        
        # 3. ìœ„ë°˜(Violation) ê·œì¹™ (True = ìœ„ë°˜ = ê¸ˆì§€)
        
        # ê·œì¹™ 1: Headê°€ 'Path'(2) -> ë¶€ëª¨ëŠ” ìì‹ì´ ì—†ì–´ì•¼ í•¨
        # (B_act, 1) & (B_act, N_nodes) -> (B_act, N_nodes)
        violation_Rule1 = (head_status.unsqueeze(-1) == 2) & parent_has_any_child

        # ê·œì¹™ 2: Headê°€ 'Supplier Load'(1) -> ë¶€ëª¨ëŠ” ìì‹ì´ ì—†ì–´ì•¼ í•¨
        violation_Rule2 = ((head_status == 1) & head_is_load).unsqueeze(-1) & parent_has_any_child

        # ê·œì¹™ 3: Headê°€ 'Normal'(0) ë˜ëŠ” 'Supplier IC'(1) -> ë¶€ëª¨ëŠ” Exclusiveì´ë©´ ì•ˆ ë¨
        violation_Rule3 = ((head_status == 0) | ((head_status == 1) & ~head_is_load)).unsqueeze(-1) & parent_is_exclusive
        
        violations = violation_Rule1 | violation_Rule2 | violation_Rule3
        
        # 4. ë°°í„°ë¦¬ëŠ” í•­ìƒ í—ˆìš©
        is_battery_mask = (self.arange_nodes.unsqueeze(0) == BATTERY_NODE_IDX)
        exclusive_ok = torch.logical_not(violations) | is_battery_mask

        return exclusive_ok

    def _get_power_sequence_mask(self, 
                                 adj_matrix_batch: torch.Tensor, 
                                 child_nodes: torch.Tensor, 
                                 td: TensorDict, 
                                 b_idx_node: torch.Tensor
                                 ) -> torch.Tensor:
        """ ì „ì› ì‹œí€€ì‹±(Power Sequence) ì œì•½ì¡°ê±´ ë§ˆìŠ¤í¬ ìƒì„± """
        B_act, N_nodes, _ = adj_matrix_batch.shape
        adj_matrix_T_batch = td["adj_matrix_T"][b_idx_node]
        candidate_mask = torch.ones(B_act, N_nodes, dtype=torch.bool, device=self.device)

        for j_idx, k_idx, f_flag in self.power_sequences:
            # Case 1: í˜„ì¬ childê°€ 'k' (jì˜ ë¶€ëª¨ë¥¼ ì°¾ëŠ” ì¤‘)
            is_k_mask = (child_nodes == k_idx)
            if is_k_mask.any():
                b_idx_check = torch.where(is_k_mask)[0] # (B_k,)
                # 'j'ì˜ ë¶€ëª¨ê°€ ì´ë¯¸ ì¡´ì¬í•˜ëŠ”ê°€?
                parent_of_j_exists = adj_matrix_batch[b_idx_check, :, j_idx].any(dim=-1) # (B_k,)

                if parent_of_j_exists.any():
                    b_constr = b_idx_check[parent_of_j_exists] # (B_constr,)
                    # 'j'ì˜ ë¶€ëª¨ ì¸ë±ìŠ¤ 
                    parent_of_j_idx = adj_matrix_batch[b_constr, :, j_idx].long().argmax(-1) # (B_constr,)
                    # 'j'ì˜ ë¶€ëª¨(parent_of_j)ì˜ ëª¨ë“  ì¡°ìƒ(ancestors)ì„ ì°¾ìŒ
                    anc_mask = self._trace_path_batch(parent_of_j_idx, adj_matrix_T_batch[b_constr])
                    anc_mask[:, BATTERY_NODE_IDX] = False # ë°°í„°ë¦¬ ì œì™¸
                    # 'k'ì˜ ë¶€ëª¨ëŠ” 'j'ì˜ ì¡°ìƒì´ ë  ìˆ˜ ì—†ìŒ
                    candidate_mask[b_constr] &= ~anc_mask
                    # (f=1) 'k'ì˜ ë¶€ëª¨ëŠ” 'j'ì˜ ë¶€ëª¨ì™€ ê°™ì„ ìˆ˜ ì—†ìŒ
                    if f_flag == 1:
                        same_parent_mask = (self.arange_nodes == parent_of_j_idx.unsqueeze(1))
                        candidate_mask[b_constr] &= ~same_parent_mask

            # Case 2: í˜„ì¬ childê°€ 'j' (kì˜ ë¶€ëª¨ë¥¼ ì°¾ëŠ” ì¤‘)
            is_j_mask = (child_nodes == j_idx)
            if is_j_mask.any():
                b_idx_check = torch.where(is_j_mask)[0]
                parent_of_k_exists = adj_matrix_batch[b_idx_check, :, k_idx].any(dim=-1)

                if parent_of_k_exists.any():
                    b_constr = b_idx_check[parent_of_k_exists]
                    parent_of_k_idx = adj_matrix_batch[b_constr, :, k_idx].long().argmax(-1)

                    anc_mask = self._trace_path_batch(parent_of_k_idx, adj_matrix_T_batch[b_constr])
                    anc_mask[:, BATTERY_NODE_IDX] = False
                    # 'j'ì˜ ë¶€ëª¨ëŠ” 'k'ì˜ ì¡°ìƒì´ ë  ìˆ˜ ì—†ìŒ
                    candidate_mask[b_constr] &= ~anc_mask
                    if f_flag == 1:
                        same_parent_mask = (self.arange_nodes == parent_of_k_idx.unsqueeze(1))
                        candidate_mask[b_constr] &= ~same_parent_mask
        return candidate_mask
    
    @torch.no_grad()
    def _get_thermal_current_mask(self,
                                  td: TensorDict,
                                  b_idx_node: torch.Tensor,
                                  child_nodes: torch.Tensor,
                                  base_valid_parents: torch.Tensor) -> torch.Tensor:
        """
        ì „ë¥˜/ë°œì—´ í•œê³„ë¥¼ ë§Œì¡±í•˜ëŠ”ì§€ ì‹œë®¬ë ˆì´ì…˜í•˜ì—¬ ë§ˆìŠ¤í¬ ìƒì„±.
        (ì—°ì‚° ë¹„ìš©ì´ ê°€ì¥ ë†’ì€ í•¨ìˆ˜)
        """
        
        # (B_act, N_max)
        thermal_current_ok = base_valid_parents.clone()
        # ì‹œë®¬ë ˆì´ì…˜ ì²­í¬ í¬ê¸° (ë©”ëª¨ë¦¬/ì†ë„ íŠ¸ë ˆì´ë“œì˜¤í”„)
        SIM_CHUNK_SIZE = 8

        B_act, N_nodes = base_valid_parents.shape

        base_nodes = td["nodes"][b_idx_node]
        base_adj_matrix = td["adj_matrix"][b_idx_node]
        base_adj_matrix_T = td["adj_matrix_T"][b_idx_node]
        
        # ë§ˆì§„(Margin) ê°’ ë¯¸ë¦¬ ë¡œë“œ
        margin_I = float(self.generator.config.constraints.get("current_margin", 0.0))
        THERMAL_MARGIN_DEG = float(self.generator.config.constraints.get("thermal_margin_deg", 5.0))        

        # (N_max) í¬ê¸°ì˜ ì²­í¬ë¡œ ë‚˜ëˆ„ì–´ ì‹œë®¬ë ˆì´ì…˜
        for chunk_start in range(0, N_nodes, SIM_CHUNK_SIZE):
            chunk_end = min(chunk_start + SIM_CHUNK_SIZE, N_nodes)
            parent_indices_in_chunk = torch.arange(chunk_start, chunk_end, device=self.device)

            # (B_act, N_chunk) - ì´ë²ˆ ì²­í¬ì—ì„œ ì‹œë®¬ë ˆì´ì…˜í•  (ë°°ì¹˜, ë¶€ëª¨) í›„ë³´
            candidates_in_chunk_mask = base_valid_parents[:, chunk_start:chunk_end]
            
            # (N_sim,) - (B_act ê¸°ì¤€ ì¸ë±ìŠ¤, ë¡œì»¬ ë¶€ëª¨ ì¸ë±ìŠ¤)
            b_idx_sim_chunk, p_idx_sim_chunk_local = candidates_in_chunk_mask.nonzero(as_tuple=True)

            if b_idx_sim_chunk.numel() == 0:
                continue # ì‹œë®¬ë ˆì´ì…˜í•  í›„ë³´ ì—†ìŒ
            
            N_sim = b_idx_sim_chunk.numel()

            # 1. ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° ì¤€ë¹„ (N_sim,)
            sim_nodes = base_nodes[b_idx_sim_chunk]
            sim_adj_matrix = base_adj_matrix[b_idx_sim_chunk].clone()
            sim_adj_matrix_T = base_adj_matrix_T[b_idx_sim_chunk].clone()
            sim_child_nodes = child_nodes[b_idx_sim_chunk]

            # (N_sim,) - ì‹¤ì œ ë¶€ëª¨ ë…¸ë“œ ì¸ë±ìŠ¤
            sim_parent_indices_global = parent_indices_in_chunk[p_idx_sim_chunk_local]
            
            # 2. (ê°€ìƒ) ì—£ì§€ ì¶”ê°€: (parent) -> (child)
            sim_rows = torch.arange(N_sim, device=self.device)
            sim_adj_matrix[sim_rows, sim_parent_indices_global, sim_child_nodes] = True
            sim_adj_matrix_T[sim_rows, sim_child_nodes, sim_parent_indices_global] = True

            # 3. ğŸš€ íŠ¸ë¦¬ ì „ì²´ ë¶€í•˜ ì‹œë®¬ë ˆì´ì…˜
            (final_i_out, power_loss, junction_temp) = self._calculate_tree_loads(
                sim_nodes,
                sim_adj_matrix, 
                sim_adj_matrix_T
            )

            # 4. ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ ê²€ì¦
            i_limit = sim_nodes[..., FEATURE_INDEX["i_limit"]] * (1.0 - margin_I)
            t_max_raw = sim_nodes[..., FEATURE_INDEX["t_junction_max"]]
            t_max = t_max_raw - THERMAL_MARGIN_DEG            
            
            # (N_sim, N_max)
            current_check_ok = (final_i_out <= i_limit + 1e-6)
            temp_check_ok = (junction_temp <= t_max + 1e-6)
            
            # (N_sim, N_max)
            all_checks_ok = current_check_ok & temp_check_ok
            
            # (N_sim, N_max) - ICê°€ ì•„ë‹Œ ë…¸ë“œëŠ” í•­ìƒ OK
            ic_type_indices = sim_nodes[..., FEATURE_INDEX["node_type"][0]:FEATURE_INDEX["node_type"][1]].argmax(-1)
            ic_mask_sim = (ic_type_indices == NODE_TYPE_IC)   

            # [ìˆ˜ì •] ê²€ì¦ ëŒ€ìƒ í•„í„°ë§: "í˜„ì¬ Active ë…¸ë“œ" + "ì´ë²ˆ ì‹œë®¬ë ˆì´ì…˜ì˜ í›„ë³´ ë¶€ëª¨"ë§Œ ê²€ì‚¬
            # (ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ë‹¤ë¥¸ í…œí”Œë¦¿ë“¤ì´ ê³ ì˜¨ì—ì„œ FAIL ëœ¨ëŠ” ê²ƒì„ ë¬´ì‹œí•˜ê¸° ìœ„í•¨)
            relevant_mask = td["is_active_mask"][b_idx_sim_chunk].clone()
            relevant_mask[sim_rows, sim_parent_indices_global] = True
            is_valid_simulation = (all_checks_ok | ~ic_mask_sim | ~relevant_mask).all(dim=-1)

            failed_sim_mask = ~is_valid_simulation
            if failed_sim_mask.any():
                b_idx_failed = b_idx_sim_chunk[failed_sim_mask]
                p_idx_failed_global = sim_parent_indices_global[failed_sim_mask]
                thermal_current_ok[b_idx_failed, p_idx_failed_global] = False
                
        return thermal_current_ok

    # ---
    # ì„¹ì…˜ 7: ê³„ì‚° í—¬í¼ í•¨ìˆ˜ 
    # ---
    @torch.no_grad()
    def _get_sleep_current_mask(self, td: TensorDict, b_idx_node: torch.Tensor, child_nodes: torch.Tensor, base_valid_parents: torch.Tensor) -> torch.Tensor:
        """
        [ì¶”ê°€] ì•”ì „ë¥˜ ì œì•½ ê²€ì¦ìš© ë§ˆìŠ¤í‚¹ í•¨ìˆ˜
        ê°€ìƒìœ¼ë¡œ ì—°ê²° í›„ Total Sleep Currentê°€ ì˜ˆì‚°(Budget)ì„ ì´ˆê³¼í•˜ë©´ ë§ˆìŠ¤í‚¹í•©ë‹ˆë‹¤.
        """
        sleep_ok = base_valid_parents.clone()
        SIM_CHUNK_SIZE = 8 # ë©”ëª¨ë¦¬ ë¬¸ì œ ì‹œ ì¡°ì ˆ
        
        B_act, N_nodes = base_valid_parents.shape
        base_nodes = td["nodes"][b_idx_node]
        base_adj_matrix = td["adj_matrix"][b_idx_node]
        base_adj_matrix_T = td["adj_matrix_T"][b_idx_node]
        
        # Budget ê°€ì ¸ì˜¤ê¸°
        # scalar_prompt_features[1] = max_sleep_current
        max_sleep_current = td["scalar_prompt_features"][b_idx_node, 1]

        for chunk_start in range(0, N_nodes, SIM_CHUNK_SIZE):
            chunk_end = min(chunk_start + SIM_CHUNK_SIZE, N_nodes)
            parent_indices_in_chunk = torch.arange(chunk_start, chunk_end, device=self.device)
            candidates_in_chunk_mask = base_valid_parents[:, chunk_start:chunk_end]
            
            b_idx_sim_chunk, p_idx_sim_chunk_local = candidates_in_chunk_mask.nonzero(as_tuple=True)
            if b_idx_sim_chunk.numel() == 0: continue
            
            N_sim = b_idx_sim_chunk.numel()
            sim_adj_matrix = base_adj_matrix[b_idx_sim_chunk].clone()
            sim_adj_matrix_T = base_adj_matrix_T[b_idx_sim_chunk].clone()
            sim_child_nodes = child_nodes[b_idx_sim_chunk]
            sim_parent_indices_global = parent_indices_in_chunk[p_idx_sim_chunk_local]
            
            # ê°€ìƒ ì—°ê²°
            sim_rows = torch.arange(N_sim, device=self.device)
            sim_adj_matrix[sim_rows, sim_parent_indices_global, sim_child_nodes] = True
            sim_adj_matrix_T[sim_rows, sim_child_nodes, sim_parent_indices_global] = True
            
            # ë…¸ë“œ ì •ë³´ (Spawnì‹œ ë§ˆìŠ¤í¬ ì—…ë°ì´íŠ¸ ë“±ì€ _calculate_total_sleep_current ë‚´ë¶€ì—ì„œ
            # is_used_ic_mask ë“±ì„ ì°¸ì¡°í•˜ë¯€ë¡œ, ì—¬ê¸°ì„œëŠ” ë…¸ë“œ Featureë§Œìœ¼ë¡œ ì¶©ë¶„í•œì§€ í™•ì¸ í•„ìš”)
            # _calculate_total_sleep_currentëŠ” is_used_ic_maskë¥¼ ì‚¬ìš©í•˜ì—¬ Self-consumption ê³„ì‚°.
            # Spawnì˜ ê²½ìš° ìƒˆ ë…¸ë“œê°€ 'Used'ê°€ ë˜ì–´ì•¼ ì „ë¥˜ê°€ ê³„ì‚°ë¨.
            
            # Spawn í›„ë³´ì¸ ê²½ìš°(is_activeê°€ Falseì¸ ê²½ìš°), ê°€ìƒìœ¼ë¡œ Used ë§ˆìŠ¤í¬ë¥¼ ì¼œì•¼ í•¨
            # ì—¬ê¸°ì„œëŠ” í¸ì˜ìƒ ì‹œë®¬ë ˆì´ì…˜ìš© Used Maskë¥¼ ìƒì„±
            sim_is_used_mask = td["is_used_ic_mask"][b_idx_node][b_idx_sim_chunk].clone()
            sim_is_used_mask[sim_rows, sim_parent_indices_global] = True # í›„ë³´ ë¶€ëª¨(í…œí”Œë¦¿ í¬í•¨)ë¥¼ Usedë¡œ ì²˜ë¦¬
            
            sim_nodes = base_nodes[b_idx_sim_chunk] # FeatureëŠ” ê·¸ëŒ€ë¡œ ì‚¬ìš© (Spawn í…œí”Œë¦¿ë„ Feature ë³´ìœ )

            # ì•”ì „ë¥˜ ê³„ì‚°
            total_sleep = self._calculate_total_sleep_current(
                nodes=sim_nodes, 
                adj_matrix=sim_adj_matrix, 
                adj_matrix_T=sim_adj_matrix_T,
                is_used_ic_mask=sim_is_used_mask 
            )
            
            # Budget ì²´í¬
            budget = max_sleep_current[b_idx_sim_chunk]
            # ì•„ì£¼ ì•½ê°„ì˜ ì˜¤ì°¨ í—ˆìš© (1e-9)
            is_valid = (total_sleep <= budget + 1e-9)
            
            failed_sim_mask = ~is_valid
            if failed_sim_mask.any():
                b_idx_failed = b_idx_sim_chunk[failed_sim_mask]
                p_idx_failed_global = sim_parent_indices_global[failed_sim_mask]
                sleep_ok[b_idx_failed, p_idx_failed_global] = False
                
        return sleep_ok

    @torch.no_grad()
    def _calculate_tree_loads(self, 
                              nodes_tensor: torch.Tensor, 
                              adj_matrix: torch.Tensor,
                              adj_matrix_T: torch.Tensor
                              ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:
        """ Adjacency Matrixë¥¼ ê¸°ë°˜ìœ¼ë¡œ íŠ¸ë¦¬ ì „ì²´ì˜ ì „ë¥˜/ì „ë ¥ì†ì‹¤/ì˜¨ë„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤. """
        
        batch_size, num_nodes, _ = nodes_tensor.shape
        
        # 1. ì´ˆê¸° ìˆ˜ìš” = Loadì˜ í™œì„± ì „ë¥˜
        current_demands = nodes_tensor[..., FEATURE_INDEX["current_active"]].clone()
        load_mask_1d = (self.node_type_tensor == NODE_TYPE_LOAD)
        current_demands[:, ~load_mask_1d] = 0.0
        
        adj_matrix_float = adj_matrix.float()
        
        ic_type = nodes_tensor[..., FEATURE_INDEX["ic_type_idx"]]
        ldo_mask_b = torch.isclose(ic_type, torch.tensor(1.0, device=ic_type.device))
        buck_mask_b = torch.isclose(ic_type, torch.tensor(2.0, device=ic_type.device))
        
        op_current = nodes_tensor[..., FEATURE_INDEX["op_current"]]
        vout = nodes_tensor[..., FEATURE_INDEX["vout_min"]]
        vin = nodes_tensor[..., FEATURE_INDEX["vin_min"]]
        safe_vin = torch.where(vin > 0, vin, 1e-6)
        eff_active = nodes_tensor[..., FEATURE_INDEX["efficiency_active"]]
        safe_eff_active = torch.where(eff_active > 0, eff_active, 0.9)
        min_fb_res = nodes_tensor[..., FEATURE_INDEX["min_fb_res"]]
        fb_current = torch.zeros_like(vout)
        valid_res_mask = (min_fb_res > 1e-6)
        fb_current[valid_res_mask] = vout[valid_res_mask] / min_fb_res[valid_res_mask]

        i_in_total = current_demands.clone() 

        for _ in range(num_nodes):
            i_out = (adj_matrix_float @ i_in_total.unsqueeze(-1)).squeeze(-1)            
            i_in_ldo = i_out + fb_current + op_current
            p_out_buck = vout * (i_out + fb_current)
            i_in_buck = (p_out_buck / safe_eff_active) / safe_vin
            new_ic_demands = torch.zeros_like(i_in_total)
            new_ic_demands[ldo_mask_b] = i_in_ldo[ldo_mask_b]
            new_ic_demands[buck_mask_b] = i_in_buck[buck_mask_b]
            new_i_in_total = current_demands + new_ic_demands
            if torch.allclose(i_in_total, new_i_in_total, atol=1e-8): break
            i_in_total = new_i_in_total

        i_out = (adj_matrix_float @ i_in_total.unsqueeze(-1)).squeeze(-1)
        power_loss = self._calculate_power_loss(nodes_tensor, i_out, ldo_mask_b, buck_mask_b)
        theta_ja = nodes_tensor[..., FEATURE_INDEX["theta_ja"]]
        ambient_temp = self.generator.config.constraints.get("ambient_temperature", 25.0)
        junction_temp = ambient_temp + power_loss * theta_ja
        
        return i_out, power_loss, junction_temp

    def _calculate_power_loss(self, 
                              ic_node_features: torch.Tensor, 
                              i_out: torch.Tensor,
                              ldo_mask: torch.Tensor,
                              buck_mask: torch.Tensor
                              ) -> torch.Tensor:
        """ I_outì„ ê¸°ë°˜ìœ¼ë¡œ ICì˜ ì „ë ¥ ì†ì‹¤(P_loss)ì„ ê³„ì‚°í•©ë‹ˆë‹¤. """
        vin = ic_node_features[..., FEATURE_INDEX["vin_min"]]
        vout = ic_node_features[..., FEATURE_INDEX["vout_min"]]
        op_current = ic_node_features[..., FEATURE_INDEX["op_current"]]
        min_fb_res = ic_node_features[..., FEATURE_INDEX["min_fb_res"]]
        fb_current = torch.zeros_like(vout)
        valid_res_mask = (min_fb_res > 1e-6)
        fb_current[valid_res_mask] = vout[valid_res_mask] / min_fb_res[valid_res_mask]

        power_loss = torch.zeros_like(i_out, dtype=ic_node_features.dtype)
        if ldo_mask.any():
            power_loss[ldo_mask] = (vin[ldo_mask] - vout[ldo_mask]) * (i_out[ldo_mask] + fb_current[ldo_mask]) + \
                                   vin[ldo_mask] * op_current[ldo_mask]
        if buck_mask.any():
            eff_active = ic_node_features[buck_mask, FEATURE_INDEX["efficiency_active"]]
            safe_eff = torch.where(eff_active > 0, eff_active, 0.9)
            p_out_buck = vout[buck_mask] * (i_out[buck_mask] + fb_current[buck_mask])
            conversion_loss = (p_out_buck / safe_eff) - p_out_buck
            power_loss[buck_mask] = conversion_loss 
        return power_loss
    
    @torch.no_grad()
    def _calculate_total_sleep_current(self, nodes=None, adj_matrix=None, adj_matrix_T=None, is_used_ic_mask=None, td=None) -> torch.Tensor:
        """ 
        [ìˆ˜ì •] ì¸ìë¥¼ ì§ì ‘ ë°›ì„ ìˆ˜ ìˆë„ë¡ ë³€ê²½í•˜ì—¬ ì‹œë®¬ë ˆì´ì…˜ ì§€ì› 
        """
        if td is not None:
            nodes = td["nodes"]
            adj_matrix = td["adj_matrix"]
            adj_matrix_T = td["adj_matrix_T"]
            is_used_ic_mask = td["is_used_ic_mask"]

        batch_size, num_nodes, _ = nodes.shape
        adj_matrix = adj_matrix.float()
        adj_matrix_T = adj_matrix_T.float()

        # 1. "Always-On" ìƒíƒœ ì „íŒŒ
        always_on_loads = (nodes[..., FEATURE_INDEX["always_on_in_sleep"]] == 1.0)
        always_on_nodes = always_on_loads.clone()
        always_on_nodes[:, BATTERY_NODE_IDX] = True
        
        for _ in range(num_nodes):
            parents_mask = (adj_matrix @ always_on_nodes.float().unsqueeze(-1)).squeeze(-1).bool()
            if (parents_mask & ~always_on_nodes).sum() == 0: break
            always_on_nodes |= parents_mask
        
        # 2. IC ìì²´ ì•”ì „ë¥˜
        is_ao = always_on_nodes
        is_used = is_used_ic_mask
        parent_is_ao = (adj_matrix_T @ is_ao.float().unsqueeze(-1)).squeeze(-1).bool()

        quiescent_current = nodes[..., FEATURE_INDEX["quiescent_current"]]
        shutdown_current = nodes[..., FEATURE_INDEX["shutdown_current"]]
        
        use_ishut_current = torch.where(shutdown_current > 1e-9, shutdown_current, quiescent_current)
        ic_self_sleep = torch.zeros(batch_size, num_nodes, device=self.device)
        
        # AO ìƒíƒœ: Iq
        ic_self_sleep[is_ao & is_used] = quiescent_current[is_ao & is_used]
        # ë¹„-AOì§€ë§Œ ë¶€ëª¨ On: Shutdown
        ic_self_sleep[~is_ao & is_used & parent_is_ao] = use_ishut_current[~is_ao & is_used & parent_is_ao]

        # í”¼ë“œë°± ì „ë¥˜
        vout = nodes[..., FEATURE_INDEX["vout_min"]]
        min_fb_res = nodes[..., FEATURE_INDEX["min_fb_res"]]
        fb_current_draw = torch.zeros_like(vout)
        valid_res_mask = (min_fb_res > 1e-6)
        fb_current_draw[valid_res_mask] = vout[valid_res_mask] / min_fb_res[valid_res_mask]
        fb_current_draw = fb_current_draw * always_on_nodes.float()
        
        shut_mask = ~is_ao & is_used & parent_is_ao
        ic_self_sleep[shut_mask] = shutdown_current[shut_mask]

        # 3. Load ì•”ì „ë¥˜
        load_sleep_draw_base = nodes[..., FEATURE_INDEX["current_sleep"]].clone()
        load_sleep_draw = load_sleep_draw_base * always_on_nodes.float()
        load_sleep_draw[~always_on_nodes] = 0.0

        # 4. ì „ë¥˜ ìˆ˜ìš” ì „íŒŒ
        current_demands_sleep = load_sleep_draw + ic_self_sleep
        
        ic_type = nodes[..., FEATURE_INDEX["ic_type_idx"]]
        ldo_mask_b = torch.isclose(ic_type, torch.tensor(1.0, device=ic_type.device))
        buck_mask_b = torch.isclose(ic_type, torch.tensor(2.0, device=ic_type.device))
        
        vin = nodes[..., FEATURE_INDEX["vin_min"]]
        safe_vin = torch.where(vin > 0, vin, 1e-6)
        eff_sleep_tensor = nodes[..., FEATURE_INDEX["efficiency_sleep"]]
        safe_eff_sleep = torch.where(eff_sleep_tensor > 0, eff_sleep_tensor, 0.35)
        
        for _ in range(num_nodes):
            i_out_sleep = (adj_matrix_T.transpose(-1, -2) @ current_demands_sleep.unsqueeze(-1)).squeeze(-1)
            new_demands_sleep = load_sleep_draw + ic_self_sleep
            
            # LDO
            ldo_demand = i_out_sleep[ldo_mask_b] + fb_current_draw[ldo_mask_b]
            new_demands_sleep[ldo_mask_b] += ldo_demand            

            # Buck
            i_out_buck = i_out_sleep[buck_mask_b]
            if_fb_buck = fb_current_draw[buck_mask_b]
            p_out_total_buck = vout[buck_mask_b] * (i_out_buck + if_fb_buck)
            eff = safe_eff_sleep[buck_mask_b]
            i_in_switching_buck = (p_out_total_buck / eff) / safe_vin[buck_mask_b]
            new_demands_sleep[buck_mask_b] += i_in_switching_buck
            
            if torch.allclose(current_demands_sleep, new_demands_sleep, atol=1e-8): break
            current_demands_sleep = new_demands_sleep

        # 5. ë°°í„°ë¦¬ ì´ ì•”ì „ë¥˜
        battery_children_mask = adj_matrix[:, BATTERY_NODE_IDX, :]
        total_sleep_current = (current_demands_sleep * battery_children_mask).sum(dim=1)
        
        return total_sleep_current