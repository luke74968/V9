# Copyright (c) 2025 Minuk Lee. All rights reserved.
# 
# This source code is proprietary and confidential.
# Unauthorized copying of this file, via any medium is strictly prohibited.
# 
# For licensing terms, see the LICENSE file.
# Contact: minuklee@snu.ac.kr
# 
import os
import sys
import time
import yaml
import json
import random
import torch
import logging
import argparse
import torch.distributed as dist

# (PyTorch 2.0+ TensorFloat32 ìµœì í™”)
if torch.cuda.is_available() and torch.cuda.get_device_capability(0)[0] >= 8:
    torch.set_float32_matmul_precision('high')

# --- í•µì‹¬ ëª¨ë“ˆ ì„í¬íŠ¸ ---
# (ì´ íŒŒì¼ë“¤ì€ ìš°ë¦¬ê°€ ë°©ê¸ˆ/ì•ìœ¼ë¡œ ë§Œë“¤ íŒŒì¼ë“¤ì…ë‹ˆë‹¤)
from .model import PocatModel
from .solver_env import PocatEnv
from .trainer import PocatTrainer
from .expert_dataset import ExpertReplayDataset # (Trainerê°€ ì‚¬ìš©í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì„í¬íŠ¸)


def setup_logger(result_dir, rank=0):
    """
    ë¡œê·¸ íŒŒì¼ì„ ì„¤ì •í•˜ê³ , 0ë²ˆ GPU(ë©”ì¸)ì—ì„œë§Œ ì½˜ì†” ì¶œë ¥ì„ í•˜ë„ë¡ ì„¤ì •í•©ë‹ˆë‹¤.
    """
    log_file = os.path.join(result_dir, 'log.txt')
    logging.basicConfig(
        filename=log_file, 
        format='%(asctime)-15s %(message)s', 
        level=logging.INFO
    )
    logger = logging.getLogger()
    
    # 0ë²ˆ í”„ë¡œì„¸ìŠ¤(ë©”ì¸)ì—ì„œë§Œ ì½˜ì†”ì— ë¡œê·¸ë¥¼ ì¶œë ¥
    if rank <= 0:
        console = logging.StreamHandler(sys.stdout)
        console.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)-15s %(message)s')
        console.setFormatter(formatter)
        logger.addHandler(console)
    return logger

def main(args):
    """
    ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ (DDP ì„¤ì •, í™˜ê²½/ëª¨ë¸/íŠ¸ë ˆì´ë„ˆ ì´ˆê¸°í™”)
    """
    
    # --- DDP (Distributed Data Parallel) ì„¤ì • ---
    args.local_rank = int(os.environ.get('LOCAL_RANK', -1))
    args.world_size = int(os.environ.get('WORLD_SIZE', 1))
    args.ddp = args.world_size > 1

    if args.ddp:
        dist.init_process_group(backend='nccl')
        torch.cuda.set_device(args.local_rank)
        device = torch.device(f"cuda:{args.local_rank}")
        if args.local_rank <= 0:
            args.log(f"ğŸš€ DDP ëª¨ë“œ ({args.world_size} GPUs) ì‹¤í–‰. ë””ë°”ì´ìŠ¤: {device}")
    else:
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        args.log(f"ğŸš€ ë‹¨ì¼ ë””ë°”ì´ìŠ¤ ëª¨ë“œ ì‹¤í–‰. ë””ë°”ì´ìŠ¤: {device}")
    # --- DDP ì„¤ì • ì™„ë£Œ ---

    # --- 1. config.yamlì—ì„œ N_MAX ê°’ ì¶”ì¶œ ---
    try:
        n_max = int(args.model_params['N_MAX'])
        args.log(f"Config loaded: N_MAX set to {n_max}")
    except (AttributeError, KeyError, TypeError, ValueError):
        args.log("âŒ CRITICAL: 'model_params: N_MAX:'ë¥¼ config.yamlì—ì„œ ì°¾ì„ ìˆ˜ ì—†ê±°ë‚˜ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return

    # --- 2. PocatEnv (í™˜ê²½) ìƒì„± ---
    # (N_max ê°’ì„ Generatorì™€ Env ì–‘ìª½ì— ì£¼ì…)
    env = PocatEnv(
        generator_params={
            "config_file_path": args.config_file,
        },
        device=device,
        N_max=n_max # Envê°€ Specì„ ìƒì„±í•  ë•Œ ì‚¬ìš©
    )

    # --- 3. PocatModel (ëª¨ë¸) ìƒì„± ì¤€ë¹„ ---
    # (args.model_params['N_MAX'] = n_max ëŠ” ì´ë¯¸ __main__ì—ì„œ ë¡œë“œë¨)
    
    # --- 4. PocatTrainer (íŠ¸ë ˆì´ë„ˆ) ìƒì„± ---
    trainer = PocatTrainer(args, env, device)

    # --- 5. Critic ì‚¬ì „í›ˆë ¨ (A2C ì•ˆì •í™”) ---
    if args.pretrain_critic:
        if args.local_rank <= 0: # 0ë²ˆ í”„ë¡œì„¸ìŠ¤ì—ì„œë§Œ ì‹¤í–‰
            trainer.pretrain_critic(
                expert_data_path=args.pretrain_critic, 
                pretrain_epochs=args.pretrain_epochs
            )
        if args.ddp:
            dist.barrier() # ëª¨ë“  í”„ë¡œì„¸ìŠ¤ê°€ ì‚¬ì „í›ˆë ¨ ì™„ë£Œê¹Œì§€ ëŒ€ê¸°

    # --- 6. ë©”ì¸ í›ˆë ¨ ë˜ëŠ” í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ---
    # [ì¶”ê°€] ì¤‘ìš” íŒŒë¼ë¯¸í„°ì— ëŒ€í•œ ì•ˆì „í•œ ê¸°ë³¸ê°’ ì²˜ë¦¬ (YAMLì—ë„ ì—†ê³  CLIë„ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì ìš©)
    if args.batch_size is None: args.batch_size = 64
    if args.num_pomo_samples is None: args.num_pomo_samples = 8
    
    # config.yamlì˜ 'pomo_size'ë¥¼ 'args.pomo_size'ë¡œ ë¡œë“œí•˜ë¯€ë¡œ, ì´ë¥¼ Trainerê°€ ì“¸ ìˆ˜ ìˆê²Œ ë§¤í•‘
    if not hasattr(args, 'pomo_size') and args.num_pomo_samples is not None:
        args.pomo_size = args.num_pomo_samples

    if args.test_only:
        if args.local_rank <= 0: # í…ŒìŠ¤íŠ¸ëŠ” 0ë²ˆ í”„ë¡œì„¸ìŠ¤ì—ì„œë§Œ
            trainer.test()
    else:
        trainer.run() # í›ˆë ¨ (DDP/ë‹¨ì¼ ëª¨ë“œ ëª¨ë‘ ì‹¤í–‰)
    
    if args.ddp:
        dist.destroy_process_group()

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    
    # --- ì‹¤í–‰ ê²½ë¡œ ë° ì„¤ì • ---
    parser.add_argument("--config_file", type=str, default="configs/config.json", help="Path to POCAT config file")
    parser.add_argument("--config_yaml", type=str, default="configs/config.yaml", help="Path to model/training config YAML")
    parser.add_argument("--seed", type=int, default=1234, help="Random seed")

    # [ìˆ˜ì •] default=Noneìœ¼ë¡œ ë³€ê²½í•˜ì—¬ config.yaml ê°’ì´ ìš°ì„  ì ìš©ë˜ë„ë¡ í•¨
    parser.add_argument("--batch_size", type=int, default=None, help="Training batch_size (per GPU)")
    parser.add_argument("--num_pomo_samples", type=int, default=None, 
                        help="Number of POMO samples. (Matches 'pomo_size' in config)")

    # --- Critic ì‚¬ì „í›ˆë ¨ ---
    parser.add_argument('--pretrain_critic', type=str, default=None, 
                        help="Path to expert_data.json for Critic pre-training.")
    parser.add_argument('--pretrain_epochs', type=int, default=5, help="Number of epochs for Critic pre-training.")    

    # --- ì¶”ë¡ (Test) / ëª¨ë¸ ë¡œë“œ ---
    parser.add_argument('--test_only', action='store_true', help="Only run test/inference")
    parser.add_argument('--load_path', type=str, default=None, help="Path to a saved model checkpoint (.pth)")
    parser.add_argument("--test_num_pomo_samples", type=int, default=None, 
                        help="Number of POMO samples for testing. (Defaults to num_pomo_samples)")
    parser.add_argument('--decode_type', type=str, default='greedy', choices=['greedy', 'sampling'],
                        help="Decoding strategy for test mode: 'greedy' or 'sampling'.")

    # --- ë¡œê·¸ ê´€ë ¨ ---
    parser.add_argument('--log_idx', type=int, default=0, help='Instance index to log (for POMO)')
    parser.add_argument('--log_mode', type=str, default='progress', choices=['progress', 'detail'],
                        help="Logging mode: 'progress' (pbar) or 'detail' (step-by-step).")

    args = parser.parse_args()

    if args.test_num_pomo_samples is None and args.num_pomo_samples is not None:
       args.test_num_pomo_samples = args.num_pomo_samples

    # --- ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬ ë° ë¡œê±° ì„¤ì • ---
    args.start_time = time.strftime("%Y-%m%d-%H%M%S", time.localtime())
    args.result_dir = os.path.join('result_transformer', args.start_time)
    
    # (DDP ë­í¬ 0ë§Œ ë””ë ‰í† ë¦¬ ìƒì„± ì‹œë„)
    local_rank_init = int(os.environ.get('LOCAL_RANK', 0))
    #if local_rank_init <= 0:
    os.makedirs(args.result_dir, exist_ok=True)
        
    logger = setup_logger(args.result_dir, rank=local_rank_init)
    args.log = logger.info
    
    # --- YAML ì„¤ì • íŒŒì¼ ë¡œë“œ ---
    # (YAML íŒŒì¼ì˜ ëª¨ë“  ì„¤ì •ì„ args ê°ì²´ì— ë³‘í•©)
    try:
        with open(args.config_yaml, "r", encoding="utf-8") as f:
            cfg_yaml = yaml.safe_load(f)
        for key, value in cfg_yaml.items():
            if not hasattr(args, key):
                setattr(args, key, value)
            # (ëª…ë ¹ì¤„ ì¸ìê°€ None/Falseì¼ ë•Œ YAML ê°’ìœ¼ë¡œ ë®ì–´ì“°ê¸°)
            elif getattr(args, key) is None or isinstance(getattr(args, key), bool):
                 setattr(args, key, value)
    except FileNotFoundError:
        logger.error(f"âŒ CRITICAL: config.yaml íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {args.config_yaml}")
        sys.exit(1)
    except Exception as e:
        logger.error(f"âŒ CRITICAL: config.yaml íŒŒì¼ íŒŒì‹± ì˜¤ë¥˜: {e}")
        sys.exit(1)


    # --- DDP ì†ì„± ë° ì‹œë“œ ì„¤ì • (main í•¨ìˆ˜ í˜¸ì¶œ ì „) ---
    # (main í•¨ìˆ˜ ë‚´ì˜ DDP ì„¤ì • ë¡œì§ì„ ì—¬ê¸°ì„œ ë¯¸ë¦¬ ì‹¤í–‰)
    args.world_size = int(os.environ.get('WORLD_SIZE', 1))
    args.ddp = args.world_size > 1
    
    seed = args.seed
    if args.ddp:
        seed += local_rank_init # DDP ë­í¬ë³„ ì˜¤í”„ì…‹ ì¶”ê°€
        
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    random.seed(seed)
    # np.random.seed(seed) # (numpy ì‚¬ìš©í•˜ëŠ” ê²½ìš°)

    # --- ì‹¤í–‰ ì¸ì ë¡œê·¸ ê¸°ë¡ ---
    if local_rank_init <= 0:
        args_dict_for_log = {k: v for k, v in vars(args).items() if k != 'log'}
        args.log("--- ğŸš€ ì‹¤í–‰ ì¸ì (Args) ---")
        args.log(json.dumps(args_dict_for_log, indent=4, default=str))
        args.log("---------------------------")
        
    main(args)