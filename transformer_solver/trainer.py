# Copyright (c) 2025 Minuk Lee. All rights reserved.
# 
# This source code is proprietary and confidential.
# Unauthorized copying of this file, via any medium is strictly prohibited.
# 
# For licensing terms, see the LICENSE file.
# Contact: minuklee@snu.ac.kr
# 
import torch
import torch.nn.functional as F
from torch.nn.parallel import DistributedDataParallel as DDP
import torch.distributed as dist
from torch.utils.data import DataLoader
from tensordict import TensorDict
# AMP ëª¨ë“ˆì„ torch.ampë¡œ ë³€ê²½í•œë‹¤.
from torch.amp import GradScaler, autocast

from tqdm import tqdm
import os
import time
from datetime import datetime
import logging
from collections import defaultdict, Counter
import json

# --- í•µì‹¬ ëª¨ë“ˆ ì„í¬íŠ¸ ---
from .model import PocatModel, PrecomputedCache, reshape_by_heads
from .solver_env import PocatEnv, BATTERY_NODE_IDX
from .expert_dataset import ExpertReplayDataset, expert_collate_fn
from .utils.common import TimeEstimator, clip_grad_norms, unbatchify, batchify

# --- ì‹œê°í™” ëª¨ë“ˆ ì„í¬íŠ¸ ---
from graphviz import Digraph
from common.data_classes import LDO, BuckConverter # (common)
from .definitions import FEATURE_INDEX, NODE_TYPE_LOAD, NODE_TYPE_IC, NODE_TYPE_BATTERY, NODE_TYPE_EMPTY

def update_progress(pbar, metrics, step):
    """ tqdm ì§„í–‰ë¥  í‘œì‹œì¤„ì„ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤. """
    if pbar is None:
        return
    
    metrics_str = (
        f"Loss: {metrics['Loss']:.4f} "
        f"($Avg: {metrics['Avg Cost']:.2f}, $AvgMin: {metrics['Avg Min Batch']:.2f}, $Min: {metrics['Min Cost']:.2f})| " 
        f"Ent: {metrics['Entropy']:.4f} | "
        f"BOM ${metrics['Avg BOM']:.2f} + Sleep {metrics['Avg Sleep']:.1f}"
    )
    pbar.set_postfix_str(metrics_str, refresh=False)
    pbar.update(1)


def cal_model_size(model, log_func):
    """ ëª¨ë¸ì˜ íŒŒë¼ë¯¸í„° ë° ë²„í¼ í¬ê¸°ë¥¼ ê³„ì‚°í•˜ì—¬ ë¡œê·¸ì— ê¸°ë¡í•©ë‹ˆë‹¤. """
    param_count = sum(p.nelement() for p in model.parameters() if p.requires_grad)
    buffer_count = sum(b.nelement() for b in model.buffers())
    log_func(f'ëª¨ë¸ íŒŒë¼ë¯¸í„° ìˆ˜: {param_count:,}')
    log_func(f'ëª¨ë¸ ë²„í¼ ìˆ˜: {buffer_count:,}')

class PocatTrainer:
    """
    PocatModelê³¼ PocatEnvë¥¼ ì‚¬ìš©í•˜ì—¬ í›ˆë ¨, ê²€ì¦, í…ŒìŠ¤íŠ¸ë¥¼
    ìˆ˜í–‰í•˜ëŠ” ë©”ì¸ íŠ¸ë ˆì´ë„ˆ í´ë˜ìŠ¤ì…ë‹ˆë‹¤. (A2C ê¸°ë°˜)
    """
    
    def __init__(self, args, env: PocatEnv, device: str):
        self.args = args
        self.env = env
        self.is_ddp = args.ddp
        self.local_rank = args.local_rank
        self.device = device

        self.result_dir = args.result_dir
        self.log = args.log

        # --- 1. ëª¨ë¸ ì´ˆê¸°í™” ë° DDP ë˜í•‘ ---
        self.model = PocatModel(**args.model_params).to(self.device)
        
        if self.is_ddp:
            self.model = DDP(
                self.model, 
                device_ids=[self.local_rank], 
                find_unused_parameters=True # (ëª¨ë¸ì€ ëª¨ë“  íŒŒë¼ë¯¸í„° ì‚¬ìš©)
            )
        
        if self.local_rank <= 0:
            cal_model_size(self.model, self.log)
        
        # --- 2. ì˜µí‹°ë§ˆì´ì € ë° ìŠ¤ì¼€ì¤„ëŸ¬ ---
        self.optimizer = torch.optim.AdamW(
            self.model.parameters(),
            lr=float(args.optimizer_params['optimizer']['lr']),
            weight_decay=float(args.optimizer_params['optimizer'].get('weight_decay', 0)),
        )
        
        if args.optimizer_params['scheduler']['name'] == 'MultiStepLR':
            self.scheduler = torch.optim.lr_scheduler.MultiStepLR(
                self.optimizer,
                milestones=args.optimizer_params['scheduler']['milestones'],
                gamma=args.optimizer_params['scheduler']['gamma']
            )
        else:
            raise NotImplementedError
            
        self.start_epoch = 1


        # [AMP] Mixed Precision Scaler ì´ˆê¸°í™”
        # configì— use_ampê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ False
        self.use_amp = getattr(args, 'use_amp', False)
        self.scaler = GradScaler(enabled=self.use_amp)
        
        if self.local_rank <= 0 and self.use_amp:
            self.log("âš¡ Mixed Precision (AMP) Training Enabled.")

        # --- 3. ëª¨ë¸ ë¡œë“œ (Checkpoint) ---
        if args.load_path is not None:
            self.log(f"ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ì¤‘: {args.load_path}")
            try:
                checkpoint = torch.load(args.load_path, map_location=device, weights_only=False)
                
                # DDP/ì¼ë°˜ ëª¨ë¸ ìƒíƒœ í˜¸í™˜ ë¡œë“œ
                model_to_load = self.model.module if self.is_ddp else self.model
                model_to_load.load_state_dict(checkpoint['model_state_dict'])
                
                if not args.test_only: # í›ˆë ¨ ì¬ê°œ ì‹œ
                    self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
                    self.start_epoch = checkpoint['epoch'] + 1
                self.log("ëª¨ë¸ ë¡œë“œ ì™„ë£Œ.")
            except Exception as e:
                self.log(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}. ë¬´ì‘ìœ„ ì´ˆê¸°í™”ë¡œ ì‹œì‘í•©ë‹ˆë‹¤.")

        self.time_estimator = TimeEstimator(log_fn=self.log)

        # --- 4. ê²€ì¦(Evaluate)ìš© ë°ì´í„°ì…‹ ---
        # [ìˆ˜ì •] Clean / Crisis ê²€ì¦ ë°ì´í„°ì…‹ ë¡œë“œ
        self.val_datasets = {}
        self.best_eval_bom = float("inf") # Clean Set ê¸°ì¤€ Best

        if self.local_rank <= 0:  # 0ë²ˆ GPUì—ì„œë§Œ ë¡œë“œ
            val_base_path = "validation_data"
            clean_path = os.path.join(val_base_path, "val_set_TII_100_clean.pt")
            crisis_path = os.path.join(val_base_path, "val_set_TII_100_crisis.pt")
            
            def load_safe(path):
                if not os.path.exists(path): return None
                try:
                    # 1. íŒŒì¼ ë¡œë“œ
                    loaded = torch.load(path, weights_only=False)
                    
                    # 2. [í•µì‹¬] ë”•ì…”ë„ˆë¦¬ í¬ì¥("tensor_data")ì´ ë˜ì–´ ìˆìœ¼ë©´ ë‚´ìš©ë¬¼ë§Œ êº¼ëƒ„
                    if isinstance(loaded, dict) and "tensor_data" in loaded:
                        data = loaded["tensor_data"]
                    else:
                        data = loaded # êµ¬ë²„ì „ íŒŒì¼ í˜¸í™˜

                    # 3. CPUë¡œ ì´ë™ (TensorDictì¸ ê²½ìš°)
                    if hasattr(data, "to"):
                        return data.to("cpu")
                    return data
                    
                except Exception as e:
                    print(f"âš ï¸ Validation Data Load Error ({path}): {e}")
                    return None

            # [Clean Set]
            if os.path.exists(clean_path):
                self.log(f"ğŸ“‚ Validation Clean Set ë¡œë“œ ì¤‘: {clean_path}")
                self.val_datasets["clean"] = load_safe(clean_path)  # CPU ë³´ê´€
            else:
                self.log(f"âš ï¸ Clean Validation íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {clean_path}")

            # [Crisis Set]
            if os.path.exists(crisis_path):
                self.log(f"ğŸ“‚ Validation Crisis Set ë¡œë“œ ì¤‘: {crisis_path}")
                self.val_datasets["crisis"] = load_safe(crisis_path)
            else:
                self.log(f"âš ï¸ Crisis Validation íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {crisis_path}")

    def pretrain_critic(self, expert_data_path: str, pretrain_epochs: int = 5):
        """
        'ì •ë‹µì§€(Expert)' ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•˜ì—¬ A2C ëª¨ë¸ì˜ Critic(Value Head)ë§Œ
        ì§€ë„í•™ìŠµ ë°©ì‹ìœ¼ë¡œ ì‚¬ì „í›ˆë ¨í•©ë‹ˆë‹¤.
        """
        args = self.args
        self.log("=================================================================")
        self.log(f"ğŸ§  Critic ì‚¬ì „í›ˆë ¨(Pre-training) ì‹œì‘...")
        
        try:
            expert_dataset = ExpertReplayDataset(
                expert_data_path=expert_data_path, 
                env=self.env, 
                device=self.device
            )
            if len(expert_dataset) == 0:
                self.log("âŒ ì˜¤ë¥˜: 'ì •ë‹µì§€' ë°ì´í„°ì…‹ì´ ë¹„ì–´ìˆì–´ ì‚¬ì „í›ˆë ¨ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
                return
            
            expert_loader = DataLoader(
                expert_dataset,
                batch_size=args.batch_size, # í›ˆë ¨ ë°°ì¹˜ í¬ê¸° ì¬ì‚¬ìš©
                shuffle=True,
                num_workers=0,
                collate_fn=expert_collate_fn # TensorDictìš© ì»¤ìŠ¤í…€ Collate
            )
        except Exception as e:
            self.log(f"âŒ ì˜¤ë¥˜: 'ì •ë‹µì§€' ë°ì´í„°ì…‹ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return

        # Critic íŒŒë¼ë¯¸í„°ë§Œ í•™ìŠµí•˜ëŠ” ë³„ë„ì˜ ì˜µí‹°ë§ˆì´ì € ìƒì„±
        model_to_train = self.model.module if self.is_ddp else self.model
        critic_params = list(model_to_train.decoder.value_head.parameters()) + \
                        list(model_to_train.decoder.Wq_context.parameters()) + \
                        list(model_to_train.decoder.multi_head_combine.parameters())
                        
        critic_optimizer = torch.optim.AdamW(
            critic_params,
            lr=float(args.optimizer_params['optimizer']['lr'])
        )

        self.model.train()

        for epoch in range(1, pretrain_epochs + 1):
            pbar = tqdm(expert_loader, desc=f"Critic Pre-train Epoch {epoch}/{pretrain_epochs}", dynamic_ncols=True)
            total_v_loss = 0
            
            for state_td_batch, target_reward_batch in pbar:
                critic_optimizer.zero_grad()
                
                # (B, 1, ...) -> (B, ...)
                state_td_batch = state_td_batch.squeeze(1)
                
                # --- ëª¨ë¸ ì¸ì½”ë”© ë° ìºì‹œ ìƒì„± ---
                prompt_embedding = model_to_train.prompt_net(
                    state_td_batch["scalar_prompt_features"], 
                    state_td_batch["matrix_prompt_features"]
                )
                encoded_nodes = model_to_train.encoder(state_td_batch, prompt_embedding)
                
                glimpse_key = reshape_by_heads(model_to_train.decoder.Wk_glimpse(encoded_nodes), model_to_train.decoder.head_num)
                glimpse_val = reshape_by_heads(model_to_train.decoder.Wv_glimpse(encoded_nodes), model_to_train.decoder.head_num)
                logit_key_connect = model_to_train.decoder.Wk_connect_logit(encoded_nodes).transpose(1, 2)
                logit_key_spawn = model_to_train.decoder.Wk_spawn_logit(encoded_nodes).transpose(1, 2)
                
                cache = PrecomputedCache(
                    encoded_nodes, glimpse_key, glimpse_val, 
                    logit_key_connect, logit_key_spawn
                )
                
                # --- ë””ì½”ë” í˜¸ì¶œ (Valueë§Œ ì‚¬ìš©) ---
                _, _, _, predicted_value = model_to_train.decoder(state_td_batch, cache)
                
                # V_Loss ê³„ì‚°: Criticì˜ ì˜ˆì¸¡ vs "ì •ë‹µì§€"ì˜ ì‹¤ì œ ë³´ìƒ
                critic_loss = F.mse_loss(predicted_value, target_reward_batch)
                
                critic_loss.backward()
                critic_optimizer.step()
                
                total_v_loss += critic_loss.item()
                pbar.set_postfix({"V_Loss (Pre)": f"{critic_loss.item():.4f}"})

            self.log(f"Critic Pre-train Epoch {epoch} | Avg V_Loss: {total_v_loss / len(expert_loader):.4f}")

        self.log("âœ… Critic ì‚¬ì „í›ˆë ¨ ì™„ë£Œ.")
        self.log("=================================================================")

    def run(self):
        """ ë©”ì¸ í›ˆë ¨ ë£¨í”„ (A2C) """
        args = self.args
        self.time_estimator.reset(self.start_epoch)
        
        if args.test_only:
            self.test()
            return

        for epoch in range(self.start_epoch, args.trainer_params['epochs'] + 1):
            if self.local_rank <= 0:
                self.log('=' * 60)
            
            self.model.train()
            
            # (DDP) DDP Samplerê°€ ì—í­ë§ˆë‹¤ ì‹œë“œë¥¼ ë³€ê²½í•˜ë„ë¡ ì„¤ì •
            #if self.is_ddp and hasattr(self.env_dataset, 'sampler'):
            #    self.env_dataset.sampler.set_epoch(epoch)
            
            #  ê·¸ë˜ë””ì–¸íŠ¸ ëˆ„ì  ìŠ¤í… ì„¤ì • (ê¸°ë³¸ê°’ 1: ëˆ„ì  ì•ˆ í•¨)
            accumulation_steps = args.trainer_params.get('gradient_accumulation_steps')
            if accumulation_steps is None:
                accumulation_steps = 1

            # ì‹¤ì œ ë£¨í”„ íšŸìˆ˜ëŠ” (ëª©í‘œ ì—…ë°ì´íŠ¸ íšŸìˆ˜ * ëˆ„ì  ìŠ¤í…)ìœ¼ë¡œ ëŠ˜ì–´ë‚¨
            total_steps = args.trainer_params['train_step'] * accumulation_steps
            
            # (DDP) 0ë²ˆ GPUì—ì„œë§Œ tqdm ì§„í–‰ë¥  í‘œì‹œ
            train_pbar = None
            if self.local_rank <= 0:
                train_pbar = tqdm(
                    total=total_steps,
                    desc=f"Epoch {epoch}",
                    dynamic_ncols=True,
                )
            
            total_loss = 0.0
            total_cost = 0.0
            total_min_batch_cost = 0.0 
            total_policy_loss = 0.0
            total_critic_loss = 0.0
            min_epoch_cost = float('inf')

            # [ì¶”ê°€] ì—”íŠ¸ë¡œí”¼ ê°€ì¤‘ì¹˜ ìŠ¤ì¼€ì¤„ë§ (Exponential Decay)
            # Epoch 1: 0.01 -> Epoch 20: ~0.019 -> Epoch 50: ~0.004
            current_entropy_weight = max(0.01, 0.1 * (0.99 ** (epoch - 1)))

            self.optimizer.zero_grad() # [ì´ë™] ë£¨í”„ ì‹œì‘ ì „ ìµœì´ˆ 1íšŒ ì´ˆê¸°í™”

            for step in range(1, total_steps + 1):

                # -----------------------------------------------------------
                # ë°ì´í„° ìƒì„± íŒŒì´í”„ë¼ì¸ ë³€ê²½ (Random Batch + POMO)
                # -----------------------------------------------------------
                pomo_size = getattr(args, 'pomo_size', 16)  # Configì—ì„œ ë¡œë“œ (ê¸°ë³¸ê°’ 16)
                
                # env.reset ëŒ€ì‹  Generator ì§ì ‘ í˜¸ì¶œ
                # td shape: [Batch, POMO, N, D]
                raw_td = self.env.generator.generate_random_batch(
                    batch_size=args.batch_size, 
                    device=self.device
                )
                
                # 2. í™˜ê²½ ì´ˆê¸°í™” (Environment Reset)
                # ìƒì„±ëœ ë¬¸ì œ(raw_td)ë¥¼ resetì— ì „ë‹¬í•˜ì—¬ ë™ì  ìƒíƒœ('done' ë“±)ë¥¼ ì´ˆê¸°í™”í•¨
                td = self.env.reset(init_td=raw_td, current_epoch=epoch)

                # ------------------------------------------------------------------
                # ëœë¤ ìƒì„±ëœ ì‹¤ì œ Layout ì •ë³´ ë¡œê·¸ (ì—í­ì˜ ì²« ìŠ¤í…ë§Œ ì¶œë ¥)
                # ------------------------------------------------------------------
                if self.local_rank <= 0 and step == 1:
                    node_types = td["nodes"][0, :, FEATURE_INDEX["node_type"][0]:FEATURE_INDEX["node_type"][1]].argmax(-1)
                    n_b = (node_types == NODE_TYPE_BATTERY).sum().item()
                    n_l = (node_types == NODE_TYPE_LOAD).sum().item()
                    n_ic = (node_types == NODE_TYPE_IC).sum().item()
                    n_e = (node_types == NODE_TYPE_EMPTY).sum().item()
                    self.log(f"ğŸ² [Epoch {epoch} Sample] Layout: [{n_b} B] + [{n_l} L] + [{n_ic} T] + [{n_e} E] (Total: {self.env.N_max})")


                # 3. ëª¨ë¸ í¬ì›Œë“œ (ì†”ë£¨ì…˜ ìƒì„±)
                # AMP ì ìš©ì„ ìœ„í•´ autocast ì»¨í…ìŠ¤íŠ¸ì—ì„œ ìˆ˜í–‰
                with autocast(device_type='cuda', enabled=self.use_amp):
                    out = self.model(
                        td, self.env, decode_type='sampling', pbar=train_pbar,
                        status_msg=f"Epoch {epoch}", log_fn=self.log,
                        log_idx=args.log_idx, log_mode=args.log_mode,
                        return_final_td=True
                    )
                
                # 4. A2C ì†ì‹¤ ê³„ì‚°
                # ê¸°ì¡´: reward = out["reward"].view(args.batch_size, pomo_size)
                # ìˆ˜ì •: -1ì„ ì‚¬ìš©í•˜ì—¬ ì‹¤ì œ POMO ê°œìˆ˜ì— ë§ê²Œ ìë™ Reshape
                
                # out["reward"] shape: (Batch * Actual_POMO, 1)
                # -> (Batch, Actual_POMO)
                reward = out["reward"].view(args.batch_size, -1)
                log_likelihood = out["log_likelihood"].view(args.batch_size, -1)
                
                bom_cost = out["bom_cost"].view(args.batch_size, -1)
                sleep_cost = out["sleep_cost"].view(args.batch_size, -1)    



                """
                Critic ë¶€ë¶„ 
                # Critic Loss (V(s)ê°€ ì‹¤ì œ ë³´ìƒ(G)ì„ ì˜ˆì¸¡í•˜ë„ë¡)
                critic_loss = F.mse_loss(value, reward)

                # Policy Loss (Actor)
                # baseline: (B_origin, 1) -> ê° ë¬¸ì œë³„ (Aug*POMO) ì „ì²´ í‰ê· 
                advantage = reward - value.detach() # Baseline = V(s)
                policy_loss = -(advantage * log_likelihood).mean()

                # Total Loss (A2C)
                loss = policy_loss + 0.5 * critic_loss
                """
                
                # 1. POMO Baseline (í˜„ì¬ ë°°ì¹˜ì˜ í‰ê· )
                pomo_baseline = reward.mean(dim=1, keepdim=True)
                
                advantage = reward - pomo_baseline
                if advantage.numel() > 1:
                    advantage = (advantage - advantage.mean()) / (advantage.std() + 1e-8)

                policy_loss = -(advantage * log_likelihood).mean()
                # ì—”íŠ¸ë¡œí”¼ ì†ì‹¤ ì¶”ê°€ (Maximize Entropy)
                entropy_loss = - current_entropy_weight * out["entropy"].mean()
                loss = policy_loss + entropy_loss

                # 5. ì—­ì „íŒŒ (AMP: lossë¥¼ ìŠ¤ì¼€ì¼ë§ í›„ backprop)
                self.scaler.scale(loss / accumulation_steps).backward()

                # ì§€ì •ëœ ëˆ„ì  ìŠ¤í…ë§ˆë‹¤ ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸ ìˆ˜í–‰
                if step % accumulation_steps == 0:
                    max_norm = float(self.args.optimizer_params.get('max_grad_norm', 0))
                    if max_norm > 0:
                        # ìŠ¤ì¼€ì¼ëœ ê·¸ë˜ë””ì–¸íŠ¸ í´ë¦¬í•‘ì„ ìœ„í•´ unscale ì‹¤í–‰
                        self.scaler.unscale_(self.optimizer)
                        clip_grad_norms(self.optimizer.param_groups, max_norm=max_norm)
                    self.scaler.step(self.optimizer)
                    self.scaler.update()
                    self.optimizer.zero_grad(set_to_none=True)

                # (DDP) ëª¨ë“  GPUì˜ í†µê³„ë¥¼ ì§‘ê³„
                if self.is_ddp:
                    dist.all_reduce(loss, op=dist.ReduceOp.AVG)
                    dist.all_reduce(policy_loss, op=dist.ReduceOp.AVG)
                    #dist.all_reduce(critic_loss, op=dist.ReduceOp.AVG)
                    # (min_costëŠ” all_reduce(op=dist.ReduceOp.MIN) í•„ìš”)
                
                # (DDP) 0ë²ˆ GPUì—ì„œë§Œ ë¡œê·¸ ê¸°ë¡
                if self.local_rank <= 0:
                    avg_cost = -reward.mean().item()
                    avg_bom = bom_cost.mean().item()
                    avg_sleep = sleep_cost.mean().item()
                    min_batch_cost = -reward.max().item()
                    total_min_batch_cost += min_batch_cost
                    min_epoch_cost = min(min_epoch_cost, min_batch_cost)

                    total_loss += loss.item()
                    total_cost += avg_cost
                    total_policy_loss += policy_loss.item()
                    #total_critic_loss += critic_loss.item()

                    # [ìˆ˜ì •] ë³€ìˆ˜ ì„ ì–¸ ìœ„ì¹˜ í™•ì¸ (Rank 0 ë¸”ë¡ ë‚´ë¶€)
                    avg_entropy_val = out["entropy"].mean().item()

                    update_progress(
                        train_pbar,
                        {
                            "Loss": loss.item(),
                            "Avg Cost": total_cost / step,
                            "Avg Min Batch": total_min_batch_cost / step, # [ì¶”ê°€] ë°°ì¹˜ë³„ ìµœì†Œê°’ì˜ í‰ê· 
                            "Min Cost": min_epoch_cost,
                            "Entropy": avg_entropy_val, # [ì¶”ê°€]
                            "Avg BOM": avg_bom,    # [ì¶”ê°€]
                            "Avg Sleep": avg_sleep # [ì¶”ê°€]
                        },
                        step
                    )

            if train_pbar:
                train_pbar.close()

            # ì—í­ì´ ëë‚  ë•Œ í•œ ë²ˆ ë” ìºì‹œ ì •ë¦¬
            if torch.cuda.is_available():
                torch.cuda.empty_cache()

            # (DDP) 0ë²ˆ GPUì—ì„œë§Œ ì—í­ ìš”ì•½, ê²€ì¦, ì €ì¥
            if self.local_rank <= 0:
                epoch_summary = (
                    f"Epoch {epoch}/{args.trainer_params['epochs']} | "
                    f"Avg Loss {total_loss / total_steps:.4f} | "
                    f"P_Loss {total_policy_loss / total_steps:.4f} | "
                    #f"V_Loss {total_critic_loss / total_steps:.4f} | "
                    f"Min Cost ${min_epoch_cost:.2f}"
                )
                tqdm.write(epoch_summary)
                self.log(epoch_summary)
                
                # --- ê²€ì¦ (Evaluate) ---
                val_metrics = self.evaluate(epoch)
                
                # ë¡œê·¸ ì¶œë ¥
                log_msg = f"[Eval Summary] Epoch {epoch}"
                if "clean" in val_metrics:
                    c = val_metrics["clean"]
                    log_msg += f" | Clean: ${c['avg_bom']:.2f} (Feas: {c['feasibility']*100:.0f}%)"
                if "crisis" in val_metrics:
                    c = val_metrics["crisis"]
                    log_msg += f" | Crisis: ${c['avg_bom']:.2f} (Feas: {c['feasibility']*100:.0f}%)"
                self.log(log_msg)

                # --- ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ---
                if (epoch % args.trainer_params['model_save_interval'] == 0) or \
                   (epoch == args.trainer_params['epochs']):
                       
                    save_path = os.path.join(args.result_dir, f'epoch-{epoch}.pth')
                    self.log(f"ëª¨ë¸ ì €ì¥ ì¤‘... (Epoch {epoch} -> {save_path})")
                    self._run_test_visualization(epoch, is_best=False) # ì‹œê°í™”
                    
                    model_state_dict = self.model.module.state_dict() if self.is_ddp else self.model.state_dict()
                    torch.save({
                        'epoch': epoch,
                        'model_state_dict': model_state_dict,
                        'optimizer_state_dict': self.optimizer.state_dict(),
                    }, save_path)

            self.scheduler.step()

            if self.local_rank <= 0:
                self.time_estimator.print_est_time(epoch, args.trainer_params['epochs'])
            
            if self.is_ddp:
                dist.barrier() # ì—í­ ì¢…ë£Œ ì‹œ ëª¨ë“  GPU ë™ê¸°í™”

        if self.local_rank <= 0:
            self.log(" *** í›ˆë ¨ ì™„ë£Œ *** ")

    @torch.no_grad()
    def validate_on_dataset(self, dataset_td: TensorDict, desc: str):
        """ íŠ¹ì • ë°ì´í„°ì…‹ì— ëŒ€í•´ Greedy í‰ê°€ë¥¼ ìˆ˜í–‰í•˜ê³  ë©”íŠ¸ë¦­ ë°˜í™˜ """
        self.model.eval()
        
        total_instances = dataset_td.shape[0]
        batch_size = 16 # í‰ê°€ ë°°ì¹˜ í¬ê¸°
        
        total_bom_cost = 0.0
        total_sleep_penalty = 0.0  # [ì¶”ê°€] ì•”ì „ë¥˜ í˜ë„í‹° í•©ê³„
        total_fail_penalty = 0.0   # [ì¶”ê°€] ì‹¤íŒ¨ í˜ë„í‹° í•©ê³„
        total_feasible_count = 0   # [ì¶”ê°€] ì„±ê³µ(Feasible)í•œ ì¼€ì´ìŠ¤ ìˆ˜
        
        num_batches = (total_instances + batch_size - 1) // batch_size
        
        for i in range(num_batches):
            start_idx = i * batch_size
            end_idx = min((i + 1) * batch_size, total_instances)
            current_batch_size = end_idx - start_idx
            
            # ... (ë°°ì¹˜ ë¡œë“œ ë° ëª¨ë¸ ì‹¤í–‰ ì½”ë“œëŠ” ê¸°ì¡´ê³¼ ë™ì¼) ...
            
            # --- ê²°ê³¼ ë¶„ì„ (ìƒì„¸ ë¦¬ì›Œë“œ ì§‘ê³„) ---
            # out["log_reward_..."] shape: (Batch * POMO, 1) -> (Batch, POMO)
            # ìš°ë¦¬ëŠ” Greedy í‰ê°€ì´ë¯€ë¡œ POMO ì¤‘ ê°€ì¥ ì¢‹ì€ ê²ƒ(Max Reward)ì„ ì„ íƒí•´ì•¼ í•¨
            
            # 1. ì „ì²´ ë¦¬ì›Œë“œ ê¸°ì¤€ Best ì¸ë±ìŠ¤ ì°¾ê¸°
            total_reward = out["reward"].view(current_batch_size, -1)
            best_values, best_indices = total_reward.max(dim=1) # (Batch,)
            
            # 2. ê° ìƒì„¸ ë¦¬ì›Œë“œ ê°€ì ¸ì˜¤ê¸°
            # log_reward_bom: (Batch, POMO)
            r_bom = out["log_reward_bom"].view(current_batch_size, -1)
            r_sleep = out["log_reward_sleep"].view(current_batch_size, -1)
            r_fail = out["log_reward_fail"].view(current_batch_size, -1)
            
            # 3. Best ì¸ë±ìŠ¤ì— í•´ë‹¹í•˜ëŠ” ê°’ë§Œ ì¶”ì¶œ (gather)
            # (Batch, 1)
            best_indices_unsqueezed = best_indices.unsqueeze(-1)
            
            best_r_bom = r_bom.gather(1, best_indices_unsqueezed).squeeze(-1)
            best_r_sleep = r_sleep.gather(1, best_indices_unsqueezed).squeeze(-1)
            best_r_fail = r_fail.gather(1, best_indices_unsqueezed).squeeze(-1)
            
            # 4. ì ìˆ˜ë¥¼ ì›ë˜ ë‹¨ìœ„(Cost)ë¡œ ë³€í™˜ (ìŒìˆ˜ -> ì–‘ìˆ˜)
            # (BOMì€ Scale 100ì´ ê³±í•´ì ¸ ìˆìœ¼ë‹ˆ ë‹¤ì‹œ ë‚˜ëˆŒì§€ëŠ” ì„ íƒì‚¬í•­ì´ë‚˜, ì—¬ê¸°ì„  ì ìˆ˜ ê·¸ëŒ€ë¡œ ë´„)
            # ì‚¬ìš©ìê°€ ì›í•˜ëŠ” ê±´ '$' ë‹¨ìœ„ì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ WEIGHT_BOMìœ¼ë¡œ ë‚˜ëˆ„ëŠ” ê²Œ ì •í™•í•¨?
            # ì¼ë‹¨ ë¦¬ì›Œë“œ ê°’ ìì²´ë¥¼ ì ˆëŒ€ê°’ìœ¼ë¡œ ë”í•¨
            
            total_bom_cost += (-best_r_bom).sum().item()
            total_sleep_penalty += (-best_r_sleep).sum().item()
            total_fail_penalty += (-best_r_fail).sum().item()
            
            # ì„±ê³µ ì—¬ë¶€ (ì‹¤íŒ¨ í˜ë„í‹°ê°€ ì—†ìœ¼ë©´ ì„±ê³µ)
            # FAILURE_PENALTY = -20000.0 ì´ë¯€ë¡œ, ì´ê²ƒë³´ë‹¤ í¬ë©´(0ì— ê°€ê¹Œìš°ë©´) ì„±ê³µ
            is_feasible = (best_r_fail > -10000.0)
            total_feasible_count += is_feasible.sum().item()
            
        # í‰ê·  ê³„ì‚°
        avg_bom = total_bom_cost / total_instances
        avg_sleep = total_sleep_penalty / total_instances
        avg_fail = total_fail_penalty / total_instances
        feasibility_rate = total_feasible_count / total_instances
        
        # ì´ Cost (ë‹¨ìˆœ í•©ì‚°)
        avg_total_cost = avg_bom + avg_sleep + avg_fail
        
        return {
            "avg_total_cost": avg_total_cost,
            "avg_bom": avg_bom,
            "avg_sleep": avg_sleep,
            "avg_fail": avg_fail,
            "feasibility": feasibility_rate
        }


    @torch.no_grad()
    def evaluate(self, epoch: int):
        """ ë¡œë“œëœ Clean / Crisis ë°ì´í„°ì…‹ì— ëŒ€í•´ í‰ê°€ ìˆ˜í–‰ """
        metrics = {}
        
        # ... (í‰ê°€ ìˆ˜í–‰ ì½”ë“œëŠ” ê¸°ì¡´ê³¼ ë™ì¼) ...
            
        # ë¡œê·¸ í¬ë§· ìˆ˜ì •
        log_msg = f"[Eval Summary] Epoch {epoch}"
        
        if "clean" in metrics:
            c = metrics["clean"]
            # Total / BOM / Sleep / Feasibility ì¶œë ¥
            log_msg += (f"\n   ğŸ‘‰ Clean : Total {c['avg_total_cost']:.1f} "
                        f"(BOM {c['avg_bom']:.1f} + Sleep {c['avg_sleep']:.1f}) "
                        f"| Feas: {c['feasibility']*100:.1f}%")
                        
        if "crisis" in metrics:
            c = metrics["crisis"]
            log_msg += (f"\n   ğŸ‘‰ Crisis: Total {c['avg_total_cost']:.1f} "
                        f"(BOM {c['avg_bom']:.1f} + Sleep {c['avg_sleep']:.1f}) "
                        f"| Feas: {c['feasibility']*100:.1f}%")
                        
        self.log(log_msg)
        
        # CSV ë¡œê¹… (ì»¬ëŸ¼ ì¶”ê°€)
        csv_path = os.path.join(self.result_dir, "val_log.csv")
        header = not os.path.exists(csv_path)
        with open(csv_path, "a", encoding="utf-8") as f:
            if header: 
                f.write("epoch,clean_total,clean_bom,clean_sleep,clean_feas,crisis_total,crisis_bom,crisis_sleep,crisis_feas\n")
            
            c = metrics.get("clean", {})
            cr = metrics.get("crisis", {})
            
            f.write(f"{epoch},"
                    f"{c.get('avg_total_cost', -1):.2f},{c.get('avg_bom', -1):.2f},{c.get('avg_sleep', -1):.2f},{c.get('feasibility', -1):.2f},"
                    f"{cr.get('avg_total_cost', -1):.2f},{cr.get('avg_bom', -1):.2f},{cr.get('avg_sleep', -1):.2f},{cr.get('feasibility', -1):.2f}\n")
            
        return metrics

    def test(self):
        """ 
        [ìµœì¢… ì‹¤í—˜] Clean / Crisis í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹(1000ê°œ)ì— ëŒ€í•œ ì •ëŸ‰ í‰ê°€ ìˆ˜í–‰ 
        (generate_final_test.pyë¡œ ìƒì„±ëœ ë°ì´í„°ê°€ ìˆì–´ì•¼ í•¨)
        """
        self.model.eval()
        self.log("=" * 60)
        self.log("ğŸ”¬ ìµœì¢… í…ŒìŠ¤íŠ¸ (Final Test) ì‹œì‘...")
        
        # 1. í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ê²½ë¡œ ì„¤ì • (generate_final_test.pyì—ì„œ ì§€ì •í•œ ê²½ë¡œ)
        test_base_path = "test_data"
        test_files = {
            "clean": "test_set_final_1000_clean.pt",
            "crisis": "test_set_final_1000_crisis.pt"
        }
        
        test_datasets = {}
        
        # 2. ë°ì´í„°ì…‹ ë¡œë“œ
        for key, filename in test_files.items():
            path = os.path.join(test_base_path, filename)
            if os.path.exists(path):
                self.log(f"ğŸ“‚ Loading Test Set [{key.upper()}]: {path}")
                try:
                    # CPUë¡œ ë¡œë“œ (í‰ê°€ ì‹œ ë°°ì¹˜ ë‹¨ìœ„ë¡œ GPU ì´ë™)
                    test_datasets[key] = torch.load(path, weights_only=False).to("cpu")
                except Exception as e:
                    self.log(f"âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            else:
                self.log(f"âš ï¸ íŒŒì¼ ì—†ìŒ: {path} (generate_final_test.pyë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”)")

        if not test_datasets:
            self.log("âŒ ìˆ˜í–‰í•  í…ŒìŠ¤íŠ¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ì¢…ë£Œí•©ë‹ˆë‹¤.")
            return

        # 3. í‰ê°€ ìˆ˜í–‰ (validate_on_dataset ì¬ì‚¬ìš©)
        results = {}
        self.log("-" * 60)
        
        for name, ds in test_datasets.items():
            self.log(f"ğŸš€ Evaluating {name.upper()} Set ({len(ds)} samples)...")
            
            # validate_on_datasetì€ ë°°ì¹˜ ì²˜ë¦¬ë¥¼ í•´ì£¼ë¯€ë¡œ ëŒ€ìš©ëŸ‰ ë°ì´í„°ë„ OK
            res = self.validate_on_dataset(ds, desc=f"Test-{name}")
            results[name] = res
            
            self.log(f"   ğŸ‘‰ {name.upper()} Result: Avg BOM ${res['avg_bom']:.4f}")

        # 4. ìµœì¢… ë¦¬í¬íŠ¸ ì¶œë ¥ (ë…¼ë¬¸ Table ì‘ì„±ìš©)
        self.log("=" * 60)
        self.log("ğŸ“Š [FINAL REPORT] ë…¼ë¬¸ ì‹¤í—˜ ê²°ê³¼ ìš”ì•½")
        
        if "clean" in results:
            r = results["clean"]
            self.log(f"âœ… Normal Condition (Clean) : Cost ${r['avg_bom']:.4f} | Feasibility {r['feasibility']*100:.1f}%")
            
        if "crisis" in results:
            r = results["crisis"]
            self.log(f"âš ï¸ Supply Crisis (Crisis) : Cost ${r['avg_bom']:.4f} | Feasibility {r['feasibility']*100:.1f}%")
            
        self.log("=" * 60)
        
        # (ì˜µì…˜) ë§ˆì§€ë§‰ìœ¼ë¡œ ì‹œê°í™” í•˜ë‚˜ ë‚¨ê¸°ê¸°
        self._run_test_visualization(epoch=9999, is_best=False)

    @torch.no_grad()
    def _run_test_visualization(self, epoch: int, is_best: bool = False):
        """
        ë‹¨ì¼ ì¸ìŠ¤í„´ìŠ¤ì— ëŒ€í•´ ì¶”ë¡ ì„ ì‹¤í–‰í•˜ê³ ,
        ìµœì¢… í…ì„œ(TensorDict) ìƒíƒœë¥¼ ê¸°ë°˜ìœ¼ë¡œ íŒŒì›ŒíŠ¸ë¦¬ ì‹œê°í™”(PNG)ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.
        """
        self.model.eval()
        args = self.args
        
        # --- [íŒŒì¼ ì´ë¦„ ì ‘ë‘ì‚¬ ì„¤ì •] ---
        if is_best:
            log_prefix = f"[Test Viz @ Epoch {epoch} (BEST)]"
            filename_prefix = f"epoch_{epoch}_best"
        elif epoch > 0:
            log_prefix = f"[Test Viz @ Epoch {epoch}]"
            filename_prefix = f"epoch_{epoch}"
        else:
            log_prefix = "[Test Viz (Standalone)]"
            filename_prefix = "test_solution"

        self.log(f"{log_prefix} ì¶”ë¡  ë° ì‹œê°í™” ì‹œì‘...")

        # 1. ë‹¨ì¼ ë°°ì¹˜(B=1)ë¡œ í™˜ê²½ ë¦¬ì…‹
        #td = self.env.reset(batch_size=1)
        # 1. ê²€ì¦ ë°ì´í„°ì…‹(Clean)ì´ ìˆëŠ”ì§€ í™•ì¸í•˜ê³ , ìˆìœ¼ë©´ 0ë²ˆ ë¬¸ì œë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
        if "clean" in self.val_datasets and self.val_datasets["clean"] is not None and len(self.val_datasets["clean"]) > 0:
            # 0ë²ˆ ì¸ë±ìŠ¤ë§Œ ì˜ë¼ì„œ ê°€ì ¸ì˜´ (í•­ìƒ ê°™ì€ ë¬¸ì œ)
            sample_td = self.val_datasets["clean"][:1].clone().to(self.device)
            td = self.env.reset(init_td=sample_td)
            self.log(f"   ğŸ‘‰ [Fixed] ê²€ì¦ ë°ì´í„°ì…‹(Clean)ì˜ ì²« ë²ˆì§¸ ìƒ˜í”Œì„ ì‹œê°í™”í•©ë‹ˆë‹¤.")
        else:
            # ë°ì´í„°ì…‹ì´ ì—†ìœ¼ë©´ ì–´ì©” ìˆ˜ ì—†ì´ ëœë¤ ìƒì„±
            td = self.env.reset(batch_size=1)
            self.log(f"   ğŸ‘‰ [Random] ê²€ì¦ ë°ì´í„°ì…‹ì´ ì—†ì–´ ëœë¤ ìƒ˜í”Œì„ ì‹œê°í™”í•©ë‹ˆë‹¤.")
        
        # 2. POMO í™•ì¥
        test_samples, start_nodes_idx = self.env.select_start_nodes(td)

        pbar_desc = f"Solving (Mode: {args.decode_type}, Samples: {test_samples})"
        pbar = tqdm(total=1, desc=pbar_desc, dynamic_ncols=True)
        
        # 3. ëª¨ë¸ ì¶”ë¡  (AMP ì‚¬ìš©)
        with autocast(device_type='cuda', enabled=self.use_amp):
            out = self.model(
                td, self.env,
                decode_type=args.decode_type,
                pbar=pbar,
                log_fn=self.log,
                log_idx=args.log_idx,
                log_mode='detail',
                return_final_td=True,
            )
        pbar.close()

        # 4. ìµœê³  ì„±ëŠ¥ ì†”ë£¨ì…˜ ì„ íƒ
        reward = out['reward'] # (B_total,)
        best_idx = reward.argmax()
        final_cost = -reward[best_idx].item()
        
        # 5. ëª¨ë¸ì´ ëŒë¦¬ê³  ì˜¨ ìµœì¢… TensorDictì—ì„œ í•´ë‹¹ sampleë§Œ ì¶”ì¶œ
        final_td_all = out["final_td"]        # (B_total, N_max, ...)
        final_td_instance = final_td_all[best_idx].clone()

        # 6. POMO ì‹œì‘ ë…¸ë“œ ì´ë¦„ ì°¾ê¸°
        best_start_node_local_idx = best_idx % test_samples
        best_start_node_idx = start_nodes_idx[best_start_node_local_idx].item()
        best_start_node_name = self.env.generator.config.node_names[best_start_node_idx]
        
        # 1. BOM Cost ê³„ì‚° (final_td_instanceì—ì„œ ì§ì ‘ í•©ì‚°)
        #    (TensorDictì—ì„œ Cost í”¼ì²˜ ì¸ë±ìŠ¤ëŠ” 5ë²ˆì…ë‹ˆë‹¤ - definitions.py ê¸°ì¤€)
        active_nodes_mask = final_td_instance["is_active_mask"].bool()
        all_nodes = final_td_instance["nodes"]
        
        # Active ë…¸ë“œ ì¤‘ IC íƒ€ì…ì¸ ê²ƒë“¤ì˜ Cost í•©ì‚°
        # (ë…¸ë“œ íƒ€ì… ì¸ë±ìŠ¤: 0~3, ICëŠ” 3ë²ˆ)
        node_types = all_nodes[..., FEATURE_INDEX["node_type"][0]:FEATURE_INDEX["node_type"][1]].argmax(-1)
        ic_mask = (node_types == NODE_TYPE_IC)
        
        # ìµœì¢…ì ìœ¼ë¡œ Active ìƒíƒœì¸ ICë“¤ì˜ ê°€ê²© í•©ê³„
        total_bom_cost = all_nodes[active_nodes_mask & ic_mask, FEATURE_INDEX["cost"]].sum().item()

        # 2. Sleep Penalty ê³„ì‚° (ì´ë¹„ìš© - BOMë¹„ìš©)
        sleep_penalty = max(0.0, final_cost - total_bom_cost)

        self.log(f"ì¶”ë¡  ì™„ë£Œ (Total: ${final_cost:.4f} | "
                 f"BOM: ${total_bom_cost:.2f} + Penalty: ${sleep_penalty:.4f}), "
                 f"Start: '{best_start_node_name}'")

        # 7. ì‹œê°í™” ì‹¤í–‰ (ìµœì¢… TDì™€ ê³„ì‚°ëœ ê°’ì„ ì‚¬ìš©)
        self.visualize_result(
            final_td_instance, 
            final_cost, 
            best_start_node_name, 
            filename_prefix
        )

        # â”€â”€ ë©”ëª¨ë¦¬ ì •ë¦¬ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # out ì•ˆì—ëŠ” reward, log_likelihood ë“± GPU í…ì„œê°€ í¬í•¨ë˜ì–´ ìˆë‹¤.
        # í•¨ìˆ˜ê°€ ëë‚˜ë©´ ì–´ì°¨í”¼ íŒŒì´ì¬ ì°¸ì¡°ëŠ” ì‚¬ë¼ì§€ì§€ë§Œ,
        # CUDA ìºì‹œë¥¼ ì¡°ê¸ˆì´ë¼ë„ ë˜ëŒë¦¬ê³  ì‹¶ë‹¤ë©´ ì—¬ê¸°ì„œ ì •ë¦¬í•´ ì¤„ ìˆ˜ ìˆë‹¤.
        try:
            del out
            del final_td_all
            del final_td_instance
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
        except NameError:
            # í˜¹ì‹œë¼ë„ ìœ„ ë³€ìˆ˜ ì´ë¦„ì´ ë°”ë€Œì–´ë„ í¬ë˜ì‹œëŠ” ë°©ì§€
            pass


        self.log(f"{log_prefix} ì‹œê°í™” ë‹¤ì´ì–´ê·¸ë¨ ì €ì¥ ì™„ë£Œ.")

    def visualize_result(self, 
                         final_td: TensorDict, 
                         final_cost: float, 
                         best_start_node_name: str, 
                         filename_prefix: str = "solution"):
        """
        ìµœì¢… TensorDict ìƒíƒœë¥¼ ê¸°ë°˜ìœ¼ë¡œ íŒŒì›ŒíŠ¸ë¦¬ ì‹œê°í™”(PNG)ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.
        """

        if self.result_dir is None: return
        os.makedirs(self.result_dir, exist_ok=True)

        # 1. ì •ë³´ ì¶”ì¶œ ë° ë§µ ìƒì„±
        node_names = self.env.generator.config.node_names
        loads_map = {load['name']: load for load in self.env.generator.config.loads}
        candidate_ics_map = {ic['name']: ic for ic in self.env.generator.config.available_ics}
        battery_conf = self.env.generator.config.battery
        constraints = self.env.generator.config.constraints

        all_nodes_features = final_td["nodes"].squeeze(0)
        is_active_mask = final_td["is_active_mask"].squeeze(0)

        # --- Spawnëœ ìŠ¬ë¡¯ì˜ ì´ë¦„ì„ í…œí”Œë¦¿ ê¸°ë°˜ìœ¼ë¡œ ìƒì„± ---
        dynamic_node_names = list(node_names)
        if len(dynamic_node_names) < self.env.N_max:
            dynamic_node_names.extend([None] * (self.env.N_max - len(dynamic_node_names)))

        spawn_name_counter: Counter = Counter()
        for idx in range(len(node_names), self.env.N_max):
            if idx >= len(is_active_mask) or not is_active_mask[idx]:
                continue

            node_feat = all_nodes_features[idx]
            node_id_val = node_feat[FEATURE_INDEX["node_id"]].item()
            template_idx = int(round(node_id_val * self.env.N_max))

            if 0 <= template_idx < len(node_names):
                base_name = node_names[template_idx]
            else:
                base_name = f"Spawned_Template_{template_idx}"

            spawn_name_counter[base_name] += 1
            dynamic_node_names[idx] = f"{base_name}#{spawn_name_counter[base_name]}"

        # --- Safe Name Lookup Helper ---
        def get_node_name_safe(idx: int) -> str:
            if 0 <= idx < len(dynamic_node_names):
                name = dynamic_node_names[idx]
                if name:
                    return name
            if idx == -1:
                return "N/A"
            return f"Spawned_IC_{idx}"
        # --- Safe Name Lookup Helper ---

        # 2. ì—£ì§€ ì¬êµ¬ì„± (adj_matrixë¥¼ ì‚¬ìš©)
        adj_matrix = final_td["adj_matrix"].squeeze(0) # (N_max, N_max)
        
        used_ic_names = set()
        child_to_parent = {}
        parent_to_children = defaultdict(list)
        
        parent_indices, child_indices = adj_matrix.nonzero(as_tuple=True)
        for p_idx, c_idx in zip(parent_indices, child_indices):
            p_name = get_node_name_safe(p_idx.item())
            c_name = get_node_name_safe(c_idx.item())
            
            child_to_parent[c_name] = p_name
            parent_to_children[p_name].append(c_name)
            
            if p_name in candidate_ics_map:
                used_ic_names.add(p_name)
        
        # 3. Always-On, Independent Rail ê²½ë¡œ ì¶”ì 
        always_on_nodes = {
            name for name, conf in loads_map.items() if conf.get("always_on_in_sleep", False)
        }
        always_on_nodes.add(battery_conf['name'])
        nodes_to_process = list(always_on_nodes)

        while nodes_to_process:
            node = nodes_to_process.pop(0)
            if node in child_to_parent:
                parent = child_to_parent[node]
                if parent not in always_on_nodes:
                    always_on_nodes.add(parent)
                    nodes_to_process.append(parent)

        supplier_nodes = set()
        path_nodes = set()
        for name, conf in loads_map.items():
            rail_type = conf.get("independent_rail_type")
            if rail_type == 'exclusive_supplier':
                supplier_nodes.add(name)
                if name in child_to_parent:
                    supplier_nodes.add(child_to_parent.get(name))
            elif rail_type == 'exclusive_path':
                current_node = name
                while current_node in child_to_parent:
                    path_nodes.add(current_node)
                    parent = child_to_parent[current_node]
                    path_nodes.add(parent)
                    if parent == battery_conf['name']: break
                    current_node = parent

        # 4. ì•¡í‹°ë¸Œ/ìŠ¬ë¦½ ì „ë¥˜ ë° ì „ë ¥ ê³„ì‚° (Bottom-up ë°©ì‹) 
        junction_temps, actual_i_ins_active, actual_i_outs_active = {}, {}, {}
        actual_i_ins_sleep, actual_i_outs_sleep, ic_self_consumption_sleep = {}, {}, {}
        
        active_current_draw = {name: conf["current_active"] for name, conf in loads_map.items()}
        sleep_current_draw = {name: conf["current_sleep"] for name, conf in loads_map.items()}

        node_types = all_nodes_features[..., FEATURE_INDEX["node_type"][0]:FEATURE_INDEX["node_type"][1]].argmax(-1)
        is_active = final_td["is_active_mask"].squeeze(0)
        active_indices = torch.where(is_active)[0]

        active_ics_indices = [
            idx.item() for idx in active_indices
            if node_types[idx] == NODE_TYPE_IC
        ]
        
        processed_ics = set()
        
        while len(processed_ics) < len(active_ics_indices):
            progress_made = False
            
            for ic_idx in active_ics_indices:
                ic_name = get_node_name_safe(ic_idx)
                if ic_name in processed_ics: continue

                if ic_name not in candidate_ics_map:
                    node_feat = all_nodes_features[ic_idx]
                    ic_type_idx = node_feat[FEATURE_INDEX["ic_type_idx"]].item()
                    ic_type = 'LDO' if ic_type_idx == 1.0 else 'Buck'
                    
                    ic_data_for_obj = {
                        'type': ic_type,
                        'name': ic_name,
                        'vin': node_feat[FEATURE_INDEX["vin_min"]].item(),
                        'vout': node_feat[FEATURE_INDEX["vout_min"]].item(),
                        # --- FIX: Missing required positional arguments ---
                        'vin_min': node_feat[FEATURE_INDEX["vin_min"]].item(),
                        'vin_max': node_feat[FEATURE_INDEX["vin_max"]].item(),
                        'vout_min': node_feat[FEATURE_INDEX["vout_min"]].item(),
                        'vout_max': node_feat[FEATURE_INDEX["vout_max"]].item(),
                        # ------------------------------------------------
                        'original_i_limit': node_feat[FEATURE_INDEX["i_limit"]].item() / (1.0 - constraints.get('current_margin', 0.1)),
                        'i_limit': node_feat[FEATURE_INDEX["i_limit"]].item(),
                        'operating_current': node_feat[FEATURE_INDEX["op_current"]].item(),
                        'quiescent_current': node_feat[FEATURE_INDEX["quiescent_current"]].item(),
                        'shutdown_current': node_feat[FEATURE_INDEX["shutdown_current"]].item(),
                        'cost': node_feat[FEATURE_INDEX["cost"]].item(),
                        'theta_ja': node_feat[FEATURE_INDEX["theta_ja"]].item(),
                        't_junction_max': node_feat[FEATURE_INDEX["t_junction_max"]].item(),
                    }
                    if ic_type == 'LDO': ic_data_for_obj['v_dropout'] = 0.0
                    
                else: 
                    ic_data_for_obj = candidate_ics_map[ic_name].copy()
                    ic_type = ic_data_for_obj['type']
                
                ic_obj = LDO(**ic_data_for_obj) if ic_type == 'LDO' else BuckConverter(**ic_data_for_obj)
                
                children_names = parent_to_children.get(ic_name, [])

                if all(c in loads_map or c in processed_ics for c in children_names):
                    
                    # --- Active ì „ë¥˜/ë°œì—´ ê³„ì‚° ---
                    total_i_out_active = sum(active_current_draw.get(c, 0) for c in children_names)
                    actual_i_outs_active[ic_name] = total_i_out_active
                    
                    i_in_active = ic_obj.calculate_active_input_current(vin=ic_obj.vin, i_out=total_i_out_active)
                    power_loss = ic_obj.calculate_power_loss(vin=ic_obj.vin, i_out=total_i_out_active)
                    
                    active_current_draw[ic_name] = i_in_active
                    actual_i_ins_active[ic_name] = i_in_active
                    ambient_temp = constraints.get('ambient_temperature', 25)
                    junction_temps[ic_name] = ambient_temp + (power_loss * ic_obj.theta_ja)

                    # --- Sleep ì „ë¥˜ ê³„ì‚° ---
                    parent_name = child_to_parent.get(ic_name)
                    is_ao = ic_name in always_on_nodes
                    parent_is_ao = parent_name in always_on_nodes or parent_name == battery_conf['name']
                    
                    total_i_out_sleep = sum(sleep_current_draw.get(c, 0) for c in children_names)

                    ic_self_sleep = ic_obj.get_self_sleep_consumption(is_ao, parent_is_ao)
                    i_in_for_children = ic_obj.calculate_sleep_input_for_children(vin=ic_obj.vin, i_out_sleep=total_i_out_sleep)
                    
                    i_in_sleep = ic_self_sleep + i_in_for_children

                    actual_i_ins_sleep[ic_name] = i_in_sleep
                    actual_i_outs_sleep[ic_name] = total_i_out_sleep
                    ic_self_consumption_sleep[ic_name] = ic_self_sleep
                    sleep_current_draw[ic_name] = i_in_sleep

                    processed_ics.add(ic_name)
                    progress_made = True
            
            if not progress_made and len(active_ics_indices) > 0 and len(processed_ics) < len(active_ics_indices): 
                self.log(f"âš ï¸ ê²½ê³ : Power Tree ê³„ì‚° ìˆœí™˜ ì°¸ì¡° ë°œìƒ ë˜ëŠ” ë¯¸ì²˜ë¦¬ IC ì”ì¡´.")
                break

        # 5. ìµœì¢… ì‹œìŠ¤í…œ ì „ì²´ ê°’ ê³„ì‚°
        primary_nodes = parent_to_children.get(battery_conf['name'], [])
        total_active_current = sum(active_current_draw.get(name, 0) for name in primary_nodes)
        total_sleep_current = sum(sleep_current_draw.get(name, 0) for name in primary_nodes)
        battery_avg_voltage = (battery_conf['voltage_min'] + battery_conf['voltage_max']) / 2
        total_active_power = battery_avg_voltage * total_active_current

        # 6. Graphviz ë‹¤ì´ì–´ê·¸ë¨ ìƒì„±
        # --- ğŸ‘‡ [ì‹ ê·œ] BOM ë¹„ìš©ê³¼ ì•”ì „ë¥˜ í˜ë„í‹° ë¶„ë¦¬ ê³„ì‚° ---
        #total_bom_cost = sum(candidate_ics_map[name]['cost'] for name in used_ic_names)

        # --- [ìˆ˜ì • í›„] ë…¸ë“œ í”¼ì²˜ í…ì„œì—ì„œ ì§ì ‘ Cost í•©ì‚° ---
        total_bom_cost = 0.0
        # active_ics_indicesëŠ” í•¨ìˆ˜ ìƒë‹¨(4ë²ˆ ì„¹ì…˜)ì—ì„œ ì´ë¯¸ êµ¬í•´ì ¸ ìˆìŠµë‹ˆë‹¤.
        for ic_idx in active_ics_indices:
            # FEATURE_INDEX["cost"] = 5 (definitions.py ê¸°ì¤€)
            node_cost = all_nodes_features[ic_idx, FEATURE_INDEX["cost"]].item()
            total_bom_cost += node_cost
            
        sleep_penalty = max(0.0, final_cost - total_bom_cost) # (ì „ì²´ - BOM = í˜ë„í‹°)
        
        label_str = (f"Transformer Solution (Start: {best_start_node_name})\\n"
                     f"Total Cost: ${final_cost:.4f}\\n"
                     f"(BOM: ${total_bom_cost:.2f} + Penalty: ${sleep_penalty:.4f})")

        dot = Digraph(comment=f"Power Tree - Cost ${final_cost:.4f}")
        dot.attr('node', shape='box', style='rounded,filled', fontname='Arial')
        
        margin_info = f"Current Margin: {constraints.get('current_margin', 0)*100:.0f}%"
        temp_info = f"Ambient Temp: {constraints.get('ambient_temperature', 25)}Â°C"
        dot.attr(rankdir='LR', label=label_str, labelloc='t')

        max_sleep_current_target = constraints.get('max_sleep_current', 0.0)
        battery_label = (f"ğŸ”‹ {battery_conf['name']}\n\n"
            f"Total Active Power: {total_active_power:.2f} W\n"
            f"Total Active Current: {total_active_current * 1000:.1f} mA\n"
            f"Target Sleep Current: <= {max_sleep_current_target * 1000000:,.1f} ÂµA\n"
            f"Total Sleep Current: {total_sleep_current * 1000000:,.1f} ÂµA")
        dot.node(battery_conf['name'], battery_label, shape='box', color='darkgreen', fillcolor='white')

        sequenced_loads = set()
        if 'power_sequences' in constraints:
            for seq in constraints['power_sequences']:
                sequenced_loads.add(seq['j']); sequenced_loads.add(seq['k'])
        
        for ic_idx in active_ics_indices:
            ic_name = get_node_name_safe(ic_idx)
            
            if ic_name not in candidate_ics_map:
                node_feat = all_nodes_features[ic_idx]
                ic_data_for_label = {
                    'name': ic_name,
                    'vin': node_feat[FEATURE_INDEX["vin_min"]].item(),
                    'vout': node_feat[FEATURE_INDEX["vout_min"]].item(),
                    'operating_current': node_feat[FEATURE_INDEX["op_current"]].item(),
                    't_junction_max': node_feat[FEATURE_INDEX["t_junction_max"]].item(),
                    'cost': node_feat[FEATURE_INDEX["cost"]].item(),
                }
            else:
                ic_data_for_label = candidate_ics_map[ic_name]
            
            
            i_in_active_val = actual_i_ins_active.get(ic_name, 0)
            i_out_active_val = actual_i_outs_active.get(ic_name, 0)
            i_in_sleep_val = actual_i_ins_sleep.get(ic_name, 0)
            i_out_sleep_val = actual_i_outs_sleep.get(ic_name, 0)
            i_self_sleep_val = ic_self_consumption_sleep.get(ic_name, 0)
            calculated_tj = junction_temps.get(ic_name, 0) 
            
            thermal_margin = ic_data_for_label['t_junction_max'] - calculated_tj
            node_color = 'blue'
            if thermal_margin < 10: node_color = 'red'
            elif thermal_margin < 25: node_color = 'orange'
            
            node_style = 'rounded,filled'
            if ic_name not in always_on_nodes:
                node_style += ',dashed'

            fill_color = 'white'
            if ic_name in path_nodes:
                fill_color = 'lightblue'
            elif ic_name in supplier_nodes:
                fill_color = 'lightyellow'
            
            label = (f"ğŸ“¦ {ic_name.split('@')[0]}\n\n"
                     f"Vin: {ic_data_for_label['vin']:.2f}V, Vout: {ic_data_for_label['vout']:.2f}V\n"
                     f"Iin: {i_in_active_val*1000:.1f}mA (Act) | {i_in_sleep_val*1000000:,.1f}ÂµA (Slp)\n"
                     f"Iout: {i_out_active_val*1000:.1f}mA (Act) | {i_out_sleep_val*1000000:,.1f}ÂµA (Slp)\n"
                     f"I_self: {ic_data_for_label['operating_current']*1000:.1f}mA (Act) | {i_self_sleep_val*1000000:,.1f}ÂµA (Slp)\n"
                     f"Tj: {calculated_tj:.1f}Â°C (Max: {ic_data_for_label['t_junction_max']}Â°C)\n"
                     f"Cost: ${ic_data_for_label['cost']:.2f}")
            dot.node(ic_name, label, color=node_color, fillcolor=fill_color, style=node_style, penwidth='3')

        for name, conf in loads_map.items():
            node_style = 'rounded,filled'
            if name not in always_on_nodes: node_style += ',dashed'
            fill_color = 'white'
            if name in path_nodes: fill_color = 'lightblue'
            elif name in supplier_nodes: fill_color = 'lightyellow'
            
            label = f"ğŸ’¡ {name}\nActive: {conf['voltage_typical']}V | {conf['current_active']*1000:.1f}mA\n"
            if conf['current_sleep'] > 0: label += f"Sleep: {conf['current_sleep'] * 1000000:,.1f}ÂµA\n"
            conditions = []
            if conf.get("independent_rail_type"): conditions.append(f"ğŸ”’ {conf['independent_rail_type']}")
            if name in sequenced_loads: conditions.append("â›“ï¸ Sequence")
            if conditions: label += " ".join(conditions)
            
            penwidth = '3' if conf.get("always_on_in_sleep", False) else '1'
            dot.node(name, label, color='dimgray', fillcolor=fill_color, style=node_style, penwidth=penwidth)

        for p_name, children in parent_to_children.items():
            for c_name in children:
                dot.edge(p_name, c_name)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"{filename_prefix}_cost_{final_cost:.4f}_{timestamp}"
        output_path = os.path.join(self.result_dir, filename)
        
        try:
            dot.render(output_path, view=False, format='png', cleanup=True)
            self.log(f"âœ… ìƒì„¸ ì‹œê°í™” ë‹¤ì´ì–´ê·¸ë¨ì„ {output_path}.png íŒŒì¼ë¡œ ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            self.log(f"âŒ ì‹œê°í™” ë Œë”ë§ ì‹¤íŒ¨. (Graphviz ì„¤ì¹˜ í™•ì¸ í•„ìš”): {e}")